{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model,multi_gpu_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input,GlobalAveragePooling2D,Layer,InputSpec\n",
    "from keras.layers.core import Dense,Flatten,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as K\n",
    "import keras.layers as kl\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pickle\n",
    "# from AttentionModule import SelfAttention, SoftAttention\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "from AttentionMed import SelfAttention, Attention\n",
    "# from coord import CoordinateChannel2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpu=1\n",
    "n_cpu=1\n",
    "tf_config= tf.ConfigProto(device_count = {'GPU': n_gpu , 'CPU': n_cpu})\n",
    "tf_config.gpu_options.allow_growth=True\n",
    "s=tf.Session(config=tf_config)\n",
    "K.set_session(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/MyDataStor1/mshaikh2/project_xray/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=os.getcwd() #Get the path\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>filename</th>\n",
       "      <th>projection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-4001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-3001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3_IM-1384-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3_IM-1384-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4_IM-2050-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>4_IM-2050-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>5_IM-2117-1003002.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>5_IM-2117-1004003.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>6_IM-2192-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>6_IM-2192-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>7_IM-2263-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>7_IM-2263-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>8_IM-2333-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>8_IM-2333-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>9_IM-2407-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>9_IM-2407-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>10_IM-0002-2001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>10_IM-0002-1001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>11_IM-0067-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11</td>\n",
       "      <td>11_IM-0067-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12</td>\n",
       "      <td>12_IM-0133-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>12_IM-0133-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>13_IM-0198-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13</td>\n",
       "      <td>13_IM-0198-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14</td>\n",
       "      <td>14_IM-0256-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>14_IM-0256-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15</td>\n",
       "      <td>15_IM-0324-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15</td>\n",
       "      <td>15_IM-0324-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16</td>\n",
       "      <td>16_IM-0389-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>16</td>\n",
       "      <td>16_IM-0389-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>17</td>\n",
       "      <td>17_IM-0460-2001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>17</td>\n",
       "      <td>17_IM-0460-1001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>18</td>\n",
       "      <td>18_IM-0520-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>18</td>\n",
       "      <td>18_IM-0520-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>19</td>\n",
       "      <td>19_IM-0583-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>19</td>\n",
       "      <td>19_IM-0583-3003.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20</td>\n",
       "      <td>20_IM-0653-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20</td>\n",
       "      <td>20_IM-0653-1002.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>21</td>\n",
       "      <td>21_IM-0729-1001-0001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>21</td>\n",
       "      <td>21_IM-0729-1001-0002.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>22</td>\n",
       "      <td>22_IM-0810-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>22</td>\n",
       "      <td>22_IM-0810-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>23</td>\n",
       "      <td>23_IM-0879-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>23</td>\n",
       "      <td>23_IM-0879-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>24</td>\n",
       "      <td>24_IM-0949-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>24</td>\n",
       "      <td>24_IM-0949-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>25</td>\n",
       "      <td>25_IM-1024-2001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>25</td>\n",
       "      <td>25_IM-1024-3001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid                      filename projection\n",
       "0     1        1_IM-0001-4001.dcm.png    Frontal\n",
       "1     1        1_IM-0001-3001.dcm.png    Lateral\n",
       "2     2        2_IM-0652-1001.dcm.png    Frontal\n",
       "3     2        2_IM-0652-2001.dcm.png    Lateral\n",
       "4     3        3_IM-1384-1001.dcm.png    Frontal\n",
       "5     3        3_IM-1384-2001.dcm.png    Lateral\n",
       "6     4        4_IM-2050-1001.dcm.png    Frontal\n",
       "7     4        4_IM-2050-2001.dcm.png    Lateral\n",
       "8     5     5_IM-2117-1003002.dcm.png    Frontal\n",
       "9     5     5_IM-2117-1004003.dcm.png    Lateral\n",
       "10    6        6_IM-2192-1001.dcm.png    Frontal\n",
       "11    6        6_IM-2192-2001.dcm.png    Lateral\n",
       "12    7        7_IM-2263-1001.dcm.png    Frontal\n",
       "13    7        7_IM-2263-2001.dcm.png    Lateral\n",
       "14    8        8_IM-2333-1001.dcm.png    Frontal\n",
       "15    8        8_IM-2333-2001.dcm.png    Lateral\n",
       "16    9        9_IM-2407-1001.dcm.png    Frontal\n",
       "17    9        9_IM-2407-2001.dcm.png    Lateral\n",
       "18   10       10_IM-0002-2001.dcm.png    Frontal\n",
       "19   10       10_IM-0002-1001.dcm.png    Lateral\n",
       "20   11       11_IM-0067-1001.dcm.png    Frontal\n",
       "21   11       11_IM-0067-2001.dcm.png    Lateral\n",
       "22   12       12_IM-0133-1001.dcm.png    Frontal\n",
       "23   12       12_IM-0133-2001.dcm.png    Lateral\n",
       "24   13       13_IM-0198-1001.dcm.png    Frontal\n",
       "25   13       13_IM-0198-2001.dcm.png    Lateral\n",
       "26   14       14_IM-0256-1001.dcm.png    Frontal\n",
       "27   14       14_IM-0256-2001.dcm.png    Lateral\n",
       "28   15       15_IM-0324-1001.dcm.png    Frontal\n",
       "29   15       15_IM-0324-2001.dcm.png    Lateral\n",
       "30   16       16_IM-0389-1001.dcm.png    Frontal\n",
       "31   16       16_IM-0389-2001.dcm.png    Lateral\n",
       "32   17       17_IM-0460-2001.dcm.png    Frontal\n",
       "33   17       17_IM-0460-1001.dcm.png    Lateral\n",
       "34   18       18_IM-0520-1001.dcm.png    Frontal\n",
       "35   18       18_IM-0520-2001.dcm.png    Lateral\n",
       "36   19       19_IM-0583-1001.dcm.png    Frontal\n",
       "37   19       19_IM-0583-3003.dcm.png    Lateral\n",
       "38   20       20_IM-0653-1001.dcm.png    Frontal\n",
       "39   20       20_IM-0653-1002.dcm.png    Lateral\n",
       "40   21  21_IM-0729-1001-0001.dcm.png    Frontal\n",
       "41   21  21_IM-0729-1001-0002.dcm.png    Lateral\n",
       "42   22       22_IM-0810-1001.dcm.png    Frontal\n",
       "43   22       22_IM-0810-2001.dcm.png    Lateral\n",
       "44   23       23_IM-0879-1001.dcm.png    Frontal\n",
       "45   23       23_IM-0879-2001.dcm.png    Lateral\n",
       "46   24       24_IM-0949-1001.dcm.png    Frontal\n",
       "47   24       24_IM-0949-2001.dcm.png    Lateral\n",
       "48   25       25_IM-1024-2001.dcm.png    Frontal\n",
       "49   25       25_IM-1024-3001.dcm.png    Lateral"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7466, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>MeSH</th>\n",
       "      <th>Problems</th>\n",
       "      <th>image</th>\n",
       "      <th>indication</th>\n",
       "      <th>comparison</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Positive TB test</td>\n",
       "      <td>None.</td>\n",
       "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n",
       "      <td>Cardiomegaly;Pulmonary Artery</td>\n",
       "      <td>Chest, 2 views, frontal and lateral</td>\n",
       "      <td>Preop bariatric surgery.</td>\n",
       "      <td>None.</td>\n",
       "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>rib pain after a XXXX, XXXX XXXX steps this XX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No displaced rib fractures, pneumothorax, or p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>PA and lateral views of the chest XXXX, XXXX a...</td>\n",
       "      <td>XXXX-year-old XXXX with XXXX.</td>\n",
       "      <td>None available</td>\n",
       "      <td>There are diffuse bilateral interstitial and a...</td>\n",
       "      <td>1. Bullous emphysema and interstitial fibrosis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Osteophyte/thoracic vertebrae/multiple/small;T...</td>\n",
       "      <td>Osteophyte;Thickening;Lung</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Chest and nasal congestion.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The cardiomediastinal silhouette and pulmonary...</td>\n",
       "      <td>No acute cardiopulmonary abnormality.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                                               MeSH  \\\n",
       "0    1                                             normal   \n",
       "1    2  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n",
       "2    3                                             normal   \n",
       "3    4  Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "4    5  Osteophyte/thoracic vertebrae/multiple/small;T...   \n",
       "\n",
       "                                            Problems  \\\n",
       "0                                             normal   \n",
       "1                      Cardiomegaly;Pulmonary Artery   \n",
       "2                                             normal   \n",
       "3  Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "4                         Osteophyte;Thickening;Lung   \n",
       "\n",
       "                                               image  \\\n",
       "0                          Xray Chest PA and Lateral   \n",
       "1                Chest, 2 views, frontal and lateral   \n",
       "2                          Xray Chest PA and Lateral   \n",
       "3  PA and lateral views of the chest XXXX, XXXX a...   \n",
       "4                          Xray Chest PA and Lateral   \n",
       "\n",
       "                                          indication      comparison  \\\n",
       "0                                   Positive TB test           None.   \n",
       "1                           Preop bariatric surgery.           None.   \n",
       "2  rib pain after a XXXX, XXXX XXXX steps this XX...             NaN   \n",
       "3                      XXXX-year-old XXXX with XXXX.  None available   \n",
       "4                        Chest and nasal congestion.             NaN   \n",
       "\n",
       "                                            findings  \\\n",
       "0  The cardiac silhouette and mediastinum size ar...   \n",
       "1  Borderline cardiomegaly. Midline sternotomy XX...   \n",
       "2                                                NaN   \n",
       "3  There are diffuse bilateral interstitial and a...   \n",
       "4  The cardiomediastinal silhouette and pulmonary...   \n",
       "\n",
       "                                          impression  \n",
       "0                               Normal chest x-XXXX.  \n",
       "1                       No acute pulmonary findings.  \n",
       "2  No displaced rib fractures, pneumothorax, or p...  \n",
       "3  1. Bullous emphysema and interstitial fibrosis...  \n",
       "4              No acute cardiopulmonary abnormality.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3851, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "proj_ds=pd.read_csv(path+'/../dataset/indiana_projections.csv')\n",
    "repo_ds=pd.read_csv(path+'/../dataset/indiana_reports.csv')\n",
    "\n",
    "display(proj_ds.head(50),proj_ds.shape)\n",
    "display(repo_ds.sort_values(by='uid').head(),repo_ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>filename</th>\n",
       "      <th>projection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-4001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3_IM-1384-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4_IM-2050-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>5_IM-2117-1003002.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                   filename projection\n",
       "0    1     1_IM-0001-4001.dcm.png    Frontal\n",
       "2    2     2_IM-0652-1001.dcm.png    Frontal\n",
       "4    3     3_IM-1384-1001.dcm.png    Frontal\n",
       "6    4     4_IM-2050-1001.dcm.png    Frontal\n",
       "8    5  5_IM-2117-1003002.dcm.png    Frontal"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3818, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_proj_ds = proj_ds[proj_ds.projection=='Frontal']\n",
    "f_proj_ds = f_proj_ds.sort_values(by='uid')\n",
    "display(f_proj_ds.head())\n",
    "f_proj_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>MeSH</th>\n",
       "      <th>Problems</th>\n",
       "      <th>image</th>\n",
       "      <th>indication</th>\n",
       "      <th>comparison</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Positive TB test</td>\n",
       "      <td>None.</td>\n",
       "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n",
       "      <td>Cardiomegaly;Pulmonary Artery</td>\n",
       "      <td>Chest, 2 views, frontal and lateral</td>\n",
       "      <td>Preop bariatric surgery.</td>\n",
       "      <td>None.</td>\n",
       "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>PA and lateral views of the chest XXXX, XXXX a...</td>\n",
       "      <td>XXXX-year-old XXXX with XXXX.</td>\n",
       "      <td>None available</td>\n",
       "      <td>There are diffuse bilateral interstitial and a...</td>\n",
       "      <td>1. Bullous emphysema and interstitial fibrosis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Osteophyte/thoracic vertebrae/multiple/small;T...</td>\n",
       "      <td>Osteophyte;Thickening;Lung</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Chest and nasal congestion.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The cardiomediastinal silhouette and pulmonary...</td>\n",
       "      <td>No acute cardiopulmonary abnormality.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>PA and Lateral Chest. XXXX, XXXX at XXXX</td>\n",
       "      <td>Evaluate for infection</td>\n",
       "      <td>XXXX, XXXX</td>\n",
       "      <td>Heart size and mediastinal contour are within ...</td>\n",
       "      <td>No acute cardiopulmonary findings.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                                               MeSH  \\\n",
       "0    1                                             normal   \n",
       "1    2  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n",
       "3    4  Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "4    5  Osteophyte/thoracic vertebrae/multiple/small;T...   \n",
       "5    6                                             normal   \n",
       "\n",
       "                                            Problems  \\\n",
       "0                                             normal   \n",
       "1                      Cardiomegaly;Pulmonary Artery   \n",
       "3  Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "4                         Osteophyte;Thickening;Lung   \n",
       "5                                             normal   \n",
       "\n",
       "                                               image  \\\n",
       "0                          Xray Chest PA and Lateral   \n",
       "1                Chest, 2 views, frontal and lateral   \n",
       "3  PA and lateral views of the chest XXXX, XXXX a...   \n",
       "4                          Xray Chest PA and Lateral   \n",
       "5          PA and Lateral Chest. XXXX, XXXX at XXXX    \n",
       "\n",
       "                      indication      comparison  \\\n",
       "0               Positive TB test           None.   \n",
       "1       Preop bariatric surgery.           None.   \n",
       "3  XXXX-year-old XXXX with XXXX.  None available   \n",
       "4    Chest and nasal congestion.             NaN   \n",
       "5         Evaluate for infection      XXXX, XXXX   \n",
       "\n",
       "                                            findings  \\\n",
       "0  The cardiac silhouette and mediastinum size ar...   \n",
       "1  Borderline cardiomegaly. Midline sternotomy XX...   \n",
       "3  There are diffuse bilateral interstitial and a...   \n",
       "4  The cardiomediastinal silhouette and pulmonary...   \n",
       "5  Heart size and mediastinal contour are within ...   \n",
       "\n",
       "                                          impression  \n",
       "0                               Normal chest x-XXXX.  \n",
       "1                       No acute pulmonary findings.  \n",
       "3  1. Bullous emphysema and interstitial fibrosis...  \n",
       "4              No acute cardiopulmonary abnormality.  \n",
       "5                 No acute cardiopulmonary findings.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3331, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_repo_ds = repo_ds.dropna(subset=['findings','impression'],how='any')\n",
    "display(c_repo_ds.head())\n",
    "c_repo_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>MeSH</th>\n",
       "      <th>Problems</th>\n",
       "      <th>image</th>\n",
       "      <th>indication</th>\n",
       "      <th>comparison</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "      <th>filename</th>\n",
       "      <th>projection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Positive TB test</td>\n",
       "      <td>None.</td>\n",
       "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "      <td>1_IM-0001-4001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>Xray Chest PA and Lateral</td>\n",
       "      <td>Positive TB test</td>\n",
       "      <td>None.</td>\n",
       "      <td>The cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>Normal chest x-XXXX.</td>\n",
       "      <td>1_IM-0001-3001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n",
       "      <td>Cardiomegaly;Pulmonary Artery</td>\n",
       "      <td>Chest, 2 views, frontal and lateral</td>\n",
       "      <td>Preop bariatric surgery.</td>\n",
       "      <td>None.</td>\n",
       "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "      <td>2_IM-0652-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n",
       "      <td>Cardiomegaly;Pulmonary Artery</td>\n",
       "      <td>Chest, 2 views, frontal and lateral</td>\n",
       "      <td>Preop bariatric surgery.</td>\n",
       "      <td>None.</td>\n",
       "      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n",
       "      <td>No acute pulmonary findings.</td>\n",
       "      <td>2_IM-0652-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n",
       "      <td>PA and lateral views of the chest XXXX, XXXX a...</td>\n",
       "      <td>XXXX-year-old XXXX with XXXX.</td>\n",
       "      <td>None available</td>\n",
       "      <td>There are diffuse bilateral interstitial and a...</td>\n",
       "      <td>1. Bullous emphysema and interstitial fibrosis...</td>\n",
       "      <td>4_IM-2050-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                                               MeSH  \\\n",
       "0    1                                             normal   \n",
       "1    1                                             normal   \n",
       "2    2  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n",
       "3    2  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n",
       "4    4  Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "\n",
       "                                            Problems  \\\n",
       "0                                             normal   \n",
       "1                                             normal   \n",
       "2                      Cardiomegaly;Pulmonary Artery   \n",
       "3                      Cardiomegaly;Pulmonary Artery   \n",
       "4  Pulmonary Disease, Chronic Obstructive;Bullous...   \n",
       "\n",
       "                                               image  \\\n",
       "0                          Xray Chest PA and Lateral   \n",
       "1                          Xray Chest PA and Lateral   \n",
       "2                Chest, 2 views, frontal and lateral   \n",
       "3                Chest, 2 views, frontal and lateral   \n",
       "4  PA and lateral views of the chest XXXX, XXXX a...   \n",
       "\n",
       "                      indication      comparison  \\\n",
       "0               Positive TB test           None.   \n",
       "1               Positive TB test           None.   \n",
       "2       Preop bariatric surgery.           None.   \n",
       "3       Preop bariatric surgery.           None.   \n",
       "4  XXXX-year-old XXXX with XXXX.  None available   \n",
       "\n",
       "                                            findings  \\\n",
       "0  The cardiac silhouette and mediastinum size ar...   \n",
       "1  The cardiac silhouette and mediastinum size ar...   \n",
       "2  Borderline cardiomegaly. Midline sternotomy XX...   \n",
       "3  Borderline cardiomegaly. Midline sternotomy XX...   \n",
       "4  There are diffuse bilateral interstitial and a...   \n",
       "\n",
       "                                          impression                filename  \\\n",
       "0                               Normal chest x-XXXX.  1_IM-0001-4001.dcm.png   \n",
       "1                               Normal chest x-XXXX.  1_IM-0001-3001.dcm.png   \n",
       "2                       No acute pulmonary findings.  2_IM-0652-1001.dcm.png   \n",
       "3                       No acute pulmonary findings.  2_IM-0652-2001.dcm.png   \n",
       "4  1. Bullous emphysema and interstitial fibrosis...  4_IM-2050-1001.dcm.png   \n",
       "\n",
       "  projection  \n",
       "0    Frontal  \n",
       "1    Lateral  \n",
       "2    Frontal  \n",
       "3    Lateral  \n",
       "4    Frontal  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6457, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_ds = pd.merge(left=c_repo_ds,right=proj_ds,on='uid',how='inner')\n",
    "display(merged_ds.head())\n",
    "merged_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chars = []\n",
    "# char_count = {}\n",
    "# finding_len = []\n",
    "# max_len=0\n",
    "# for finding in c_repo_ds.findings:\n",
    "#     tokens = finding.lower()\n",
    "#     for i in list(\"[-<>:.,()]/\"):\n",
    "#         tokens = tokens.replace(i,' ')\n",
    "#     tokens=tokens.strip()\n",
    "#     if max_len<len(tokens):\n",
    "#         max_len=len(tokens)\n",
    "#     finding_len.append(len(tokens))\n",
    "#     chars+=tokens\n",
    "# for impr in c_repo_ds.impression:\n",
    "#     tokens = impr.lower()\n",
    "#     for i in list(\"[-<>:.,()]/\"):\n",
    "#         tokens = tokens.replace(i,' ')\n",
    "#     tokens=tokens.strip()\n",
    "#     chars+=tokens\n",
    "#     if max_len<len(tokens):\n",
    "#         max_len=len(tokens)\n",
    "#     finding_len.append(len(tokens))\n",
    "# print(len(list(set(chars))))\n",
    "# for char in chars:\n",
    "#     if char not in char_count.keys():\n",
    "#         char_count[char]=1\n",
    "#     else:\n",
    "#         char_count[char]+=1\n",
    "# df_ccount = pd.DataFrame()\n",
    "# df_ccount['chars']=char_count.keys()\n",
    "# df_ccount['c_count']=char_count.values()\n",
    "# df_ccount = df_ccount.sort_values(by='c_count',ascending=False).reset_index()\n",
    "# display(df_ccount.head(10))\n",
    "# df_ccount['index'].max(),max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ch_to_co = df_ccount\n",
    "# ch_to_co.index = ch_to_co.chars\n",
    "# ch_to_co = ch_to_co['index'].to_dict()\n",
    "# display(ch_to_co)\n",
    "# co_to_ch = df_ccount\n",
    "# co_to_ch.index = co_to_ch['index']\n",
    "# co_to_ch = co_to_ch['chars'].to_dict()\n",
    "# display(co_to_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = nlp('startseq ' \n",
    "#              + ' '.join(c_repo_ds.impression.values).lower().replace('/',' ')\n",
    "#              + ' endseq.' \n",
    "#              + ' startseq' \n",
    "#              + ' '.join(c_repo_ds.findings.values).lower().replace('/',' ')\n",
    "#              + ' endseq.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = [str(x) for x in tokens]\n",
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>words</th>\n",
       "      <th>w_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1608</td>\n",
       "      <td>.</td>\n",
       "      <td>21069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1667</td>\n",
       "      <td>no</td>\n",
       "      <td>6824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1855</td>\n",
       "      <td>the</td>\n",
       "      <td>6596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1370</td>\n",
       "      <td>is</td>\n",
       "      <td>4367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>538</td>\n",
       "      <td>are</td>\n",
       "      <td>4312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>910</td>\n",
       "      <td>normal</td>\n",
       "      <td>3548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99</td>\n",
       "      <td>,</td>\n",
       "      <td>3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1380</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>3080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1089</td>\n",
       "      <td>of</td>\n",
       "      <td>3043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1675</td>\n",
       "      <td>and</td>\n",
       "      <td>3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1434</td>\n",
       "      <td>acute</td>\n",
       "      <td>2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1853</td>\n",
       "      <td>or</td>\n",
       "      <td>2614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>694</td>\n",
       "      <td>pleural</td>\n",
       "      <td>2613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>405</td>\n",
       "      <td>pneumothorax</td>\n",
       "      <td>2407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>367</td>\n",
       "      <td>there</td>\n",
       "      <td>2361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1649</td>\n",
       "      <td>effusion</td>\n",
       "      <td>2303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1336</td>\n",
       "      <td>heart</td>\n",
       "      <td>2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1450</td>\n",
       "      <td>lungs</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>483</td>\n",
       "      <td>size</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>310</td>\n",
       "      <td>focal</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1693</td>\n",
       "      <td>clear</td>\n",
       "      <td>1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1223</td>\n",
       "      <td>in</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1591</td>\n",
       "      <td>disease</td>\n",
       "      <td>1546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>353</td>\n",
       "      <td>cardiopulmonary</td>\n",
       "      <td>1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1214</td>\n",
       "      <td>pulmonary</td>\n",
       "      <td>1528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>851</td>\n",
       "      <td>within</td>\n",
       "      <td>1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1127</td>\n",
       "      <td>limits</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>185</td>\n",
       "      <td>right</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>348</td>\n",
       "      <td>left</td>\n",
       "      <td>1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1082</td>\n",
       "      <td>abnormality</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>201</td>\n",
       "      <td>definitive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>1537</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>1043</td>\n",
       "      <td>respect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>199</td>\n",
       "      <td>beyond</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>1540</td>\n",
       "      <td>lytic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>1042</td>\n",
       "      <td>showed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>197</td>\n",
       "      <td>detailed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>492</td>\n",
       "      <td>primarily</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>1545</td>\n",
       "      <td>representative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>493</td>\n",
       "      <td>l4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>495</td>\n",
       "      <td>reversal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>205</td>\n",
       "      <td>perforation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>207</td>\n",
       "      <td>sternoclavicular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>1051</td>\n",
       "      <td>unilateral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>1059</td>\n",
       "      <td>orif</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>470</td>\n",
       "      <td>exchanged</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>1070</td>\n",
       "      <td>tenting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>1511</td>\n",
       "      <td>clavicles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>1063</td>\n",
       "      <td>duct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>475</td>\n",
       "      <td>assessment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>1518</td>\n",
       "      <td>suggestions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>212</td>\n",
       "      <td>plates</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>1528</td>\n",
       "      <td>inthe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>478</td>\n",
       "      <td>being</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>210</td>\n",
       "      <td>shrapnel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>484</td>\n",
       "      <td>accentuates</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1938</th>\n",
       "      <td>208</td>\n",
       "      <td>grafts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1939</th>\n",
       "      <td>1526</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>1527</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>972</td>\n",
       "      <td>mentally</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1942 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             words  w_count\n",
       "0      1608                 .    21069\n",
       "1      1667                no     6824\n",
       "2      1855               the     6596\n",
       "3      1370                is     4367\n",
       "4       538               are     4312\n",
       "5       910            normal     3548\n",
       "6        99                 ,     3534\n",
       "7      1380              xxxx     3080\n",
       "8      1089                of     3043\n",
       "9      1675               and     3029\n",
       "10     1434             acute     2871\n",
       "11     1853                or     2614\n",
       "12      694           pleural     2613\n",
       "13      405      pneumothorax     2407\n",
       "14      367             there     2361\n",
       "15     1649          effusion     2303\n",
       "16     1336             heart     2150\n",
       "17     1450             lungs     2093\n",
       "18      483              size     1916\n",
       "19      310             focal     1796\n",
       "20     1693             clear     1609\n",
       "21     1223                in     1561\n",
       "22     1591           disease     1546\n",
       "23      353   cardiopulmonary     1545\n",
       "24     1214         pulmonary     1528\n",
       "25      851            within     1522\n",
       "26     1127            limits     1448\n",
       "27      185             right     1282\n",
       "28      348              left     1121\n",
       "29     1082       abnormality     1106\n",
       "...     ...               ...      ...\n",
       "1912    201        definitive        1\n",
       "1913   1537               3.0        1\n",
       "1914   1043           respect        1\n",
       "1915    199            beyond        1\n",
       "1916   1540             lytic        1\n",
       "1917   1042            showed        1\n",
       "1918    197          detailed        1\n",
       "1919    492         primarily        1\n",
       "1920   1545    representative        1\n",
       "1921    493                l4        1\n",
       "1922    495          reversal        1\n",
       "1923    205       perforation        1\n",
       "1924    207  sternoclavicular        1\n",
       "1925   1051        unilateral        1\n",
       "1926   1059              orif        1\n",
       "1927    470         exchanged        1\n",
       "1928   1070           tenting        1\n",
       "1929   1511         clavicles        1\n",
       "1930   1063              duct        1\n",
       "1931    475        assessment        1\n",
       "1932   1518       suggestions        1\n",
       "1933    212            plates        1\n",
       "1934   1528             inthe        1\n",
       "1935    478             being        1\n",
       "1936    210          shrapnel        1\n",
       "1937    484       accentuates        1\n",
       "1938    208            grafts        1\n",
       "1939   1526           jewelry        1\n",
       "1940   1527                          1\n",
       "1941    972          mentally        1\n",
       "\n",
       "[1942 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1942 193\n"
     ]
    }
   ],
   "source": [
    "# word_count = {}\n",
    "# for word in vocab:\n",
    "#     if word not in word_count.keys():\n",
    "#         word_count[word]=1\n",
    "#     else:\n",
    "#         word_count[word]+=1\n",
    "# df_wcount = pd.DataFrame()\n",
    "# df_wcount['words']=word_count.keys()\n",
    "# df_wcount['w_count']=word_count.values()\n",
    "# df_wcount = df_wcount.sort_values(by='w_count',ascending=False).reset_index()\n",
    "# df_wcount['index']+=1\n",
    "\n",
    "# df_wcount.to_csv('../dataset/vocab_count.csv',index=False)\n",
    "df_wcount = pd.read_csv('../dataset/vocab_count.csv')\n",
    "\n",
    "display(df_wcount)\n",
    "vocab_size=df_wcount.shape[0]\n",
    "max_wlen = 193\n",
    "print(vocab_size,max_wlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 ['.', ',', '-', '..', \"'s\", ':', '(', ')', ' ', ';', '1.4', '>', '3.3', '1.9', '<', 'bilaterally.there', '1.2', '1.0', '2.1', 'p.m.', '1.7', '1.5', '3.5', '1.6', '3.7', '[', 't12-l1', '1.8', \"xxxx't\", '?', '2.0', '4.5', '2.2', '3.2', \"'re\", 'l1-l2', '4.6', 'xxxx.in', 'a.m.', 'l2-l3', '4.3', 'contour.unfolded', 'effusion.heart', '0.9', '5.9', '5.8', 'apex.there', '16.2', 'body(lateral', 'xxxx-', '2.no', '2.6', '1.severe', ']', '1.there', 'enlargement.prominence', '1.lucency', '6.0', '2.8', '1.3', '1.1', '3.chronic', 'limits.the', '2.5', 'limits.minimal', '4.8', 'normal.calcified', 'mediastinum.there', '7.0', '24.7', '3rd-5xxxx', '6.8', '3.0', '  ']\n"
     ]
    }
   ],
   "source": [
    "new_words= [word for word in df_wcount['words'].values if not word.isalnum()]\n",
    "print(len(new_words),new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'but': 1158,\n",
       " 'exists': 1873,\n",
       " 'around': 596,\n",
       " 'malignancy': 658,\n",
       " 'levels': 902,\n",
       " '  ': 1527,\n",
       " 'from': 576,\n",
       " 'radiation': 1210,\n",
       " '1.2': 882,\n",
       " 'sarcoid': 149,\n",
       " 'coarsened': 537,\n",
       " 'along': 982,\n",
       " 'processes': 1751,\n",
       " 'approximately': 1108,\n",
       " 'has': 299,\n",
       " 'graft': 259,\n",
       " 'diaphragms': 1001,\n",
       " 'symmetric': 970,\n",
       " 'location': 831,\n",
       " 'vasculatures': 74,\n",
       " 'hypoinflated': 1245,\n",
       " 'peripherally': 1593,\n",
       " 'basilar': 1162,\n",
       " 'up': 1542,\n",
       " 'significantly': 1887,\n",
       " 'removal': 1274,\n",
       " 'coronal': 911,\n",
       " 'radiograph': 1836,\n",
       " 'narrowed': 129,\n",
       " 'expected': 30,\n",
       " 'ordering': 35,\n",
       " 'irregularities': 1761,\n",
       " 'consider': 518,\n",
       " 'weeks': 1345,\n",
       " 'occluder': 995,\n",
       " 'incidental': 1342,\n",
       " 'described': 1198,\n",
       " 'lumbosacral': 1419,\n",
       " 'certified': 567,\n",
       " 'pm': 169,\n",
       " 'apex.there': 1920,\n",
       " 'magnification': 1842,\n",
       " 'pain': 1647,\n",
       " 'vertebroplasty': 1747,\n",
       " 'though': 282,\n",
       " 'confidently': 420,\n",
       " 'image': 710,\n",
       " 'abnormal': 942,\n",
       " '[': 305,\n",
       " 'neck': 1107,\n",
       " 'lordosis': 1775,\n",
       " 'positioning': 895,\n",
       " 'reflect': 859,\n",
       " 'osteophytic': 1222,\n",
       " 'potential': 291,\n",
       " 'annular': 388,\n",
       " 'film': 23,\n",
       " 'message': 1319,\n",
       " 'fibronodular': 48,\n",
       " 'attached': 579,\n",
       " 'obstruction': 1009,\n",
       " 'adenopathy': 1579,\n",
       " 'known': 246,\n",
       " 'centered': 1581,\n",
       " 'enlarged': 652,\n",
       " 't': 427,\n",
       " 'hyperlucent': 321,\n",
       " 'ij': 397,\n",
       " 'employed': 1587,\n",
       " 'redistribution': 796,\n",
       " 'distinct': 158,\n",
       " 'nodule': 526,\n",
       " 'parenchymal': 58,\n",
       " 'look': 818,\n",
       " 'suspected': 1125,\n",
       " 'concerning': 1917,\n",
       " 'time': 19,\n",
       " 'consolidating': 1111,\n",
       " 'pic': 1243,\n",
       " 'popliteal': 731,\n",
       " 'mass': 86,\n",
       " 'identified': 1804,\n",
       " 'ng': 969,\n",
       " 'projectional': 1694,\n",
       " 'cardio': 1486,\n",
       " 'history': 1119,\n",
       " 'previously': 1753,\n",
       " '3.chronic': 303,\n",
       " 'nonsclerotic': 1754,\n",
       " 'remainder': 1697,\n",
       " 'cta': 327,\n",
       " 'widened': 879,\n",
       " 'subcentimeter': 999,\n",
       " 'hyperdensity': 1832,\n",
       " 'xxxx.in': 860,\n",
       " 'into': 1867,\n",
       " 'clearing': 570,\n",
       " 'circular': 1478,\n",
       " 'disrupted': 1272,\n",
       " 'strongly': 1150,\n",
       " 'earlier': 558,\n",
       " '3.2': 624,\n",
       " 'fracture': 1468,\n",
       " 'pneumonia': 62,\n",
       " 'lymph': 1304,\n",
       " 'sent': 1645,\n",
       " 'artifact': 1791,\n",
       " 'habitus': 907,\n",
       " 'closure': 1296,\n",
       " \"xxxx't\": 138,\n",
       " 'tuberculous': 1838,\n",
       " 'radiopaque': 963,\n",
       " 'or': 1853,\n",
       " 'kyphosis': 798,\n",
       " 'removed': 1513,\n",
       " 'lucency': 1168,\n",
       " 'nodularity': 1261,\n",
       " 'entire': 1801,\n",
       " 'then': 10,\n",
       " 'bronchial': 513,\n",
       " 'vessel': 648,\n",
       " 'multilevel': 1126,\n",
       " 'chronicity': 672,\n",
       " 'fusion': 1805,\n",
       " 'date': 635,\n",
       " 'marrow': 586,\n",
       " 'persistent': 241,\n",
       " 'anchors': 100,\n",
       " 'seems': 1817,\n",
       " 'once': 761,\n",
       " 'midabdomen': 1627,\n",
       " 'bowel': 1067,\n",
       " 'bibasal': 594,\n",
       " 'segments': 937,\n",
       " 'lobar': 70,\n",
       " 'explained': 940,\n",
       " 'advanced': 1216,\n",
       " '19': 662,\n",
       " 'mentally': 972,\n",
       " 'crescentic': 1229,\n",
       " 'emphysema': 1112,\n",
       " 'lungs': 1450,\n",
       " 'all': 465,\n",
       " 'superiorly': 927,\n",
       " 'thanks': 759,\n",
       " 'tracking': 1756,\n",
       " 'underlying': 1760,\n",
       " 'studies': 687,\n",
       " 'improved': 1032,\n",
       " 'foot': 1171,\n",
       " 'noted': 431,\n",
       " 'thickening': 263,\n",
       " 'summation': 530,\n",
       " 'suggestions': 1518,\n",
       " 'allow': 583,\n",
       " 'limit': 21,\n",
       " 'prominent': 7,\n",
       " 'atrium': 135,\n",
       " 'hyperlucency': 1049,\n",
       " 'neoplastic': 1755,\n",
       " 'elevation': 1874,\n",
       " 'evaluate': 1630,\n",
       " 'xray': 1654,\n",
       " 'patchy': 1173,\n",
       " 'helpful': 1474,\n",
       " 'vein': 1453,\n",
       " 'superficial': 133,\n",
       " 'hyperostosis': 113,\n",
       " 'characteristic': 517,\n",
       " 'silhouettes': 186,\n",
       " '5.9': 1929,\n",
       " 'ring': 1029,\n",
       " 'visualization': 194,\n",
       " 'engorgement': 109,\n",
       " 'positional': 1590,\n",
       " 'filled': 1508,\n",
       " 'considering': 66,\n",
       " 'enlargement': 1388,\n",
       " 'zone': 1822,\n",
       " 'my': 155,\n",
       " 'maximal': 50,\n",
       " 'exam': 477,\n",
       " '2.no': 780,\n",
       " 'accessed': 1930,\n",
       " 'unclear': 415,\n",
       " 'phenomenon': 161,\n",
       " 'idiopathic': 600,\n",
       " 'accentuation': 1703,\n",
       " 'contrasted': 1689,\n",
       " '6th': 1671,\n",
       " 'nerve': 1860,\n",
       " 'silhouette': 1869,\n",
       " 'cystic': 1312,\n",
       " '16.2': 1795,\n",
       " 'mild': 403,\n",
       " 'diaphragm': 509,\n",
       " 'costodiaphragmatic': 461,\n",
       " 'trachea': 442,\n",
       " 'umbilical': 611,\n",
       " 'appreciated': 746,\n",
       " 'unfolded': 1413,\n",
       " 'op': 1408,\n",
       " 'follow': 1047,\n",
       " ';': 1512,\n",
       " 'readily': 90,\n",
       " 'poly': 1202,\n",
       " 'coracoclavicular': 245,\n",
       " 'orif': 1059,\n",
       " 'aeration': 813,\n",
       " 'vena': 1793,\n",
       " 'marked': 1028,\n",
       " 'units': 1338,\n",
       " 'tracheostomy': 735,\n",
       " 'having': 1852,\n",
       " 'non': 293,\n",
       " 'do': 1738,\n",
       " 'interval': 1561,\n",
       " 'elsewhere': 157,\n",
       " 'obese': 1572,\n",
       " 'evaluation': 1659,\n",
       " 'geographic': 46,\n",
       " 'cm': 1288,\n",
       " 'convincing': 1826,\n",
       " 'subcutaneous': 1748,\n",
       " 'chronically': 1057,\n",
       " 'dimension': 1479,\n",
       " 'become': 1550,\n",
       " 'malleoli': 888,\n",
       " 'dyspnea': 156,\n",
       " 'questioned': 501,\n",
       " 'caliber': 676,\n",
       " 'by': 809,\n",
       " 'expansile': 84,\n",
       " 'documented': 551,\n",
       " 'apparent': 333,\n",
       " 'osteopenia': 78,\n",
       " 'evaluated': 1295,\n",
       " 'diameter': 994,\n",
       " 'deformities': 696,\n",
       " 'relating': 606,\n",
       " 'demineralization': 1417,\n",
       " 'midclavicular': 627,\n",
       " 'ratio': 1906,\n",
       " 'narrowing': 885,\n",
       " 'parahilar': 1185,\n",
       " 'constellation': 617,\n",
       " 'bacterial': 844,\n",
       " 'acetabulum': 1851,\n",
       " 'high': 3,\n",
       " 'reveal': 339,\n",
       " 'rotatory': 721,\n",
       " 'cortex': 1809,\n",
       " 'some': 1710,\n",
       " 'congenital': 1653,\n",
       " 'outlining': 503,\n",
       " 'extraluminal': 1281,\n",
       " 'bronchiectatic': 40,\n",
       " 'proximal': 607,\n",
       " 'fissural': 14,\n",
       " '1.0': 22,\n",
       " 'almost': 1660,\n",
       " 'periphery': 218,\n",
       " 'showed': 1042,\n",
       " 'consolidation': 226,\n",
       " '4.8': 1026,\n",
       " 'asbestos': 239,\n",
       " 'lung': 866,\n",
       " 'heavily': 32,\n",
       " 'in': 1223,\n",
       " 'ensure': 1903,\n",
       " 'screw': 647,\n",
       " 'tunneled': 254,\n",
       " 'continues': 33,\n",
       " 'fissure': 887,\n",
       " 'embolization': 1405,\n",
       " 'exacerbation': 998,\n",
       " 'reformats': 1131,\n",
       " 'increased': 1175,\n",
       " 'reflecting': 337,\n",
       " 'buckling': 1386,\n",
       " 'reactive': 1348,\n",
       " 'ventricle': 1289,\n",
       " 'early': 26,\n",
       " 'favored': 308,\n",
       " 'intussusception': 890,\n",
       " 'superimposes': 1438,\n",
       " 'hypodense': 541,\n",
       " 'recommendations': 621,\n",
       " 'obviously': 1378,\n",
       " '1.there': 1163,\n",
       " 'pneumomediastinum': 200,\n",
       " 'compensatory': 1762,\n",
       " 'retrocrural': 1217,\n",
       " 'opacity': 520,\n",
       " 'wound': 1311,\n",
       " '.': 1608,\n",
       " 's1': 1194,\n",
       " 'postop': 821,\n",
       " 'decubitus': 849,\n",
       " 'assessment': 475,\n",
       " 'lobectomy': 569,\n",
       " 'part': 971,\n",
       " 'hemithorax': 545,\n",
       " 'fully': 1352,\n",
       " 'foci': 1523,\n",
       " 'measure': 917,\n",
       " 'limits.the': 1337,\n",
       " 'persist': 1551,\n",
       " 'injection': 656,\n",
       " 'innumerable': 913,\n",
       " '2': 996,\n",
       " 'paraesophageal': 230,\n",
       " 'sinuses': 841,\n",
       " 'retrosternally': 1577,\n",
       " 'xxxx': 1380,\n",
       " 'hilar': 204,\n",
       " 'today': 232,\n",
       " 'scattered': 944,\n",
       " 'difference': 262,\n",
       " 'definitive': 201,\n",
       " 'superior': 1055,\n",
       " 'enlarging': 89,\n",
       " 'cutaneous': 1364,\n",
       " 'midfoot': 1184,\n",
       " 'outside': 666,\n",
       " 'joint': 1221,\n",
       " 'displaced': 622,\n",
       " 'layering': 926,\n",
       " 'endseq': 463,\n",
       " 'aicd': 1788,\n",
       " 'postsurgical': 1582,\n",
       " 'copd': 1806,\n",
       " '11': 554,\n",
       " 'left': 348,\n",
       " 'posterobasal': 1351,\n",
       " 'stimulator': 107,\n",
       " 'osteophyte': 1718,\n",
       " '1a': 1631,\n",
       " 'chest': 1104,\n",
       " 'considerations': 993,\n",
       " 'shortening': 1854,\n",
       " 'involving': 953,\n",
       " 'abnormally': 304,\n",
       " 'suggest': 1560,\n",
       " 'specific': 318,\n",
       " 'technical': 1145,\n",
       " 'followed': 64,\n",
       " 'onset': 1290,\n",
       " 'see': 284,\n",
       " 'demonstrable': 1824,\n",
       " 'characterized': 891,\n",
       " 'benign': 392,\n",
       " 'complete': 1244,\n",
       " 'rotation': 634,\n",
       " 'cabg': 438,\n",
       " 'abnormality': 1082,\n",
       " 'that': 793,\n",
       " 'lymphoma': 1433,\n",
       " 'contain': 1575,\n",
       " 'typical': 587,\n",
       " 'better': 423,\n",
       " 'symptoms': 751,\n",
       " 'resolve': 1813,\n",
       " 'mri': 1571,\n",
       " 'bronchopulmonary': 425,\n",
       " 'injuries': 1465,\n",
       " '1.8': 173,\n",
       " 'additional': 575,\n",
       " 'bochdalek': 1395,\n",
       " 'initiated': 1003,\n",
       " 'postinflammatory': 1564,\n",
       " 'passes': 85,\n",
       " 'metacarpal': 1663,\n",
       " 'two': 574,\n",
       " 'can': 1704,\n",
       " 'stool': 1846,\n",
       " 'clavicle': 528,\n",
       " 'b': 760,\n",
       " 'masses': 192,\n",
       " 'splenic': 1367,\n",
       " 'sympathetic': 28,\n",
       " 'dextrocardia': 145,\n",
       " '2.6': 1848,\n",
       " 'ovoid': 1078,\n",
       " '7th': 1664,\n",
       " 'descending': 140,\n",
       " 'inhalational': 1354,\n",
       " 'calcific': 1481,\n",
       " 'indicated': 1902,\n",
       " 'true': 275,\n",
       " 'degenerated': 1714,\n",
       " 'stent': 720,\n",
       " 'bone': 957,\n",
       " 'overload': 1725,\n",
       " 'paraspinal': 72,\n",
       " 'traumatic': 605,\n",
       " 'dilation': 1876,\n",
       " 'vertically': 1618,\n",
       " 'developmental': 654,\n",
       " 'pancreatitis': 886,\n",
       " 'differences': 1890,\n",
       " 'projectile': 1774,\n",
       " 'sulcus': 1823,\n",
       " 'ankle': 546,\n",
       " 'space': 1870,\n",
       " 'heart': 1336,\n",
       " 'levoscoliosis': 929,\n",
       " 'except': 905,\n",
       " 'thoracotomy': 1303,\n",
       " 'stringy': 863,\n",
       " 'nasogastric': 1696,\n",
       " 'favoring': 718,\n",
       " 'acuity': 319,\n",
       " 'decrease': 807,\n",
       " 'articulation': 1294,\n",
       " 'infiltrative': 778,\n",
       " 'technologist': 802,\n",
       " 'scan': 722,\n",
       " 'expansion': 1012,\n",
       " 'epicardial': 1489,\n",
       " 'exposure': 387,\n",
       " 'central': 112,\n",
       " 'bilateral': 1573,\n",
       " 'effusion': 1649,\n",
       " 'nondiagnostic': 1557,\n",
       " 'hemoptysis': 1238,\n",
       " 'eventration': 1519,\n",
       " 'supraclavicular': 1203,\n",
       " 'tomogram': 159,\n",
       " 'biliary': 147,\n",
       " 'based': 1935,\n",
       " 'noncontrasted': 1563,\n",
       " 'centrally': 1117,\n",
       " 'pathologic': 1789,\n",
       " 'study': 443,\n",
       " 'cavitary': 1305,\n",
       " 'thin': 717,\n",
       " 'mediport': 13,\n",
       " 'they': 1687,\n",
       " 'side': 1603,\n",
       " 'mitral': 976,\n",
       " 'related': 306,\n",
       " 'intramedullary': 588,\n",
       " 'curvature': 1299,\n",
       " 'pelvis': 1901,\n",
       " 'post': 855,\n",
       " '1.5': 693,\n",
       " 'obscure': 677,\n",
       " 'terminates': 1679,\n",
       " 'retracted': 1180,\n",
       " 'sign': 1496,\n",
       " 'hyperexpansion': 1240,\n",
       " 'margins': 539,\n",
       " 'patient': 771,\n",
       " 'no': 1667,\n",
       " 'as': 257,\n",
       " 'interstitium': 1484,\n",
       " 'dedicated': 1418,\n",
       " 'we': 948,\n",
       " 'interlobar': 1269,\n",
       " 'tubing': 1896,\n",
       " 'mixed': 889,\n",
       " 'again': 1536,\n",
       " 'morbidly': 182,\n",
       " 'femur': 977,\n",
       " 'old': 464,\n",
       " 'glenoid': 320,\n",
       " 'visualized': 733,\n",
       " 'bilaterally': 1124,\n",
       " 'cavoatrial': 1885,\n",
       " 'hemiabdomen': 1207,\n",
       " 'amount': 1783,\n",
       " 'flexure': 514,\n",
       " 'excluded': 362,\n",
       " 'prominence': 1467,\n",
       " 'electrodes': 98,\n",
       " 'airspace': 338,\n",
       " 'dense': 1097,\n",
       " 'separation': 1878,\n",
       " 'thought': 702,\n",
       " 'gastric': 1457,\n",
       " 'balloon': 352,\n",
       " '1': 408,\n",
       " 'worst': 533,\n",
       " 'startseq': 105,\n",
       " 'suspect': 41,\n",
       " 'alternatively': 1256,\n",
       " 'clavicular': 198,\n",
       " 'interface': 1422,\n",
       " 'a': 273,\n",
       " 'cardiothymic': 143,\n",
       " 'be': 1135,\n",
       " 'regarding': 787,\n",
       " 'breast': 1722,\n",
       " 'icd': 1731,\n",
       " 'callus': 1148,\n",
       " 'appreciable': 1250,\n",
       " 'there': 367,\n",
       " 'intrathoracic': 1639,\n",
       " 'lytic': 1540,\n",
       " 'definitely': 82,\n",
       " 'it': 1379,\n",
       " 'aerated': 370,\n",
       " 'peritracheal': 716,\n",
       " 'define': 1763,\n",
       " 'increase': 1736,\n",
       " 'entirely': 1705,\n",
       " 'please': 856,\n",
       " 'seen': 1597,\n",
       " 'evolving': 1711,\n",
       " 'reasonable': 529,\n",
       " 'being': 478,\n",
       " 'magnified': 912,\n",
       " 'large': 1200,\n",
       " 'radiography': 1786,\n",
       " 'represents': 424,\n",
       " 'suggested': 1008,\n",
       " 'intravenous': 128,\n",
       " 'hemidiaphragms': 552,\n",
       " 'radiographic': 1904,\n",
       " 'retention': 233,\n",
       " 'suggestion': 45,\n",
       " 'partly': 1827,\n",
       " 'discrete': 893,\n",
       " 'expiratory': 1549,\n",
       " 'opaque': 565,\n",
       " 'aorto': 1661,\n",
       " 'inflammatory': 108,\n",
       " 'superimposition': 1157,\n",
       " 'small': 737,\n",
       " 'secondary': 347,\n",
       " 'ago': 1061,\n",
       " 'dr': 1050,\n",
       " '?': 1830,\n",
       " 'pericardial': 1578,\n",
       " 'uncalcified': 1206,\n",
       " 'endplate': 271,\n",
       " 'resultant': 568,\n",
       " 'evidenced': 1096,\n",
       " 'forearm': 1897,\n",
       " 'stents': 34,\n",
       " 'maintained': 1493,\n",
       " 'sternum': 681,\n",
       " 'thorax': 1488,\n",
       " 'necks': 379,\n",
       " 'aspergilloma': 94,\n",
       " 'punctate': 757,\n",
       " '5th': 1407,\n",
       " 'compressive': 77,\n",
       " 'resolving': 1825,\n",
       " 'width': 636,\n",
       " 'empyema': 1934,\n",
       " 'months': 956,\n",
       " 'shortness': 1629,\n",
       " 'intraperitoneal': 734,\n",
       " 'anteriorly': 37,\n",
       " 'tibial': 17,\n",
       " 'first': 1875,\n",
       " 'jugular': 1270,\n",
       " 'blunted': 1471,\n",
       " 'implantable': 1398,\n",
       " 'subclavian': 1520,\n",
       " '5': 1735,\n",
       " 'erosions': 390,\n",
       " 'grade': 1190,\n",
       " 'viral': 359,\n",
       " 'costicartilage': 1188,\n",
       " 'cervicothoracic': 63,\n",
       " 'electronic': 1284,\n",
       " 'cxr': 1879,\n",
       " 'incomplete': 1449,\n",
       " 'plates': 212,\n",
       " 'hyperaerated': 523,\n",
       " 'developed': 1562,\n",
       " 'primary': 1314,\n",
       " 'volume': 1062,\n",
       " 'normal.calcified': 167,\n",
       " 'bullae': 1882,\n",
       " 'obscures': 1066,\n",
       " 'last': 1490,\n",
       " 'aspect': 1863,\n",
       " 'diffusely': 571,\n",
       " 'endplates': 400,\n",
       " '02': 805,\n",
       " '1.4': 154,\n",
       " 'overlay': 1907,\n",
       " 'postobstructive': 870,\n",
       " 'are': 538,\n",
       " 'account': 380,\n",
       " 'segmental': 49,\n",
       " 'infections': 44,\n",
       " 'performance': 1607,\n",
       " 't8': 1048,\n",
       " 'osteophytes': 928,\n",
       " 'evident': 1323,\n",
       " 'distributed': 229,\n",
       " 'whose': 1251,\n",
       " 'myeloma': 1273,\n",
       " 'lymphoid': 1673,\n",
       " 'femoral': 213,\n",
       " 'rectal': 1283,\n",
       " 'gastrostomy': 371,\n",
       " 'pretracheal': 25,\n",
       " 'lingula': 1278,\n",
       " 'maximum': 1114,\n",
       " 'collecting': 631,\n",
       " 'p': 651,\n",
       " 'metastases': 1919,\n",
       " 'atelectatic': 317,\n",
       " 'would': 626,\n",
       " 'moved': 1616,\n",
       " 'dilated': 1583,\n",
       " 'reduced': 615,\n",
       " 'bronchitis': 116,\n",
       " 'catheter': 1219,\n",
       " 'adjacent': 1189,\n",
       " 'reticular': 1684,\n",
       " 'a.m.': 344,\n",
       " 'inferior': 1331,\n",
       " 'suggestive': 361,\n",
       " 'desired': 500,\n",
       " 'humeral': 57,\n",
       " 'above': 1586,\n",
       " 'obscuring': 892,\n",
       " 'hematoma': 1335,\n",
       " 'atherosclerotic': 1464,\n",
       " 'cardiomegaly': 1525,\n",
       " 'postprocedural': 272,\n",
       " 't4': 165,\n",
       " 'osteopenic': 131,\n",
       " 'measures': 469,\n",
       " '10': 714,\n",
       " 'granulomas': 1371,\n",
       " 'particularly': 1308,\n",
       " 'patellofemoral': 349,\n",
       " 'hindfoot': 1276,\n",
       " 'spasm': 1730,\n",
       " 'bilaterally.there': 614,\n",
       " 'pleura': 1719,\n",
       " 'body(lateral': 67,\n",
       " 'scoliosis': 646,\n",
       " 'fullness': 915,\n",
       " 'biventricular': 612,\n",
       " 'larger': 1044,\n",
       " 'improving': 83,\n",
       " 'residuals': 106,\n",
       " 'status': 1346,\n",
       " 'radiodense': 770,\n",
       " 'tips': 1765,\n",
       " 'subphrenic': 376,\n",
       " 'diminished': 118,\n",
       " 'verification': 705,\n",
       " 'vascular': 1543,\n",
       " 'infrahilar': 1363,\n",
       " 'coarse': 1541,\n",
       " 'workup': 1916,\n",
       " 'disease': 1591,\n",
       " 'films': 1472,\n",
       " \"'re\": 700,\n",
       " 'comparisons': 222,\n",
       " 'ectasia': 826,\n",
       " 'fungal': 992,\n",
       " 'laparoscopic': 417,\n",
       " 'transverse': 1267,\n",
       " 'provide': 374,\n",
       " 'exchanged': 470,\n",
       " 'aorta': 1657,\n",
       " '8th': 550,\n",
       " 'myocardial': 251,\n",
       " 'hypertension': 897,\n",
       " 'repeated': 394,\n",
       " 'caval': 279,\n",
       " 'supine': 521,\n",
       " 'shoulder': 1641,\n",
       " 'synovial': 1692,\n",
       " 'artery': 1539,\n",
       " 'junction': 842,\n",
       " '6.0': 266,\n",
       " 'vascularity': 445,\n",
       " 'lumpectomy': 1310,\n",
       " 'wedging': 1103,\n",
       " 'limits': 1127,\n",
       " 'goiter': 1041,\n",
       " 'additionally': 1797,\n",
       " 'head': 1262,\n",
       " 'pattern': 1040,\n",
       " 'mediastinum': 876,\n",
       " 'possibly': 1883,\n",
       " 'bulge': 1701,\n",
       " 'external': 1857,\n",
       " 'distortion': 916,\n",
       " 'third': 312,\n",
       " 'artifactually': 346,\n",
       " 'term': 130,\n",
       " 'hyperinflation': 950,\n",
       " 'changes': 214,\n",
       " 'organomegaly': 823,\n",
       " 'will': 1010,\n",
       " 'piercing': 1149,\n",
       " 'fibrosis': 1534,\n",
       " 'attenuation': 827,\n",
       " 'parenchyma': 755,\n",
       " 'beyond': 199,\n",
       " 'without': 616,\n",
       " 'performed': 785,\n",
       " 'receipt': 244,\n",
       " 'attributable': 496,\n",
       " 'beneath': 1034,\n",
       " 'reflex': 1414,\n",
       " 'atypical': 1442,\n",
       " 'cardiomediastinal': 762,\n",
       " 'lucent': 1033,\n",
       " 'purpose': 365,\n",
       " 'esophagectomy': 1740,\n",
       " 'artifactual': 1307,\n",
       " 'markers': 120,\n",
       " 'primarily': 492,\n",
       " 'underinflation': 918,\n",
       " 'subpleural': 840,\n",
       " 'remain': 298,\n",
       " 'subsequent': 490,\n",
       " 'granulomata': 1424,\n",
       " 'six': 1785,\n",
       " 'cyst': 101,\n",
       " 'smooth': 467,\n",
       " 'osteochondromatosis': 507,\n",
       " 'crosstable': 1376,\n",
       " 'replacement': 1656,\n",
       " 'prevertebral': 286,\n",
       " 'feeding': 667,\n",
       " 'hypertrophy': 803,\n",
       " 'fractured': 949,\n",
       " 'acute': 1434,\n",
       " 'primordial': 1437,\n",
       " 'lucencies': 93,\n",
       " 'nipple': 979,\n",
       " 'fourth': 1231,\n",
       " 'relates': 724,\n",
       " 'shadows': 447,\n",
       " 'continued': 180,\n",
       " 'progression': 1925,\n",
       " 'cardiopulmonary': 353,\n",
       " 'foreign': 1750,\n",
       " 'grafts': 208,\n",
       " 'asymmetric': 1759,\n",
       " 'rule': 1741,\n",
       " 'spondylitic': 595,\n",
       " 'including': 1377,\n",
       " 'demonstrates': 448,\n",
       " 'cardiomyopathy': 1912,\n",
       " 'differential': 1193,\n",
       " 'crowding': 409,\n",
       " 'syndesmophyte': 1095,\n",
       " 'lines': 1013,\n",
       " 'i': 1892,\n",
       " 'determined': 462,\n",
       " 'comparison': 1613,\n",
       " 'bridging': 1087,\n",
       " 'found': 1329,\n",
       " 'essentially': 1662,\n",
       " 'difficult': 1515,\n",
       " 'also': 765,\n",
       " 'shift': 144,\n",
       " 'years': 1462,\n",
       " 'fibrotic': 1818,\n",
       " 'upward': 894,\n",
       " 'healing': 1548,\n",
       " 'intrapulmonary': 1636,\n",
       " 'cleared': 1159,\n",
       " 'raising': 1728,\n",
       " 'obscuration': 1871,\n",
       " 'indwelling': 1940,\n",
       " 'tortuosity': 549,\n",
       " 'already': 767,\n",
       " 'spinal': 253,\n",
       " 'highly': 1122,\n",
       " 'crosses': 817,\n",
       " 'exaggerated': 834,\n",
       " 'nonspecific': 453,\n",
       " 'evidence': 1652,\n",
       " 'globular': 1181,\n",
       " 'either': 1872,\n",
       " 'vasculature': 1886,\n",
       " 'shunt': 289,\n",
       " 'amputation': 582,\n",
       " 'collapse': 1347,\n",
       " 'obstructive': 1,\n",
       " 'bipolar': 625,\n",
       " 'recurrent': 502,\n",
       " 'densities': 422,\n",
       " 'include': 906,\n",
       " 'arm': 847,\n",
       " 'to': 640,\n",
       " 'reversal': 495,\n",
       " 'br': 964,\n",
       " '1.severe': 629,\n",
       " 'cuffing': 590,\n",
       " 'hand': 1086,\n",
       " 'correlate': 5,\n",
       " 'substernal': 1767,\n",
       " 'trapping': 519,\n",
       " 'pleuritis': 1787,\n",
       " '>': 313,\n",
       " 'ordered': 325,\n",
       " 'if': 1589,\n",
       " 'outward': 1350,\n",
       " 'until': 1459,\n",
       " 'residual': 830,\n",
       " 'uncertain': 433,\n",
       " 'question': 1074,\n",
       " 'contusion': 1622,\n",
       " 'telemetry': 839,\n",
       " 'gross': 1828,\n",
       " 'most': 1165,\n",
       " '010': 96,\n",
       " 'midline': 747,\n",
       " 'besides': 858,\n",
       " 'partial': 1800,\n",
       " 'intrathecal': 1446,\n",
       " 'sagittal': 1257,\n",
       " 'pelvic': 1265,\n",
       " '2.5': 1241,\n",
       " 'questions': 862,\n",
       " 'radiographs': 1038,\n",
       " 'denser': 1686,\n",
       " 'convexity': 1031,\n",
       " 'leads': 1253,\n",
       " '12': 1727,\n",
       " 'simply': 1790,\n",
       " '4.6': 81,\n",
       " ')': 661,\n",
       " 'concern': 777,\n",
       " 'component': 1201,\n",
       " 'densely': 1259,\n",
       " 'cardia': 1341,\n",
       " 'valve': 920,\n",
       " 'reticulonodular': 742,\n",
       " 'core': 345,\n",
       " 'postradiation': 1829,\n",
       " 'recess': 11,\n",
       " 'radiating': 980,\n",
       " 'interruption': 880,\n",
       " 'mediastinum.there': 160,\n",
       " 'impression': 43,\n",
       " 'monitor': 691,\n",
       " 'fluid': 1522,\n",
       " 'carinatum': 1027,\n",
       " 'total': 1638,\n",
       " 'about': 1005,\n",
       " 'which': 95,\n",
       " 'area': 396,\n",
       " 't10': 1025,\n",
       " 'xxxx-': 845,\n",
       " 'abdominal': 1866,\n",
       " 'narrow': 650,\n",
       " 'otherwise': 1385,\n",
       " 'repeat': 1362,\n",
       " 'l1': 1212,\n",
       " 'tortuous': 292,\n",
       " 'interspace': 166,\n",
       " 'contour': 592,\n",
       " 'uniformly': 903,\n",
       " 'disc': 800,\n",
       " 'largely': 221,\n",
       " 'senescent': 450,\n",
       " 'pleuroparenchymal': 938,\n",
       " 'epipericardial': 1808,\n",
       " 'disruption': 1182,\n",
       " 'size': 483,\n",
       " 'scar': 206,\n",
       " 'overlap': 1143,\n",
       " 'slightly': 1844,\n",
       " 'consolidations': 256,\n",
       " 'were': 591,\n",
       " 'considerably': 418,\n",
       " 'result': 1431,\n",
       " 'between': 1065,\n",
       " 'more': 1700,\n",
       " 'obliquely': 1547,\n",
       " 'occult': 1670,\n",
       " 'origin': 748,\n",
       " 'sternotomy': 1260,\n",
       " 'tissue': 137,\n",
       " 'breath': 678,\n",
       " 'called': 871,\n",
       " 'scars': 1781,\n",
       " 'definite': 869,\n",
       " 'right': 185,\n",
       " 'coils': 1435,\n",
       " 'sized': 486,\n",
       " 'tendinitis': 247,\n",
       " 'indeterminant': 1737,\n",
       " 'cardiophrenic': 877,\n",
       " 'deviation': 1423,\n",
       " 'venous': 127,\n",
       " 'arthroplasty': 1399,\n",
       " 'enthesophyte': 1672,\n",
       " 'towards': 482,\n",
       " 'measuring': 1046,\n",
       " 'indeterminate': 1713,\n",
       " 'moderate': 481,\n",
       " 'postinfectious': 297,\n",
       " 'l1-l2': 1113,\n",
       " 'muscle': 1228,\n",
       " 'recent': 544,\n",
       " 'p.m.': 1196,\n",
       " 'osseus': 1183,\n",
       " 'axillary': 1019,\n",
       " 'unknown': 1814,\n",
       " 'totally': 314,\n",
       " 'combination': 163,\n",
       " 'accepted': 236,\n",
       " 'stabilization': 560,\n",
       " 'platelike': 179,\n",
       " 'throughout': 270,\n",
       " 'loculated': 768,\n",
       " 'consideration': 1440,\n",
       " 'these': 1052,\n",
       " 'avn': 1683,\n",
       " 'sclerosis': 1816,\n",
       " 'tricompartmental': 444,\n",
       " 'line': 822,\n",
       " 'startseqthe': 1375,\n",
       " 'worse': 255,\n",
       " 'clinical': 1455,\n",
       " 'shielded': 322,\n",
       " 'establish': 1382,\n",
       " 'nondisplaced': 1039,\n",
       " 'malalignment': 134,\n",
       " 'bordered': 816,\n",
       " 'remodeling': 1677,\n",
       " 'care': 1834,\n",
       " 'circumscribed': 597,\n",
       " 'fold': 779,\n",
       " 'sequelae': 644,\n",
       " 'projects': 1144,\n",
       " 'minimal': 170,\n",
       " 'diffuse': 1076,\n",
       " 'radiologist': 1698,\n",
       " 'suture': 268,\n",
       " 'pronounced': 814,\n",
       " 'defect': 961,\n",
       " 'cortical': 1942,\n",
       " 'extension': 686,\n",
       " 'case': 56,\n",
       " 'costophrenic': 110,\n",
       " 'clavicles': 1511,\n",
       " 'undergone': 865,\n",
       " '2.2': 1154,\n",
       " 'midlung': 1359,\n",
       " 'aorticopulmonary': 440,\n",
       " 'other': 1115,\n",
       " 'glenohumeral': 1404,\n",
       " 'appear': 637,\n",
       " 'bases': 1678,\n",
       " 'ap': 1326,\n",
       " 'defibrillator': 296,\n",
       " '5.8': 670,\n",
       " 'extremely': 61,\n",
       " 'rods': 653,\n",
       " 'emphysematous': 988,\n",
       " 'possibility': 1381,\n",
       " 'muscular': 176,\n",
       " 'injury': 1625,\n",
       " 'base': 638,\n",
       " 'cholecystectomy': 884,\n",
       " 'numerous': 1142,\n",
       " 'subpulmonic': 54,\n",
       " 'mildly': 267,\n",
       " 'spiculated': 1792,\n",
       " 'diaphragmatic': 1152,\n",
       " 'iv': 1780,\n",
       " 'formations': 589,\n",
       " 'portable': 1425,\n",
       " 'now': 1179,\n",
       " 'detail': 47,\n",
       " 'exact': 1355,\n",
       " 'ct': 1643,\n",
       " 'cartilages': 1706,\n",
       " 'sacroiliac': 1555,\n",
       " 'top': 250,\n",
       " 'juxtahilar': 835,\n",
       " 'ligamentous': 806,\n",
       " 'subchondral': 1864,\n",
       " 'approximating': 1080,\n",
       " 'stated': 900,\n",
       " 'behind': 542,\n",
       " 'anomaly': 623,\n",
       " 'irregularity': 1366,\n",
       " 'effusions': 1291,\n",
       " 'normally': 488,\n",
       " 'change': 1248,\n",
       " 'characterization': 1339,\n",
       " 'fissures': 363,\n",
       " 'incidentally': 1102,\n",
       " 'department': 215,\n",
       " 'ureteral': 1232,\n",
       " 'hip': 1264,\n",
       " 'costochondral': 12,\n",
       " 'articular': 460,\n",
       " ...}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{1: 'obstructive',\n",
       " 2: 'lordotic',\n",
       " 3: 'high',\n",
       " 4: '38',\n",
       " 5: 'correlate',\n",
       " 6: 'strandy',\n",
       " 7: 'prominent',\n",
       " 8: 'inability',\n",
       " 9: 'discuss',\n",
       " 10: 'then',\n",
       " 11: 'recess',\n",
       " 12: 'costochondral',\n",
       " 13: 'mediport',\n",
       " 14: 'fissural',\n",
       " 15: 'retained',\n",
       " 16: 'nonrib',\n",
       " 17: 'tibial',\n",
       " 18: 'clips',\n",
       " 19: 'time',\n",
       " 20: 'confirmation',\n",
       " 21: 'limit',\n",
       " 22: '1.0',\n",
       " 23: 'film',\n",
       " 24: 'valvuloplasty',\n",
       " 25: 'pretracheal',\n",
       " 26: 'early',\n",
       " 27: 'bibasilar',\n",
       " 28: 'sympathetic',\n",
       " 29: 'verify',\n",
       " 30: 'expected',\n",
       " 31: 'prostheses',\n",
       " 32: 'heavily',\n",
       " 33: 'continues',\n",
       " 34: 'stents',\n",
       " 35: 'ordering',\n",
       " 36: 'enchondroma',\n",
       " 37: 'anteriorly',\n",
       " 38: 'hypoventilation',\n",
       " 39: 'grossly',\n",
       " 40: 'bronchiectatic',\n",
       " 41: 'suspect',\n",
       " 42: 'kub',\n",
       " 43: 'impression',\n",
       " 44: 'infections',\n",
       " 45: 'suggestion',\n",
       " 46: 'geographic',\n",
       " 47: 'detail',\n",
       " 48: 'fibronodular',\n",
       " 49: 'segmental',\n",
       " 50: 'maximal',\n",
       " 51: 'islands',\n",
       " 52: 'osseous',\n",
       " 53: 'similar',\n",
       " 54: 'subpulmonic',\n",
       " 55: 'xxxxpm',\n",
       " 56: 'case',\n",
       " 57: 'humeral',\n",
       " 58: 'parenchymal',\n",
       " 59: 'appears',\n",
       " 60: 'note',\n",
       " 61: 'extremely',\n",
       " 62: 'pneumonia',\n",
       " 63: 'cervicothoracic',\n",
       " 64: 'followed',\n",
       " 65: 'horizontal',\n",
       " 66: 'considering',\n",
       " 67: 'body(lateral',\n",
       " 68: 'aneurysmal',\n",
       " 69: 'clarification',\n",
       " 70: 'lobar',\n",
       " 71: 'brachiocephalic',\n",
       " 72: 'paraspinal',\n",
       " 73: 'online',\n",
       " 74: 'vasculatures',\n",
       " 75: 'therapy',\n",
       " 76: 'exist',\n",
       " 77: 'compressive',\n",
       " 78: 'osteopenia',\n",
       " 79: 'resection',\n",
       " 80: 'dextroconvex',\n",
       " 81: '4.6',\n",
       " 82: 'definitely',\n",
       " 83: 'improving',\n",
       " 84: 'expansile',\n",
       " 85: 'passes',\n",
       " 86: 'mass',\n",
       " 87: 'end',\n",
       " 88: 'notified',\n",
       " 89: 'enlarging',\n",
       " 90: 'readily',\n",
       " 91: 'prosthetic',\n",
       " 92: 'critical',\n",
       " 93: 'lucencies',\n",
       " 94: 'aspergilloma',\n",
       " 95: 'which',\n",
       " 96: '010',\n",
       " 97: 'infectious',\n",
       " 98: 'electrodes',\n",
       " 99: ',',\n",
       " 100: 'anchors',\n",
       " 101: 'cyst',\n",
       " 102: 'remote',\n",
       " 103: 'institution',\n",
       " 104: 'hyperexpanded',\n",
       " 105: 'startseq',\n",
       " 106: 'residuals',\n",
       " 107: 'stimulator',\n",
       " 108: 'inflammatory',\n",
       " 109: 'engorgement',\n",
       " 110: 'costophrenic',\n",
       " 111: 'destructive',\n",
       " 112: 'central',\n",
       " 113: 'hyperostosis',\n",
       " 114: 'appearing',\n",
       " 115: 'surgery',\n",
       " 116: 'bronchitis',\n",
       " 117: 'spaces',\n",
       " 118: 'diminished',\n",
       " 119: 'consists',\n",
       " 120: 'markers',\n",
       " 121: 'vasculaturity',\n",
       " 122: 'an',\n",
       " 123: 'neurostimulator',\n",
       " 124: 'preoperative',\n",
       " 125: ' ',\n",
       " 126: 'views',\n",
       " 127: 'venous',\n",
       " 128: 'intravenous',\n",
       " 129: 'narrowed',\n",
       " 130: 'term',\n",
       " 131: 'osteopenic',\n",
       " 132: 'loops',\n",
       " 133: 'superficial',\n",
       " 134: 'malalignment',\n",
       " 135: 'atrium',\n",
       " 136: 'hyper',\n",
       " 137: 'tissue',\n",
       " 138: \"xxxx't\",\n",
       " 139: 'midshaft',\n",
       " 140: 'descending',\n",
       " 141: 'vague',\n",
       " 142: 'confluence',\n",
       " 143: 'cardiothymic',\n",
       " 144: 'shift',\n",
       " 145: 'dextrocardia',\n",
       " 146: '2v',\n",
       " 147: 'biliary',\n",
       " 148: 'hypoventilatory',\n",
       " 149: 'sarcoid',\n",
       " 150: 'referring',\n",
       " 151: 'recurrence',\n",
       " 152: 'number',\n",
       " 153: 'concomitant',\n",
       " 154: '1.4',\n",
       " 155: 'my',\n",
       " 156: 'dyspnea',\n",
       " 157: 'elsewhere',\n",
       " 158: 'distinct',\n",
       " 159: 'tomogram',\n",
       " 160: 'mediastinum.there',\n",
       " 161: 'phenomenon',\n",
       " 162: 'granuloma',\n",
       " 163: 'combination',\n",
       " 164: 'arteries',\n",
       " 165: 't4',\n",
       " 166: 'interspace',\n",
       " 167: 'normal.calcified',\n",
       " 168: 'available',\n",
       " 169: 'pm',\n",
       " 170: 'minimal',\n",
       " 171: 'vp',\n",
       " 172: 'chin',\n",
       " 173: '1.8',\n",
       " 174: 'projection',\n",
       " 175: 'convex',\n",
       " 176: 'muscular',\n",
       " 177: 'acknowledged',\n",
       " 178: 'currently',\n",
       " 179: 'platelike',\n",
       " 180: 'continued',\n",
       " 181: 'exchange',\n",
       " 182: 'morbidly',\n",
       " 183: '1.9',\n",
       " 184: 'bodies',\n",
       " 185: 'right',\n",
       " 186: 'silhouettes',\n",
       " 187: 'submitted',\n",
       " 188: 'recommended',\n",
       " 189: 'adequately',\n",
       " 190: 'diagnostic',\n",
       " 191: 'short',\n",
       " 192: 'masses',\n",
       " 193: 'chondral',\n",
       " 194: 'visualization',\n",
       " 195: 'surface',\n",
       " 196: 'only',\n",
       " 197: 'detailed',\n",
       " 198: 'clavicular',\n",
       " 199: 'beyond',\n",
       " 200: 'pneumomediastinum',\n",
       " 201: 'definitive',\n",
       " 202: 'unfolding',\n",
       " 203: 'its',\n",
       " 204: 'hilar',\n",
       " 205: 'perforation',\n",
       " 206: 'scar',\n",
       " 207: 'sternoclavicular',\n",
       " 208: 'grafts',\n",
       " 209: 'hiatus',\n",
       " 210: 'shrapnel',\n",
       " 211: 'included',\n",
       " 212: 'plates',\n",
       " 213: 'femoral',\n",
       " 214: 'changes',\n",
       " 215: 'department',\n",
       " 216: 'maybe',\n",
       " 217: '2nd',\n",
       " 218: 'periphery',\n",
       " 219: 'ribs',\n",
       " 220: 'morgagni',\n",
       " 221: 'largely',\n",
       " 222: 'comparisons',\n",
       " 223: 'lesions',\n",
       " 224: 'pectus',\n",
       " 225: '2.0',\n",
       " 226: 'consolidation',\n",
       " 227: 'thoracic',\n",
       " 228: 'osteoarthritis',\n",
       " 229: 'distributed',\n",
       " 230: 'paraesophageal',\n",
       " 231: 'dextrocurvature',\n",
       " 232: 'today',\n",
       " 233: 'retention',\n",
       " 234: '1.7',\n",
       " 235: 'thickness',\n",
       " 236: 'accepted',\n",
       " 237: 'hemodialysis',\n",
       " 238: 'clinically',\n",
       " 239: 'asbestos',\n",
       " 240: 'few',\n",
       " 241: 'persistent',\n",
       " 242: 'calcaneal',\n",
       " 243: 'carcinoma',\n",
       " 244: 'receipt',\n",
       " 245: 'coracoclavicular',\n",
       " 246: 'known',\n",
       " 247: 'tendinitis',\n",
       " 248: 'multilobar',\n",
       " 249: 'humerus',\n",
       " 250: 'top',\n",
       " 251: 'myocardial',\n",
       " 252: 'ekg',\n",
       " 253: 'spinal',\n",
       " 254: 'tunneled',\n",
       " 255: 'worse',\n",
       " 256: 'consolidations',\n",
       " 257: 'as',\n",
       " 258: 'thready',\n",
       " 259: 'graft',\n",
       " 260: 'fixation',\n",
       " 261: 'parapneumonic',\n",
       " 262: 'difference',\n",
       " 263: 'thickening',\n",
       " 264: 'computed',\n",
       " 265: 'lv',\n",
       " 266: '6.0',\n",
       " 267: 'mildly',\n",
       " 268: 'suture',\n",
       " 269: 'obvious',\n",
       " 270: 'throughout',\n",
       " 271: 'endplate',\n",
       " 272: 'postprocedural',\n",
       " 273: 'a',\n",
       " 274: 'corticated',\n",
       " 275: 'true',\n",
       " 276: 'deformity',\n",
       " 277: 'three',\n",
       " 278: 'plateaus',\n",
       " 279: 'caval',\n",
       " 280: 'obliteration',\n",
       " 281: 'distending',\n",
       " 282: 'though',\n",
       " 283: 'bullous',\n",
       " 284: 'see',\n",
       " 285: '12th',\n",
       " 286: 'prevertebral',\n",
       " 287: 'hiatal',\n",
       " 288: 'reaction',\n",
       " 289: 'shunt',\n",
       " 290: 'compatible',\n",
       " 291: 'potential',\n",
       " 292: 'tortuous',\n",
       " 293: 'non',\n",
       " 294: 'midthoracic',\n",
       " 295: 'dissection',\n",
       " 296: 'defibrillator',\n",
       " 297: 'postinfectious',\n",
       " 298: 'remain',\n",
       " 299: 'has',\n",
       " 300: 'worsening',\n",
       " 301: '13',\n",
       " 302: 'alveolar',\n",
       " 303: '3.chronic',\n",
       " 304: 'abnormally',\n",
       " 305: '[',\n",
       " 306: 'related',\n",
       " 307: 'engorged',\n",
       " 308: 'favored',\n",
       " 309: 'single',\n",
       " 310: 'focal',\n",
       " 311: 'nonenlarged',\n",
       " 312: 'third',\n",
       " 313: '>',\n",
       " 314: 'totally',\n",
       " 315: 'addended',\n",
       " 316: 'cholelithiasis',\n",
       " 317: 'atelectatic',\n",
       " 318: 'specific',\n",
       " 319: 'acuity',\n",
       " 320: 'glenoid',\n",
       " 321: 'hyperlucent',\n",
       " 322: 'shielded',\n",
       " 323: 'indistinctness',\n",
       " 324: 'noncalcified',\n",
       " 325: 'ordered',\n",
       " 326: 'second',\n",
       " 327: 'cta',\n",
       " 328: 'presence',\n",
       " 329: 'bronchovascular',\n",
       " 330: 'addition',\n",
       " 331: 'suited',\n",
       " 332: 'reviewed',\n",
       " 333: 'apparent',\n",
       " 334: '3.3',\n",
       " 335: 'sided',\n",
       " 336: 'interspaces',\n",
       " 337: 'reflecting',\n",
       " 338: 'airspace',\n",
       " 339: 'reveal',\n",
       " 340: 'postoperative',\n",
       " 341: 'calcium',\n",
       " 342: 'tapering',\n",
       " 343: '3.7',\n",
       " 344: 'a.m.',\n",
       " 345: 'core',\n",
       " 346: 'artifactually',\n",
       " 347: 'secondary',\n",
       " 348: 'left',\n",
       " 349: 'patellofemoral',\n",
       " 350: ':',\n",
       " 351: 'swimmers',\n",
       " 352: 'balloon',\n",
       " 353: 'cardiopulmonary',\n",
       " 354: '2.8',\n",
       " 355: '1.3',\n",
       " 356: 'angulate',\n",
       " 357: 'results',\n",
       " 358: 'ventricular',\n",
       " 359: 'viral',\n",
       " 360: 'svc',\n",
       " 361: 'suggestive',\n",
       " 362: 'excluded',\n",
       " 363: 'fissures',\n",
       " 364: 'traverses',\n",
       " 365: 'purpose',\n",
       " 366: 'perhaps',\n",
       " 367: 'there',\n",
       " 368: 'immediately',\n",
       " 369: 'regions',\n",
       " 370: 'aerated',\n",
       " 371: 'gastrostomy',\n",
       " 372: '4',\n",
       " 373: 'communicated',\n",
       " 374: 'provide',\n",
       " 375: 'portions',\n",
       " 376: 'subphrenic',\n",
       " 377: 'cell',\n",
       " 378: '-',\n",
       " 379: 'necks',\n",
       " 380: 'account',\n",
       " 381: 'relative',\n",
       " 382: 'radiographically',\n",
       " 383: 'esophagus',\n",
       " 384: 'representing',\n",
       " 385: '4.5',\n",
       " 386: 'wide',\n",
       " 387: 'exposure',\n",
       " 388: 'annular',\n",
       " 389: 'margin',\n",
       " 390: 'erosions',\n",
       " 391: 'localized',\n",
       " 392: 'benign',\n",
       " 393: 'imaging',\n",
       " 394: 'repeated',\n",
       " 395: 'reasonably',\n",
       " 396: 'area',\n",
       " 397: 'ij',\n",
       " 398: 'relatively',\n",
       " 399: 'streakiness',\n",
       " 400: 'endplates',\n",
       " 401: 'suspicion',\n",
       " 402: 'cross',\n",
       " 403: 'mild',\n",
       " 404: '1st',\n",
       " 405: 'pneumothorax',\n",
       " 406: 'placement',\n",
       " 407: 'pull',\n",
       " 408: '1',\n",
       " 409: 'crowding',\n",
       " 410: 'like',\n",
       " 411: 'traction',\n",
       " 412: 'lymphadenopathy',\n",
       " 413: 'knees',\n",
       " 414: 'fossae',\n",
       " 415: 'unclear',\n",
       " 416: 'hemorrhage',\n",
       " 417: 'laparoscopic',\n",
       " 418: 'considerably',\n",
       " 419: 'predominantly',\n",
       " 420: 'confidently',\n",
       " 421: 'bronchiectasis',\n",
       " 422: 'densities',\n",
       " 423: 'better',\n",
       " 424: 'represents',\n",
       " 425: 'bronchopulmonary',\n",
       " 426: 'plaque',\n",
       " 427: 't',\n",
       " 428: 'appearances',\n",
       " 429: 'kv',\n",
       " 430: 'distribution',\n",
       " 431: 'noted',\n",
       " 432: 'stranding',\n",
       " 433: 'uncertain',\n",
       " 434: 'medication',\n",
       " 435: 'regular',\n",
       " 436: 'ectatic',\n",
       " 437: 'midright',\n",
       " 438: 'cabg',\n",
       " 439: 'may',\n",
       " 440: 'aorticopulmonary',\n",
       " 441: 'lingular',\n",
       " 442: 'trachea',\n",
       " 443: 'study',\n",
       " 444: 'tricompartmental',\n",
       " 445: 'vascularity',\n",
       " 446: 'physician',\n",
       " 447: 'shadows',\n",
       " 448: 'demonstrates',\n",
       " 449: 'infarct',\n",
       " 450: 'senescent',\n",
       " 451: 'subcarinal',\n",
       " 452: 't6',\n",
       " 453: 'nonspecific',\n",
       " 454: 'air',\n",
       " 455: 'below',\n",
       " 456: 'redemonstration',\n",
       " 457: 'factors',\n",
       " 458: '7.0',\n",
       " 459: 'tb',\n",
       " 460: 'articular',\n",
       " 461: 'costodiaphragmatic',\n",
       " 462: 'determined',\n",
       " 463: 'endseq',\n",
       " 464: 'old',\n",
       " 465: 'all',\n",
       " 466: 'verterbroplasty',\n",
       " 467: 'smooth',\n",
       " 468: 'on',\n",
       " 469: 'measures',\n",
       " 470: 'exchanged',\n",
       " 471: 'completely',\n",
       " 472: 'medially',\n",
       " 473: 'frontal',\n",
       " 474: 'peripheral',\n",
       " 475: 'assessment',\n",
       " 476: 'colon',\n",
       " 477: 'exam',\n",
       " 478: 'being',\n",
       " 479: 'previous',\n",
       " 480: 'however',\n",
       " 481: 'moderate',\n",
       " 482: 'towards',\n",
       " 483: 'size',\n",
       " 484: 'accentuates',\n",
       " 485: 'generator',\n",
       " 486: 'sized',\n",
       " 487: 'hours',\n",
       " 488: 'normally',\n",
       " 489: 'joints',\n",
       " 490: 'subsequent',\n",
       " 491: 'degenerate',\n",
       " 492: 'primarily',\n",
       " 493: 'l4',\n",
       " 494: 'quadrant',\n",
       " 495: 'reversal',\n",
       " 496: 'attributable',\n",
       " 497: 'overlies',\n",
       " 498: 'posttraumatic',\n",
       " 499: 'laterally',\n",
       " 500: 'desired',\n",
       " 501: 'questioned',\n",
       " 502: 'recurrent',\n",
       " 503: 'outlining',\n",
       " 504: 'appearance',\n",
       " 505: 'projected',\n",
       " 506: 'varying',\n",
       " 507: 'osteochondromatosis',\n",
       " 508: 'mid',\n",
       " 509: 'diaphragm',\n",
       " 510: 'reference',\n",
       " 511: 'paramediastinal',\n",
       " 512: 'satisfactory',\n",
       " 513: 'bronchial',\n",
       " 514: 'flexure',\n",
       " 515: 'sectional',\n",
       " 516: 'middle',\n",
       " 517: 'characteristic',\n",
       " 518: 'consider',\n",
       " 519: 'trapping',\n",
       " 520: 'opacity',\n",
       " 521: 'supine',\n",
       " 522: 'walled',\n",
       " 523: 'hyperaerated',\n",
       " 524: 'show',\n",
       " 525: 'caudal',\n",
       " 526: 'nodule',\n",
       " 527: 'suction',\n",
       " 528: 'clavicle',\n",
       " 529: 'reasonable',\n",
       " 530: 'summation',\n",
       " 531: 'scapula',\n",
       " 532: 'appendage',\n",
       " 533: 'worst',\n",
       " 534: 'segment',\n",
       " 535: 'intra',\n",
       " 536: 'configuration',\n",
       " 537: 'coarsened',\n",
       " 538: 'are',\n",
       " 539: 'margins',\n",
       " 540: 'than',\n",
       " 541: 'hypodense',\n",
       " 542: 'behind',\n",
       " 543: 'free',\n",
       " 544: 'recent',\n",
       " 545: 'hemithorax',\n",
       " 546: 'ankle',\n",
       " 547: 'further',\n",
       " 548: 'generally',\n",
       " 549: 'tortuosity',\n",
       " 550: '8th',\n",
       " 551: 'documented',\n",
       " 552: 'hemidiaphragms',\n",
       " 553: 'noncontrast',\n",
       " 554: '11',\n",
       " 555: 'assess',\n",
       " 556: 'prosthesis',\n",
       " 557: 'represent',\n",
       " 558: 'earlier',\n",
       " 559: 'clothing',\n",
       " 560: 'stabilization',\n",
       " 561: 'due',\n",
       " 562: 'atherosclerosis',\n",
       " 563: 'pneumoperitoneum',\n",
       " 564: 'contributes',\n",
       " 565: 'opaque',\n",
       " 566: 'fractures',\n",
       " 567: 'certified',\n",
       " 568: 'resultant',\n",
       " 569: 'lobectomy',\n",
       " 570: 'clearing',\n",
       " 571: 'diffusely',\n",
       " 572: 'recommend',\n",
       " 573: 'this',\n",
       " 574: 'two',\n",
       " 575: 'additional',\n",
       " 576: 'from',\n",
       " 577: 'correct',\n",
       " 578: 'basal',\n",
       " 579: 'attached',\n",
       " 580: 'raises',\n",
       " 581: 'useful',\n",
       " 582: 'amputation',\n",
       " 583: 'allow',\n",
       " 584: 'examinations',\n",
       " 585: 'bearing',\n",
       " 586: 'marrow',\n",
       " 587: 'typical',\n",
       " 588: 'intramedullary',\n",
       " 589: 'formations',\n",
       " 590: 'cuffing',\n",
       " 591: 'were',\n",
       " 592: 'contour',\n",
       " 593: '16',\n",
       " 594: 'bibasal',\n",
       " 595: 'spondylitic',\n",
       " 596: 'around',\n",
       " 597: 'circumscribed',\n",
       " 598: 'energy',\n",
       " 599: 'overlying',\n",
       " 600: 'idiopathic',\n",
       " 601: 'diminutive',\n",
       " 602: 'sacrum',\n",
       " 603: 'deformed',\n",
       " 604: 'lobulated',\n",
       " 605: 'traumatic',\n",
       " 606: 'relating',\n",
       " 607: 'proximal',\n",
       " 608: 'remains',\n",
       " 609: 'apex',\n",
       " 610: 'fluoroscopic',\n",
       " 611: 'umbilical',\n",
       " 612: 'biventricular',\n",
       " 613: 'extensive',\n",
       " 614: 'bilaterally.there',\n",
       " 615: 'reduced',\n",
       " 616: 'without',\n",
       " 617: 'constellation',\n",
       " 618: 'considered',\n",
       " 619: 'for',\n",
       " 620: 'warranted',\n",
       " 621: 'recommendations',\n",
       " 622: 'displaced',\n",
       " 623: 'anomaly',\n",
       " 624: '3.2',\n",
       " 625: 'bipolar',\n",
       " 626: 'would',\n",
       " 627: 'midclavicular',\n",
       " 628: 'notable',\n",
       " 629: '1.severe',\n",
       " 630: 'cartilage',\n",
       " 631: 'collecting',\n",
       " 632: 'triangular',\n",
       " 633: 'structure',\n",
       " 634: 'rotation',\n",
       " 635: 'date',\n",
       " 636: 'width',\n",
       " 637: 'appear',\n",
       " 638: 'base',\n",
       " 639: 'pannus',\n",
       " 640: 'to',\n",
       " 641: 'hemothorax',\n",
       " 642: 'effusion.heart',\n",
       " 643: 'overlapping',\n",
       " 644: 'sequelae',\n",
       " 645: 'calcified',\n",
       " 646: 'scoliosis',\n",
       " 647: 'screw',\n",
       " 648: 'vessel',\n",
       " 649: 'expanded',\n",
       " 650: 'narrow',\n",
       " 651: 'p',\n",
       " 652: 'enlarged',\n",
       " 653: 'rods',\n",
       " 654: 'developmental',\n",
       " 655: 'upon',\n",
       " 656: 'injection',\n",
       " 657: 'any',\n",
       " 658: 'malignancy',\n",
       " 659: 'node',\n",
       " 660: 'projecting',\n",
       " 661: ')',\n",
       " 662: '19',\n",
       " 663: 'significant',\n",
       " 664: 'apical',\n",
       " 665: 'oriented',\n",
       " 666: 'outside',\n",
       " 667: 'feeding',\n",
       " 668: '0.9',\n",
       " 669: 'interstitial',\n",
       " 670: '5.8',\n",
       " 671: 'although',\n",
       " 672: 'chronicity',\n",
       " 673: 'laryngeal',\n",
       " 674: 'sarcoidosis',\n",
       " 675: '..',\n",
       " 676: 'caliber',\n",
       " 677: 'obscure',\n",
       " 678: 'breath',\n",
       " 679: 'retraction',\n",
       " 680: 'levocurvature',\n",
       " 681: 'sternum',\n",
       " 682: 'cirrhotic',\n",
       " 683: 'deep',\n",
       " 684: 'tubes',\n",
       " 685: 'bandlike',\n",
       " 686: 'extension',\n",
       " 687: 'studies',\n",
       " 688: 'inspiratory',\n",
       " 689: 'spine',\n",
       " 690: 'given',\n",
       " 691: 'monitor',\n",
       " 692: 'subtle',\n",
       " 693: '1.5',\n",
       " 694: 'pleural',\n",
       " 695: 'flattening',\n",
       " 696: 'deformities',\n",
       " 697: 'destruction',\n",
       " 698: 'histoplasmosis',\n",
       " 699: 'informed',\n",
       " 700: \"'re\",\n",
       " 701: 'dislocations',\n",
       " 702: 'thought',\n",
       " 703: 'dislocation',\n",
       " 704: 'junctions',\n",
       " 705: 'verification',\n",
       " 706: 'transmetatarsal',\n",
       " 707: 'loss',\n",
       " 708: 'marking',\n",
       " 709: 'enhanced',\n",
       " 710: 'image',\n",
       " 711: 'identify',\n",
       " 712: 'reside',\n",
       " 713: 'markedly',\n",
       " 714: '10',\n",
       " 715: 'vertebral',\n",
       " 716: 'peritracheal',\n",
       " 717: 'thin',\n",
       " 718: 'favoring',\n",
       " 719: 'elbow',\n",
       " 720: 'stent',\n",
       " 721: 'rotatory',\n",
       " 722: 'scan',\n",
       " 723: 't12',\n",
       " 724: 'relates',\n",
       " 725: 'etiology',\n",
       " 726: 'underinflated',\n",
       " 727: 'systems',\n",
       " 728: 'dystrophy',\n",
       " 729: 'soft',\n",
       " 730: 'groundglass',\n",
       " 731: 'popliteal',\n",
       " 732: 'positioned',\n",
       " 733: 'visualized',\n",
       " 734: 'intraperitoneal',\n",
       " 735: 'tracheostomy',\n",
       " 736: 'blood',\n",
       " 737: 'small',\n",
       " 738: 'pedicle',\n",
       " 739: 'partially',\n",
       " 740: 'greater',\n",
       " 741: 'interpretation',\n",
       " 742: 'reticulonodular',\n",
       " 743: 'perihilar',\n",
       " 744: 'conveyed',\n",
       " 745: 'contour.unfolded',\n",
       " 746: 'appreciated',\n",
       " 747: 'midline',\n",
       " 748: 'origin',\n",
       " 749: 'resolved',\n",
       " 750: 'iliac',\n",
       " 751: 'symptoms',\n",
       " 752: 'overall',\n",
       " 753: 'anterolateral',\n",
       " 754: '2.1',\n",
       " 755: 'parenchyma',\n",
       " 756: 'volumes',\n",
       " 757: 'punctate',\n",
       " 758: 'posteriorly',\n",
       " 759: 'thanks',\n",
       " 760: 'b',\n",
       " 761: 'once',\n",
       " 762: 'cardiomediastinal',\n",
       " 763: 'collection',\n",
       " 764: 'bypass',\n",
       " 765: 'also',\n",
       " 766: 'overt',\n",
       " 767: 'already',\n",
       " 768: 'loculated',\n",
       " 769: 'kidneys',\n",
       " 770: 'radiodense',\n",
       " 771: 'patient',\n",
       " 772: 'certainty',\n",
       " 773: 'persists',\n",
       " 774: 'planning',\n",
       " 775: 'development',\n",
       " 776: 'device',\n",
       " 777: 'concern',\n",
       " 778: 'infiltrative',\n",
       " 779: 'fold',\n",
       " 780: '2.no',\n",
       " 781: 'believed',\n",
       " 782: 'cavitation',\n",
       " 783: 'confluent',\n",
       " 784: 'compartment',\n",
       " 785: 'performed',\n",
       " 786: 'degraded',\n",
       " 787: 'regarding',\n",
       " 788: 'vertebra',\n",
       " 789: '3.5',\n",
       " 790: 'prior',\n",
       " 791: 'extubation',\n",
       " 792: 't7',\n",
       " 793: 'that',\n",
       " 794: '4th',\n",
       " 795: 'inserted',\n",
       " 796: 'redistribution',\n",
       " 797: 'atrial',\n",
       " 798: 'kyphosis',\n",
       " 799: 'hyperinflated',\n",
       " 800: 'disc',\n",
       " 801: 'discoid',\n",
       " 802: 'technologist',\n",
       " 803: 'hypertrophy',\n",
       " 804: 'abdomen',\n",
       " 805: '02',\n",
       " 806: 'ligamentous',\n",
       " 807: 'decrease',\n",
       " 808: 'definitively',\n",
       " 809: 'by',\n",
       " 810: 'at',\n",
       " 811: 'opportunistic',\n",
       " 812: 'sequela',\n",
       " 813: 'aeration',\n",
       " 814: 'pronounced',\n",
       " 815: 'recesses',\n",
       " 816: 'bordered',\n",
       " 817: 'crosses',\n",
       " 818: 'look',\n",
       " 819: 'have',\n",
       " 820: 'nondilated',\n",
       " 821: 'postop',\n",
       " 822: 'line',\n",
       " 823: 'organomegaly',\n",
       " 824: 'sizes',\n",
       " 825: 'aspiration',\n",
       " 826: 'ectasia',\n",
       " 827: 'attenuation',\n",
       " 828: 'embolism',\n",
       " 829: 'background',\n",
       " 830: 'residual',\n",
       " 831: 'location',\n",
       " 832: 'lobes',\n",
       " 833: 'features',\n",
       " 834: 'exaggerated',\n",
       " 835: 'juxtahilar',\n",
       " 836: 'accessory',\n",
       " 837: '<',\n",
       " 838: 'rectum',\n",
       " 839: 'telemetry',\n",
       " 840: 'subpleural',\n",
       " 841: 'sinuses',\n",
       " 842: 'junction',\n",
       " 843: 'inlet',\n",
       " 844: 'bacterial',\n",
       " 845: 'xxxx-',\n",
       " 846: 'greatest',\n",
       " 847: 'arm',\n",
       " 848: 'recently',\n",
       " 849: 'decubitus',\n",
       " 850: 'same',\n",
       " 851: 'within',\n",
       " 852: 'surgical',\n",
       " 853: 'developing',\n",
       " 854: 'noticed',\n",
       " 855: 'post',\n",
       " 856: 'please',\n",
       " 857: 'cavity',\n",
       " 858: 'besides',\n",
       " 859: 'reflect',\n",
       " 860: 'xxxx.in',\n",
       " 861: 'capping',\n",
       " 862: 'questions',\n",
       " 863: 'stringy',\n",
       " 864: 'quality',\n",
       " 865: 'undergone',\n",
       " 866: 'lung',\n",
       " 867: 'symmetrically',\n",
       " 868: 'dextro',\n",
       " 869: 'definite',\n",
       " 870: 'postobstructive',\n",
       " 871: 'called',\n",
       " 872: 'subdiaphragmatic',\n",
       " 873: 'with',\n",
       " 874: 'subsegmental',\n",
       " 875: 'support',\n",
       " 876: 'mediastinum',\n",
       " 877: 'cardiophrenic',\n",
       " 878: 'upper',\n",
       " 879: 'widened',\n",
       " 880: 'interruption',\n",
       " 881: 'metastatic',\n",
       " 882: '1.2',\n",
       " 883: 'brain',\n",
       " 884: 'cholecystectomy',\n",
       " 885: 'narrowing',\n",
       " 886: 'pancreatitis',\n",
       " 887: 'fissure',\n",
       " 888: 'malleoli',\n",
       " 889: 'mixed',\n",
       " 890: 'intussusception',\n",
       " 891: 'characterized',\n",
       " 892: 'obscuring',\n",
       " 893: 'discrete',\n",
       " 894: 'upward',\n",
       " 895: 'positioning',\n",
       " 896: 'mechanical',\n",
       " 897: 'hypertension',\n",
       " 898: 'reformatted',\n",
       " 899: 'pneumothoraces',\n",
       " 900: 'stated',\n",
       " 901: 'condition',\n",
       " 902: 'levels',\n",
       " 903: 'uniformly',\n",
       " 904: 'superimposing',\n",
       " 905: 'except',\n",
       " 906: 'include',\n",
       " 907: 'habitus',\n",
       " 908: 'metastasis',\n",
       " 909: 'improvement',\n",
       " 910: 'normal',\n",
       " 911: 'coronal',\n",
       " 912: 'magnified',\n",
       " 913: 'innumerable',\n",
       " 914: 'nonconsolidating',\n",
       " 915: 'fullness',\n",
       " 916: 'distortion',\n",
       " 917: 'measure',\n",
       " 918: 'underinflation',\n",
       " 919: 'poorly',\n",
       " 920: 'valve',\n",
       " 921: 'sulcal',\n",
       " 922: 'includes',\n",
       " 923: 'through',\n",
       " 924: 'institutions',\n",
       " 925: 'anterior',\n",
       " 926: 'layering',\n",
       " 927: 'superiorly',\n",
       " 928: 'osteophytes',\n",
       " 929: 'levoscoliosis',\n",
       " 930: 'stomach',\n",
       " 931: 'demonstrated',\n",
       " 932: 'osteoporosis',\n",
       " 933: 'subcapital',\n",
       " 934: 't9',\n",
       " 935: 'demonstration',\n",
       " 936: 'images',\n",
       " 937: 'segments',\n",
       " 938: 'pleuroparenchymal',\n",
       " 939: 'septal',\n",
       " 940: 'explained',\n",
       " 941: 'internal',\n",
       " 942: 'abnormal',\n",
       " 943: 'paratracheal',\n",
       " 944: 'scattered',\n",
       " 945: 'procedure',\n",
       " 946: 'level',\n",
       " 947: 'unchanged',\n",
       " 948: 'we',\n",
       " 949: 'fractured',\n",
       " 950: 'hyperinflation',\n",
       " 951: 'confirm',\n",
       " 952: 'overlie',\n",
       " 953: 'involving',\n",
       " 954: 'spurring',\n",
       " 955: 'fragment',\n",
       " 956: 'months',\n",
       " 957: 'bone',\n",
       " 958: 'l2-l3',\n",
       " 959: 'ossifications',\n",
       " 960: 'geode',\n",
       " 961: 'defect',\n",
       " 962: 'congestive',\n",
       " 963: 'radiopaque',\n",
       " 964: 'br',\n",
       " 965: 'possible',\n",
       " 966: 'dextroscoliosis',\n",
       " 967: 'piercings',\n",
       " 968: 'example',\n",
       " 969: 'ng',\n",
       " 970: 'symmetric',\n",
       " 971: 'part',\n",
       " 972: 'mentally',\n",
       " 973: 'localize',\n",
       " 974: 'region',\n",
       " 975: 'followup',\n",
       " 976: 'mitral',\n",
       " 977: 'femur',\n",
       " 978: 'cardiothoracic',\n",
       " 979: 'nipple',\n",
       " 980: 'radiating',\n",
       " 981: 'monitoring',\n",
       " 982: 'along',\n",
       " 983: 'tissues',\n",
       " 984: 'hemidiaphragm',\n",
       " 985: 'pneumonitis',\n",
       " 986: 'mostly',\n",
       " 987: 'questionable',\n",
       " 988: 'emphysematous',\n",
       " 989: 'rib',\n",
       " 990: 'failure',\n",
       " 991: 'physicians',\n",
       " 992: 'fungal',\n",
       " 993: 'considerations',\n",
       " 994: 'diameter',\n",
       " 995: 'occluder',\n",
       " 996: '2',\n",
       " 997: 'fifth',\n",
       " 998: 'exacerbation',\n",
       " 999: 'subcentimeter',\n",
       " 1000: 'distal',\n",
       " ...}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_to_co = df_wcount\n",
    "w_to_co.index = w_to_co.words\n",
    "w_to_co = w_to_co['index'].to_dict()\n",
    "display(w_to_co)\n",
    "co_to_w = df_wcount\n",
    "co_to_w.index = co_to_w['index']\n",
    "co_to_w = co_to_w['words'].to_dict()\n",
    "display(co_to_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mediport'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(sorted(finding_len,reverse=True))\n",
    "# display(df.head(50))\n",
    "# df.plot(kind='hist',figsize=(6,6))\n",
    "co_to_w[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 300\n",
    "# embedding_matrix = np.zeros((vocab_size+1, embedding_size)) # last one : to cater to empty/-1\n",
    "# for word,idx in w_to_co.items():\n",
    "#     token = nlp(word)\n",
    "#     embedding_matrix[idx] = token.vector\n",
    "# embedding_matrix[vocab_size] = np.zeros(embedding_size)\n",
    "embedding_matrix = pd.read_pickle('../dataset/initial_emb_mat.p')\n",
    "embedding_matrix = embedding_matrix.values\n",
    "# print(embedding_matrix.shape)\n",
    "# df_emb = pd.DataFrame(embedding_matrix)\n",
    "# df_emb.to_pickle('../dataset/initial_emb_mat.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1943, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arch = 'irv2'\n",
    "text_arch = '1dcnn_attention'\n",
    "model_name = '{0}_{1}_words'.format(img_arch,text_arch)\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGGNet():\n",
    "    image_input = Input(shape=(256,256,3),name='image_input')\n",
    "    # x = CoordinateChannel2D()(inp)\n",
    "    x = kl.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', name='block1_conv1')(image_input)\n",
    "    x = kl.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = kl.Conv2D(filters=64, kernel_size=2, strides=2, activation='relu', padding='same', name='block1_reduction_conv')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(0.5)(x)\n",
    "\n",
    "    x = kl.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = kl.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = kl.Conv2D(filters=128, kernel_size=2, strides=2, activation='relu', padding='same', name='block2_reduction_conv')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(0.5)(x)\n",
    "\n",
    "    x = kl.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = kl.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = kl.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = kl.Conv2D(filters=256, kernel_size=2, strides=2, activation='relu', padding='same', name='block3_reduction_conv')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(0.5)(x)\n",
    "\n",
    "    x = kl.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = kl.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = kl.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    # x = CoordinateChannel2D(use_radius=True)(x)\n",
    "#     x, samap, g = SelfAttention(ch=512, name='self_attention')(x)\n",
    "    x = kl.Conv2D(filters=512, kernel_size=2, strides=2, activation='relu', padding='same', name='block4_reduction_conv')(x)\n",
    "    x = kl.BatchNormalization()(x)\n",
    "    x = kl.Dropout(0.5)(x)\n",
    "\n",
    "    x = kl.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = kl.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = kl.Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "#     x, amaps = SoftAttention(ch=512, m=32, name='soft_attention')(x)\n",
    "    x = kl.Conv2D(filters=512, kernel_size=2, strides=2, activation='relu', padding='same', name='block5_reduction_conv')(x)\n",
    "    return Model(image_input,x,name='imgModel')\n",
    "def DenseNet():\n",
    "    qw = Input(shape=(256,256,3),name='image_input')\n",
    "    qw_1 = kl.Conv2D(strides=1,padding='valid',activation='relu',filters=64,name='conv',kernel_size=3)(qw)\n",
    "\n",
    "    qw_1 = densenet.densenet.conv_block(x=qw_1,growth_rate=64,name='conv_1',)\n",
    "\n",
    "    qw_2 = densenet.densenet.dense_block(qw_1,blocks=1,name='block_1')\n",
    "    qw_2 = kl.BatchNormalization()(qw_2)\n",
    "    qw_2 = kl.Activation('relu')(qw_2)\n",
    "    qw_2 = kl.Conv2D(filters=64, kernel_size=2, strides=2, activation='relu', padding='same', name='block1_reduction_conv')(qw_2)\n",
    "    qw_2 = kl.Dropout(0.5)(qw_2)\n",
    "\n",
    "    qw_2 = densenet.densenet.dense_block(qw_2,blocks=1,name='block_2')\n",
    "    qw_2 = kl.BatchNormalization()(qw_2)\n",
    "    qw_2 = kl.Activation('relu')(qw_2)\n",
    "    # qw_2 = kl.MaxPool2D(pool_size=2)(qw_2)\n",
    "    qw_2 = kl.Conv2D(filters=128, kernel_size=2, strides=2, activation='relu', padding='same', name='block2_reduction_conv')(qw_2)\n",
    "    qw_2 = kl.Dropout(0.5)(qw_2)\n",
    "\n",
    "    qw_2 = densenet.densenet.dense_block(qw_2,blocks=1,name='block_3')\n",
    "    qw_2 = kl.BatchNormalization()(qw_2)\n",
    "    qw_2 = kl.Activation('relu')(qw_2)\n",
    "    # qw_2 = kl.MaxPool2D(pool_size=2)(qw_2)\n",
    "    qw_2 = kl.Conv2D(filters=256, kernel_size=2, strides=2, activation='relu', padding='same', name='block3_reduction_conv')(qw_2)\n",
    "    qw_2 = kl.Dropout(0.5)(qw_2)\n",
    "\n",
    "    qw_2 = densenet.densenet.dense_block(qw_2,blocks=1,name='block_4')\n",
    "    qw_2 = kl.BatchNormalization()(qw_2)\n",
    "    qw_2 = kl.Activation('relu')(qw_2)\n",
    "    # qw_2 = kl.MaxPool2D(pool_size=2)(qw_2)\n",
    "    qw_2 = kl.Conv2D(filters=512, kernel_size=2, strides=2, activation='relu', padding='same', name='block4_reduction_conv')(qw_2)\n",
    "    qw_2 = kl.Dropout(0.5)(qw_2)\n",
    "\n",
    "    qw_2 = densenet.densenet.dense_block(qw_2,blocks=1,name='block_5')\n",
    "    qw_2 = kl.BatchNormalization()(qw_2)\n",
    "    qw_2 = kl.Activation('relu')(qw_2)\n",
    "    # qw_2 = kl.MaxPool2D(pool_size=2)(qw_2)\n",
    "    qw_2 = kl.Conv2D(filters=1024, kernel_size=2, strides=2, activation='relu', padding='same', name='block5_reduction_conv')(qw_2)\n",
    "    # qw_2 = kl.Dropout(0.5)(qw_2)\n",
    "    qw_2 = kl.BatchNormalization()(qw_2)\n",
    "    qw_2 = kl.Activation('relu')(qw_2)\n",
    "\n",
    "    return Model(qw,qw_2, name='imgModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing image weights..\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 127, 127, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 127, 127, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 127, 127, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 125, 125, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 125, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 125, 125, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 125, 125, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 125, 125, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 125, 125, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 62, 62, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 62, 62, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 62, 62, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 62, 62, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 60, 60, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 60, 60, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 60, 60, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 29, 29, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 29, 29, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 29, 29, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 29, 29, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 29, 29, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 29, 29, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 29, 29, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 29, 29, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 29, 29, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 29, 29, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 29, 29, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 29, 29, 96)   18432       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 29, 29, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 29, 29, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 29, 29, 64)   12288       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 29, 29, 96)   288         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 29, 29, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 29, 29, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 29, 29, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 29, 29, 96)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 29, 29, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 29, 29, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 29, 29, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 29, 29, 320)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 29, 29, 32)   96          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 29, 29, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 29, 29, 48)   13824       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 29, 29, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 29, 29, 48)   144         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 29, 29, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 29, 29, 48)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 29, 29, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 29, 29, 32)   9216        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 29, 29, 64)   27648       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 29, 29, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 29, 29, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 29, 29, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 29, 29, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 29, 29, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 29, 29, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 29, 29, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 29, 29, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 29, 29, 32)   96          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 29, 29, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 29, 29, 48)   13824       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 29, 29, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 29, 29, 48)   144         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 29, 29, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 29, 29, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 29, 29, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 29, 29, 32)   9216        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 29, 29, 64)   27648       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 29, 29, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 29, 29, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 29, 29, 64)   192         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 29, 29, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 29, 29, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 29, 29, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 29, 29, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 29, 29, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 29, 29, 32)   96          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 29, 29, 32)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 29, 29, 48)   13824       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 29, 29, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 29, 29, 48)   144         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 29, 29, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 29, 29, 48)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 29, 29, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 29, 29, 32)   9216        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 29, 29, 64)   27648       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 29, 29, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 29, 29, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 29, 29, 64)   192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 29, 29, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 29, 29, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 29, 29, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_25[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 29, 29, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 29, 29, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 29, 29, 32)   96          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 29, 29, 32)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 29, 29, 48)   13824       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 29, 29, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 29, 29, 48)   144         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 29, 29, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 29, 29, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 29, 29, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 29, 29, 32)   9216        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 29, 29, 64)   27648       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 29, 29, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 29, 29, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 29, 29, 64)   192         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 29, 29, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 29, 29, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 29, 29, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_31[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 29, 29, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 29, 29, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 29, 29, 32)   96          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 29, 29, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 29, 29, 48)   13824       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 29, 29, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 29, 29, 48)   144         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 29, 29, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 29, 29, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 29, 29, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 29, 29, 32)   9216        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 29, 29, 64)   27648       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 29, 29, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 29, 29, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 29, 29, 64)   192         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 29, 29, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 29, 29, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 29, 29, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_37[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 29, 29, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 29, 29, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 29, 29, 32)   96          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 29, 29, 32)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 29, 29, 48)   13824       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 29, 29, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 29, 29, 48)   144         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 29, 29, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 29, 29, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 29, 29, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 29, 29, 32)   9216        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 29, 29, 64)   27648       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 29, 29, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 29, 29, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 29, 29, 64)   192         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 29, 29, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 29, 29, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 29, 29, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_43[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 29, 29, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 29, 29, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 29, 29, 32)   96          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 29, 29, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 29, 29, 48)   13824       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 29, 29, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 29, 29, 48)   144         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 29, 29, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 29, 29, 48)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 29, 29, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 29, 29, 32)   9216        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 29, 29, 64)   27648       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 29, 29, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 29, 29, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 29, 29, 64)   192         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 29, 29, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 29, 29, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 29, 29, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_49[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 29, 29, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 29, 29, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 29, 29, 32)   96          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 29, 29, 32)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 29, 29, 48)   13824       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 29, 29, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 29, 29, 48)   144         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 29, 29, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 29, 29, 48)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 29, 29, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 29, 29, 32)   9216        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 29, 29, 64)   27648       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 29, 29, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 29, 29, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 29, 29, 64)   192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 29, 29, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 29, 29, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 29, 29, 64)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_55[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 29, 29, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 29, 29, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 29, 29, 32)   96          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 29, 29, 32)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 29, 29, 48)   13824       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 29, 29, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 29, 29, 48)   144         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 29, 29, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 29, 29, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 29, 29, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 29, 29, 32)   9216        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 29, 29, 64)   27648       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 29, 29, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 29, 29, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 29, 29, 64)   192         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 29, 29, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 29, 29, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 29, 29, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 29, 29, 128)  0           activation_61[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 29, 29, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 29, 29, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 29, 29, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 29, 29, 32)   96          conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 29, 29, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 29, 29, 48)   13824       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 29, 29, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 29, 29, 48)   144         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 29, 29, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 29, 29, 48)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 29, 29, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 29, 29, 32)   9216        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 29, 29, 64)   27648       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 29, 29, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 29, 29, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 29, 29, 64)   192         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 29, 29, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 29, 29, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 29, 29, 64)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 29, 29, 128)  0           activation_67[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 29, 29, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 29, 29, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 29, 29, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 29, 29, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 29, 29, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 29, 29, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 29, 29, 256)  589824      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 29, 29, 256)  768         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 29, 29, 256)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 14, 14, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 14, 14, 384)  884736      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 14, 14, 384)  1152        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 14, 14, 384)  1152        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 384)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 384)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 14, 14, 1088) 0           activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 14, 14, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 14, 14, 128)  384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 128)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 14, 14, 160)  143360      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 14, 14, 160)  480         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 160)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 14, 14, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 14, 14, 192)  215040      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 14, 14, 192)  576         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 14, 14, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 192)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_77[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 14, 14, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 14, 14, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 14, 14, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 14, 14, 128)  384         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 128)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 14, 14, 160)  143360      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 14, 14, 160)  480         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 160)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 14, 14, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 14, 14, 192)  215040      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 14, 14, 192)  576         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 14, 14, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 192)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_81[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 14, 14, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 14, 14, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 14, 14, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 14, 14, 128)  384         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 128)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 14, 14, 160)  143360      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 14, 14, 160)  480         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 160)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 14, 14, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 14, 14, 192)  215040      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 14, 14, 192)  576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 14, 14, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 192)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_85[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 14, 14, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 14, 14, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 14, 14, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 14, 14, 128)  384         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 14, 14, 128)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 14, 14, 160)  143360      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 14, 14, 160)  480         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 14, 14, 160)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 14, 14, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 14, 14, 192)  215040      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 14, 14, 192)  576         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 14, 14, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 14, 14, 192)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 14, 14, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_89[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 14, 14, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 14, 14, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 14, 14, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 14, 14, 128)  384         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 14, 14, 128)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 14, 14, 160)  143360      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 14, 14, 160)  480         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 14, 14, 160)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 14, 14, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 14, 14, 192)  215040      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 14, 14, 192)  576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 14, 14, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 14, 14, 192)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 14, 14, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_93[0][0]              \n",
      "                                                                 activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 14, 14, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 14, 14, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 14, 14, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 14, 14, 128)  384         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 14, 14, 128)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 14, 14, 160)  143360      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 14, 14, 160)  480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 14, 14, 160)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 14, 14, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 14, 14, 192)  215040      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 14, 14, 192)  576         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 14, 14, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 14, 14, 192)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 14, 14, 192)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_97[0][0]              \n",
      "                                                                 activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 14, 14, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 14, 14, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 14, 14, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 14, 14, 128)  384         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 14, 14, 128)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 14, 14, 160)  143360      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 14, 14, 160)  480         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 14, 14, 160)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 14, 14, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 14, 14, 192)  215040      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 14, 14, 192)  576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 14, 14, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 14, 14, 192)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 14, 14, 192)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 14, 14, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 14, 14, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 14, 14, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 14, 14, 128)  384         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 14, 14, 128)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 14, 14, 160)  143360      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 14, 14, 160)  480         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 14, 14, 160)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 14, 14, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 14, 14, 192)  215040      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 14, 14, 192)  576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 14, 14, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 14, 14, 192)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 14, 14, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_105[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 14, 14, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 14, 14, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 14, 14, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 14, 14, 128)  384         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 14, 14, 128)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 14, 14, 160)  143360      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 14, 14, 160)  480         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 14, 14, 160)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 14, 14, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 14, 14, 192)  215040      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 14, 14, 192)  576         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 14, 14, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 14, 14, 192)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 14, 14, 192)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 14, 14, 384)  0           activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 14, 14, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 14, 14, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 14, 14, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 14, 14, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 14, 14, 128)  384         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 14, 14, 128)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 14, 14, 160)  143360      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 14, 14, 160)  480         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 14, 14, 160)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 14, 14, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 14, 14, 192)  215040      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 14, 14, 192)  576         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 14, 14, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 14, 14, 192)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 14, 14, 192)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_113[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 14, 14, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 14, 14, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 14, 14, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 14, 14, 128)  384         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 14, 14, 128)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 14, 14, 160)  143360      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 14, 14, 160)  480         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 14, 14, 160)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 14, 14, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 14, 14, 192)  215040      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 14, 14, 192)  576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 14, 14, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 14, 14, 192)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 14, 14, 192)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_117[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 14, 14, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 14, 14, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 14, 14, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 14, 14, 128)  384         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 14, 14, 128)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 14, 14, 160)  143360      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 14, 14, 160)  480         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 14, 14, 160)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 14, 14, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 14, 14, 192)  215040      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 14, 14, 192)  576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 14, 14, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 14, 14, 192)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 14, 14, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 14, 14, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 14, 14, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 14, 14, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 14, 14, 128)  384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 14, 14, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 14, 14, 160)  143360      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 14, 14, 160)  480         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 14, 14, 160)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 14, 14, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 14, 14, 192)  215040      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 14, 14, 192)  576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 14, 14, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 14, 14, 192)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 14, 14, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 14, 14, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 14, 14, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 14, 14, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 14, 14, 128)  384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 14, 14, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 14, 14, 160)  143360      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 14, 14, 160)  480         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 14, 14, 160)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 14, 14, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 14, 14, 192)  215040      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 14, 14, 192)  576         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 14, 14, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 14, 14, 192)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 14, 14, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_129[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 14, 14, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 14, 14, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 14, 14, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 14, 14, 128)  384         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 14, 14, 128)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 14, 14, 160)  143360      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 14, 14, 160)  480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 14, 14, 160)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 14, 14, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 14, 14, 192)  215040      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 14, 14, 192)  576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 14, 14, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 14, 14, 192)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 14, 14, 192)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_133[0][0]             \n",
      "                                                                 activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 14, 14, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 14, 14, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 14, 14, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 14, 14, 128)  384         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 14, 14, 128)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 14, 14, 160)  143360      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 14, 14, 160)  480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 14, 14, 160)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 14, 14, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 14, 14, 192)  215040      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 14, 14, 192)  576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 14, 14, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 14, 14, 192)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 14, 14, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_137[0][0]             \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 14, 14, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 14, 14, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 14, 14, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 14, 14, 128)  384         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 14, 14, 128)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 14, 14, 160)  143360      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 14, 14, 160)  480         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 14, 14, 160)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 14, 14, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 14, 14, 192)  215040      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 14, 14, 192)  576         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 14, 14, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 14, 14, 192)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 14, 14, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_141[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 14, 14, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 14, 14, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 14, 14, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 14, 14, 128)  384         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 14, 14, 128)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 14, 14, 160)  143360      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 14, 14, 160)  480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 14, 14, 160)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 14, 14, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 14, 14, 192)  215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 14, 14, 192)  576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 14, 14, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 14, 14, 192)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 14, 14, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 14, 14, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 14, 14, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 14, 14, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 14, 14, 128)  384         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 14, 14, 128)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 14, 14, 160)  143360      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 14, 14, 160)  480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 14, 14, 160)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 14, 14, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 14, 14, 192)  215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 14, 14, 192)  576         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 14, 14, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 14, 14, 192)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 14, 14, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_149[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 14, 14, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 14, 14, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 14, 14, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 14, 14, 128)  384         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 14, 14, 128)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 14, 14, 160)  143360      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 14, 14, 160)  480         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 14, 14, 160)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 14, 14, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 14, 14, 192)  215040      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 14, 14, 192)  576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 14, 14, 192)  576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 14, 14, 192)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 14, 14, 192)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 14, 14, 384)  0           activation_153[0][0]             \n",
      "                                                                 activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 14, 14, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 14, 14, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 14, 14, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 14, 14, 256)  768         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 14, 14, 256)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 14, 14, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 14, 14, 288)  663552      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 14, 14, 256)  768         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 14, 14, 256)  768         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 14, 14, 288)  864         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 14, 14, 256)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 14, 14, 256)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 14, 14, 288)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 6, 6, 384)    884736      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 6, 6, 288)    663552      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 6, 6, 320)    829440      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 6, 6, 384)    1152        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 6, 6, 288)    864         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 6, 6, 320)    960         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 6, 6, 384)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 6, 6, 288)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 6, 6, 320)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 6, 6, 2080)   0           activation_158[0][0]             \n",
      "                                                                 activation_160[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 6, 6, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 6, 6, 192)    576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 6, 6, 192)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 6, 6, 224)    129024      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 6, 6, 224)    672         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 6, 6, 224)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 6, 6, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 6, 6, 256)    172032      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 6, 6, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 6, 6, 256)    768         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 6, 6, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 6, 6, 256)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_164[0][0]             \n",
      "                                                                 activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 6, 6, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 6, 6, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 6, 6, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 6, 6, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 6, 6, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 6, 6, 224)    129024      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 6, 6, 224)    672         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 6, 6, 224)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 6, 6, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 6, 6, 256)    172032      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 6, 6, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 6, 6, 256)    768         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 6, 6, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 6, 6, 256)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_168[0][0]             \n",
      "                                                                 activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 6, 6, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 6, 6, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 6, 6, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 6, 6, 192)    576         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 6, 6, 192)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 6, 6, 224)    129024      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 6, 6, 224)    672         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 6, 6, 224)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 6, 6, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 6, 6, 256)    172032      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 6, 6, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 6, 6, 256)    768         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 6, 6, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 6, 6, 256)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_172[0][0]             \n",
      "                                                                 activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 6, 6, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 6, 6, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 6, 6, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 6, 6, 192)    576         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 6, 6, 192)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 6, 6, 224)    129024      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 6, 6, 224)    672         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 6, 6, 224)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 6, 6, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 6, 6, 256)    172032      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 6, 6, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 6, 6, 256)    768         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 6, 6, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 6, 6, 256)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_176[0][0]             \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 6, 6, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 6, 6, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 6, 6, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 6, 6, 192)    576         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 6, 6, 192)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 6, 6, 224)    129024      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 6, 6, 224)    672         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 6, 6, 224)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 6, 6, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 6, 6, 256)    172032      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 6, 6, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 6, 6, 256)    768         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 6, 6, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 6, 6, 256)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_180[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 6, 6, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 6, 6, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 6, 6, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 6, 6, 192)    576         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 6, 6, 192)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 6, 6, 224)    129024      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 6, 6, 224)    672         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 6, 6, 224)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 6, 6, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 6, 6, 256)    172032      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 6, 6, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 6, 6, 256)    768         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 6, 6, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 6, 6, 256)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_184[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 6, 6, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 6, 6, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 6, 6, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 6, 6, 192)    576         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 6, 6, 192)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 6, 6, 224)    129024      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 6, 6, 224)    672         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 6, 6, 224)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 6, 6, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 6, 6, 256)    172032      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 6, 6, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 6, 6, 256)    768         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 6, 6, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 6, 6, 256)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_188[0][0]             \n",
      "                                                                 activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 6, 6, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 6, 6, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 6, 6, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 6, 6, 192)    576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 6, 6, 192)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 6, 6, 224)    129024      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 6, 6, 224)    672         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 6, 6, 224)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 6, 6, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 6, 6, 256)    172032      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 6, 6, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 6, 6, 256)    768         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 6, 6, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 6, 6, 256)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_192[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 6, 6, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 6, 6, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 6, 6, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 6, 6, 192)    576         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 6, 6, 192)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 6, 6, 224)    129024      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 6, 6, 224)    672         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 6, 6, 224)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 6, 6, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 6, 6, 256)    172032      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 6, 6, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 6, 6, 256)    768         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 6, 6, 192)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 6, 6, 256)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 6, 6, 448)    0           activation_196[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 6, 6, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 6, 6, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 6, 6, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 6, 6, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 6, 6, 192)    576         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 6, 6, 192)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 6, 6, 224)    129024      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 6, 6, 224)    672         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 6, 6, 224)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 6, 6, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 6, 6, 256)    172032      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 6, 6, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 6, 6, 256)    768         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 6, 6, 192)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 6, 6, 256)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 6, 6, 448)    0           activation_200[0][0]             \n",
      "                                                                 activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 6, 6, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 6, 6, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 6, 6, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 6, 6, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 6, 6, 1536)   0           conv_7b_bn[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 54,336,736\n",
      "Trainable params: 54,276,192\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if img_arch=='vgg':\n",
    "    imgNet = VGGNet()\n",
    "elif img_arch == 'densenet121':\n",
    "    imgNet = DenseNet121(include_top=False,input_shape=(256,256,3))\n",
    "    imgNet.trainable = True\n",
    "elif img_arch == 'densenet':\n",
    "    imgNet = DenseNet()\n",
    "elif img_arch == 'irv2':\n",
    "    imgNet =InceptionResNetV2(include_top=False,input_shape=(256,256,3))\n",
    "if os.path.exists('../checkpoints/{0}_{1}_img_module.h5'.format(img_arch,text_arch)):\n",
    "    print('loading existing image weights..')\n",
    "    imgNet.load_weights('../checkpoints/{0}_{1}_img_module.h5'.format(img_arch,text_arch))\n",
    "imgNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textNet():\n",
    "    words_input = kl.Input(shape=(max_wlen,),name='words_input')\n",
    "    x2 = kl.Embedding(vocab_size+1, embedding_size, mask_zero=False, name='w2v_emb')(words_input)\n",
    "    x2 = kl.Conv1D(filters=512,kernel_size=3,strides=1,activation='relu', padding='same')(x2)\n",
    "    x2 = kl.BatchNormalization()(x2)\n",
    "#     x2 = kl.Dropout(0.1)(x2)\n",
    "    sa_out_x2_1,s_x2_1,g_x2_1 = SelfAttention(ch=int(x2.shape[-1]))(x2)\n",
    "    sa_out_x2_2,s_x2_2,g_x2_2 = SelfAttention(ch=int(x2.shape[-1]))(x2)\n",
    "    sa_out_x2_3,s_x2_3,g_x2_3 = SelfAttention(ch=int(x2.shape[-1]))(x2)\n",
    "    sa_out_x2_4,s_x2_4,g_x2_4 = SelfAttention(ch=int(x2.shape[-1]))(x2)\n",
    "    x3 = kl.Add()([sa_out_x2_1,sa_out_x2_2,sa_out_x2_3,sa_out_x2_4])\n",
    "    x3 = kl.BatchNormalization()(x3)\n",
    "    sa_out_x3_1,s_x3_1,g_x3_1 = SelfAttention(ch=int(x3.shape[-1]))(x3)\n",
    "    sa_out_x3_2,s_x3_2,g_x3_2 = SelfAttention(ch=int(x3.shape[-1]))(x3)\n",
    "    sa_out_x3_3,s_x3_3,g_x3_3 = SelfAttention(ch=int(x3.shape[-1]))(x3)\n",
    "    sa_out_x3_4,s_x3_4,g_x3_4 = SelfAttention(ch=int(x3.shape[-1]))(x3)\n",
    "    x4 = kl.Add()([sa_out_x3_1,sa_out_x3_2,sa_out_x3_3,sa_out_x3_4])\n",
    "    x4 = kl.BatchNormalization()(x4)\n",
    "    sa_out_x4_1,s_x4_1,g_x4_1 = SelfAttention(ch=int(x3.shape[-1]))(x4)\n",
    "    sa_out_x4_2,s_x4_2,g_x4_2 = SelfAttention(ch=int(x3.shape[-1]))(x4)\n",
    "    sa_out_x4_3,s_x4_3,g_x4_3 = SelfAttention(ch=int(x3.shape[-1]))(x4)\n",
    "    sa_out_x4_4,s_x4_4,g_x4_4 = SelfAttention(ch=int(x3.shape[-1]))(x4)\n",
    "    x5 = kl.Add()([sa_out_x4_1,sa_out_x4_2,sa_out_x4_3,sa_out_x4_4])\n",
    "    x5 = kl.BatchNormalization()(x5)\n",
    "    sa_pool = kl.GlobalAveragePooling1D(name='sa_gap')(x5)\n",
    "    a_out,cs = Attention(ch=int(sa_pool.shape[-1]))([sa_pool,x2])    \n",
    "    a_pool = kl.Lambda(lambda x:K.tf.squeeze(x,axis=1),name='a_gap')(a_out)\n",
    "    out = kl.Concatenate()([a_pool,sa_pool])\n",
    "#     print('cx.shape:',out.shape)\n",
    "    \n",
    "    return Model(words_input,out,name='textModel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_shape_q_k: (1, 512, 64)\n",
      "kernel_shape_v: (1, 512, 512)\n",
      "q.shape,k.shape,v.shape, (?, 1, 64) (?, 193, 64) (?, 193, 512)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_input (InputLayer)        (None, 193)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "w2v_emb (Embedding)             (None, 193, 300)     582900      words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 193, 512)     461312      w2v_emb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 193, 512)     2048        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_1 (SelfAttention [(None, 193, 512), ( 590977      batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_2 (SelfAttention [(None, 193, 512), ( 590977      batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_3 (SelfAttention [(None, 193, 512), ( 590977      batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_4 (SelfAttention [(None, 193, 512), ( 590977      batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 193, 512)     0           self_attention_1[0][0]           \n",
      "                                                                 self_attention_2[0][0]           \n",
      "                                                                 self_attention_3[0][0]           \n",
      "                                                                 self_attention_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 193, 512)     2048        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_5 (SelfAttention [(None, 193, 512), ( 590977      batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_6 (SelfAttention [(None, 193, 512), ( 590977      batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_7 (SelfAttention [(None, 193, 512), ( 590977      batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_8 (SelfAttention [(None, 193, 512), ( 590977      batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 193, 512)     0           self_attention_5[0][0]           \n",
      "                                                                 self_attention_6[0][0]           \n",
      "                                                                 self_attention_7[0][0]           \n",
      "                                                                 self_attention_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 193, 512)     2048        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_9 (SelfAttention [(None, 193, 512), ( 590977      batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_10 (SelfAttentio [(None, 193, 512), ( 590977      batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_11 (SelfAttentio [(None, 193, 512), ( 590977      batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "self_attention_12 (SelfAttentio [(None, 193, 512), ( 590977      batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 193, 512)     0           self_attention_9[0][0]           \n",
      "                                                                 self_attention_10[0][0]          \n",
      "                                                                 self_attention_11[0][0]          \n",
      "                                                                 self_attention_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 193, 512)     2048        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sa_gap (GlobalAveragePooling1D) (None, 512)          0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         [(None, 1, 512), (1, 590976      sa_gap[0][0]                     \n",
      "                                                                 batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "a_gap (Lambda)                  (None, 512)          0           attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           a_gap[0][0]                      \n",
      "                                                                 sa_gap[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,735,104\n",
      "Trainable params: 8,731,008\n",
      "Non-trainable params: 4,096\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "textNet = textNet()\n",
    "textNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"1383pt\" viewBox=\"0.00 0.00 2010.00 1383.00\" width=\"2010pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1379)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-1379 2006,-1379 2006,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140577803504944 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140577803504944</title>\n",
       "<polygon fill=\"none\" points=\"1077,-1328.5 1077,-1374.5 1367,-1374.5 1367,-1328.5 1077,-1328.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1153\" y=\"-1347.8\">words_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"1229,-1328.5 1229,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1256.5\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1229,-1351.5 1284,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1256.5\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1284,-1328.5 1284,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1325.5\" y=\"-1359.3\">(None, 193)</text>\n",
       "<polyline fill=\"none\" points=\"1284,-1351.5 1367,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1325.5\" y=\"-1336.3\">(None, 193)</text>\n",
       "</g>\n",
       "<!-- 140576936593000 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140576936593000</title>\n",
       "<polygon fill=\"none\" points=\"1069,-1245.5 1069,-1291.5 1375,-1291.5 1375,-1245.5 1069,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139.5\" y=\"-1264.8\">w2v_emb: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"1210,-1245.5 1210,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1237.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1210,-1268.5 1265,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1237.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1265,-1245.5 1265,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1320\" y=\"-1276.3\">(None, 193)</text>\n",
       "<polyline fill=\"none\" points=\"1265,-1268.5 1375,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1320\" y=\"-1253.3\">(None, 193, 300)</text>\n",
       "</g>\n",
       "<!-- 140577803504944&#45;&gt;140576936593000 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140577803504944-&gt;140576936593000</title>\n",
       "<path d=\"M1222,-1328.3799C1222,-1320.1745 1222,-1310.7679 1222,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1225.5001,-1301.784 1222,-1291.784 1218.5001,-1301.784 1225.5001,-1301.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576947403576 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140576947403576</title>\n",
       "<polygon fill=\"none\" points=\"1078,-1162.5 1078,-1208.5 1366,-1208.5 1366,-1162.5 1078,-1162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139.5\" y=\"-1181.8\">conv1d_1: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1201,-1162.5 1201,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1228.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1201,-1185.5 1256,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1228.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1256,-1162.5 1256,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1311\" y=\"-1193.3\">(None, 193, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1256,-1185.5 1366,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1311\" y=\"-1170.3\">(None, 193, 512)</text>\n",
       "</g>\n",
       "<!-- 140576936593000&#45;&gt;140576947403576 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140576936593000-&gt;140576947403576</title>\n",
       "<path d=\"M1222,-1245.3799C1222,-1237.1745 1222,-1227.7679 1222,-1218.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1225.5001,-1218.784 1222,-1208.784 1218.5001,-1218.784 1225.5001,-1218.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140577091136760 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140577091136760</title>\n",
       "<polygon fill=\"none\" points=\"1003,-1079.5 1003,-1125.5 1441,-1125.5 1441,-1079.5 1003,-1079.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139.5\" y=\"-1098.8\">batch_normalization_204: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1276,-1079.5 1276,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1303.5\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1276,-1102.5 1331,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1303.5\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1331,-1079.5 1331,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1386\" y=\"-1110.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1331,-1102.5 1441,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1386\" y=\"-1087.3\">(None, 193, 512)</text>\n",
       "</g>\n",
       "<!-- 140576947403576&#45;&gt;140577091136760 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140576947403576-&gt;140577091136760</title>\n",
       "<path d=\"M1222,-1162.3799C1222,-1154.1745 1222,-1144.7679 1222,-1135.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1225.5001,-1135.784 1222,-1125.784 1218.5001,-1135.784 1225.5001,-1135.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576920754104 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140576920754104</title>\n",
       "<polygon fill=\"none\" points=\"61,-996.5 61,-1042.5 511,-1042.5 511,-996.5 61,-996.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153\" y=\"-1015.8\">self_attention_1: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"245,-996.5 245,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"245,-1019.5 300,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"272.5\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"300,-996.5 300,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1027.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"300,-1019.5 511,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-1004.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140577091136760&#45;&gt;140576920754104 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140577091136760-&gt;140576920754104</title>\n",
       "<path d=\"M1002.9547,-1084.8144C867.1502,-1073.6359 688.8001,-1058.571 521.1072,-1043.0967\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"521.3785,-1039.607 511.0988,-1042.1715 520.7341,-1046.5773 521.3785,-1039.607\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576920067376 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140576920067376</title>\n",
       "<polygon fill=\"none\" points=\"529,-996.5 529,-1042.5 979,-1042.5 979,-996.5 529,-996.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"621\" y=\"-1015.8\">self_attention_2: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"713,-996.5 713,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740.5\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"713,-1019.5 768,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740.5\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"768,-996.5 768,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"873.5\" y=\"-1027.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"768,-1019.5 979,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"873.5\" y=\"-1004.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140577091136760&#45;&gt;140576920067376 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140577091136760-&gt;140576920067376</title>\n",
       "<path d=\"M1092.2574,-1079.4901C1030.6314,-1068.5607 956.8786,-1055.4806 893.9912,-1044.3275\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"894.4525,-1040.8548 883.995,-1042.5547 893.2301,-1047.7472 894.4525,-1040.8548\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576901729248 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140576901729248</title>\n",
       "<polygon fill=\"none\" points=\"997,-996.5 997,-1042.5 1447,-1042.5 1447,-996.5 997,-996.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1089\" y=\"-1015.8\">self_attention_3: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1181,-996.5 1181,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1208.5\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1181,-1019.5 1236,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1208.5\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1236,-996.5 1236,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1341.5\" y=\"-1027.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1236,-1019.5 1447,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1341.5\" y=\"-1004.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140577091136760&#45;&gt;140576901729248 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140577091136760-&gt;140576901729248</title>\n",
       "<path d=\"M1222,-1079.3799C1222,-1071.1745 1222,-1061.7679 1222,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1225.5001,-1052.784 1222,-1042.784 1218.5001,-1052.784 1225.5001,-1052.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576900861400 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140576900861400</title>\n",
       "<polygon fill=\"none\" points=\"1465,-996.5 1465,-1042.5 1915,-1042.5 1915,-996.5 1465,-996.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1557\" y=\"-1015.8\">self_attention_4: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1649,-996.5 1649,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1676.5\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1649,-1019.5 1704,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1676.5\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1704,-996.5 1704,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1809.5\" y=\"-1027.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1704,-1019.5 1915,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1809.5\" y=\"-1004.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140577091136760&#45;&gt;140576900861400 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140577091136760-&gt;140576900861400</title>\n",
       "<path d=\"M1351.7426,-1079.4901C1413.3686,-1068.5607 1487.1214,-1055.4806 1550.0088,-1044.3275\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1550.7699,-1047.7472 1560.005,-1042.5547 1549.5475,-1040.8548 1550.7699,-1047.7472\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576018738424 -->\n",
       "<g class=\"node\" id=\"node24\">\n",
       "<title>140576018738424</title>\n",
       "<polygon fill=\"none\" points=\"1618,-166.5 1618,-212.5 2002,-212.5 2002,-166.5 1618,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1686\" y=\"-185.8\">attention_1: Attention</text>\n",
       "<polyline fill=\"none\" points=\"1754,-166.5 1754,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1781.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1754,-189.5 1809,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1781.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1809,-166.5 1809,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1905.5\" y=\"-197.3\">[(None, 512), (None, 193, 512)]</text>\n",
       "<polyline fill=\"none\" points=\"1809,-189.5 2002,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1905.5\" y=\"-174.3\">[(None, 1, 512), (1, 193)]</text>\n",
       "</g>\n",
       "<!-- 140577091136760&#45;&gt;140576018738424 -->\n",
       "<g class=\"edge\" id=\"edge33\">\n",
       "<title>140577091136760-&gt;140576018738424</title>\n",
       "<path d=\"M1441.2233,-1097.1523C1633.7548,-1090.3272 1888.6134,-1075.2724 1924,-1043 1959.5254,-1010.601 1943,-984.5807 1943,-936.5 1943,-936.5 1943,-936.5 1943,-355.5 1943,-297.4074 1892.7788,-248.0278 1854.0576,-218.589\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1856.1105,-215.754 1845.9917,-212.6138 1851.9437,-221.3788 1856.1105,-215.754\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576900124288 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>140576900124288</title>\n",
       "<polygon fill=\"none\" points=\"535,-913.5 535,-959.5 1093,-959.5 1093,-913.5 535,-913.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"575\" y=\"-932.8\">add_1: Add</text>\n",
       "<polyline fill=\"none\" points=\"615,-913.5 615,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"642.5\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"615,-936.5 670,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"642.5\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"670,-913.5 670,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"881.5\" y=\"-944.3\">[(None, 193, 512), (None, 193, 512), (None, 193, 512), (None, 193, 512)]</text>\n",
       "<polyline fill=\"none\" points=\"670,-936.5 1093,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"881.5\" y=\"-921.3\">(None, 193, 512)</text>\n",
       "</g>\n",
       "<!-- 140576920754104&#45;&gt;140576900124288 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>140576920754104-&gt;140576900124288</title>\n",
       "<path d=\"M432.3763,-996.4901C502.3322,-985.4932 586.1391,-972.319 657.3737,-961.1212\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"658.0039,-964.5652 667.339,-959.5547 656.9168,-957.6501 658.0039,-964.5652\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576920067376&#45;&gt;140576900124288 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>140576920067376-&gt;140576900124288</title>\n",
       "<path d=\"M770.7133,-996.3799C777.0317,-987.6394 784.3355,-977.5358 791.123,-968.1465\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"794.1462,-969.9387 797.1682,-959.784 788.4732,-965.8378 794.1462,-969.9387\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576901729248&#45;&gt;140576900124288 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>140576901729248-&gt;140576900124288</title>\n",
       "<path d=\"M1108.8911,-996.4901C1055.608,-985.6506 991.9262,-972.6958 937.3992,-961.6033\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"937.826,-958.1185 927.329,-959.5547 936.4305,-964.978 937.826,-958.1185\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576900861400&#45;&gt;140576900124288 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>140576900861400-&gt;140576900124288</title>\n",
       "<path d=\"M1464.8981,-996.8613C1461.9136,-996.5717 1458.9464,-996.2845 1456,-996 1331.4982,-983.9791 1193.3657,-971.1159 1077.2234,-960.436\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1077.4036,-956.9379 1067.1252,-959.5078 1076.7628,-963.9085 1077.4036,-956.9379\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576920122312 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>140576920122312</title>\n",
       "<polygon fill=\"none\" points=\"595,-830.5 595,-876.5 1033,-876.5 1033,-830.5 595,-830.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"731.5\" y=\"-849.8\">batch_normalization_205: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"868,-830.5 868,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"895.5\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"868,-853.5 923,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"895.5\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"923,-830.5 923,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"978\" y=\"-861.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"923,-853.5 1033,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"978\" y=\"-838.3\">(None, 193, 512)</text>\n",
       "</g>\n",
       "<!-- 140576900124288&#45;&gt;140576920122312 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>140576900124288-&gt;140576920122312</title>\n",
       "<path d=\"M814,-913.3799C814,-905.1745 814,-895.7679 814,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"817.5001,-886.784 814,-876.784 810.5001,-886.784 817.5001,-886.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576899424664 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>140576899424664</title>\n",
       "<polygon fill=\"none\" points=\"1404,-747.5 1404,-793.5 1854,-793.5 1854,-747.5 1404,-747.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1496\" y=\"-766.8\">self_attention_5: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1588,-747.5 1588,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1615.5\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1588,-770.5 1643,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1615.5\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1643,-747.5 1643,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1748.5\" y=\"-778.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1643,-770.5 1854,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1748.5\" y=\"-755.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140576920122312&#45;&gt;140576899424664 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>140576920122312-&gt;140576899424664</title>\n",
       "<path d=\"M1033.209,-831.1756C1144.536,-819.8381 1279.896,-806.0529 1393.4443,-794.4891\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1394.0706,-797.9435 1403.6645,-793.4483 1393.3613,-790.9795 1394.0706,-797.9435\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576898845888 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>140576898845888</title>\n",
       "<polygon fill=\"none\" points=\"0,-747.5 0,-793.5 450,-793.5 450,-747.5 0,-747.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92\" y=\"-766.8\">self_attention_6: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"184,-747.5 184,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"184,-770.5 239,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"239,-747.5 239,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344.5\" y=\"-778.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"239,-770.5 450,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344.5\" y=\"-755.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140576920122312&#45;&gt;140576898845888 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>140576920122312-&gt;140576898845888</title>\n",
       "<path d=\"M650.7128,-830.4901C572.274,-819.4367 478.2251,-806.1837 398.4982,-794.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"398.74,-791.4484 388.3494,-793.5187 397.7631,-798.3799 398.74,-791.4484\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576897863072 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>140576897863072</title>\n",
       "<polygon fill=\"none\" points=\"468,-747.5 468,-793.5 918,-793.5 918,-747.5 468,-747.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560\" y=\"-766.8\">self_attention_7: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"652,-747.5 652,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"679.5\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"652,-770.5 707,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"679.5\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"707,-747.5 707,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"812.5\" y=\"-778.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"707,-770.5 918,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"812.5\" y=\"-755.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140576920122312&#45;&gt;140576897863072 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>140576920122312-&gt;140576897863072</title>\n",
       "<path d=\"M780.2948,-830.3799C766.3824,-820.8367 750.1012,-809.6686 735.3927,-799.5793\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"737.1704,-796.5544 726.9442,-793.784 733.2107,-802.3269 737.1704,-796.5544\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576897149976 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>140576897149976</title>\n",
       "<polygon fill=\"none\" points=\"936,-747.5 936,-793.5 1386,-793.5 1386,-747.5 936,-747.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1028\" y=\"-766.8\">self_attention_8: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1120,-747.5 1120,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1147.5\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1120,-770.5 1175,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1147.5\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1175,-747.5 1175,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1280.5\" y=\"-778.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1175,-770.5 1386,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1280.5\" y=\"-755.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140576920122312&#45;&gt;140576897149976 -->\n",
       "<g class=\"edge\" id=\"edge16\">\n",
       "<title>140576920122312-&gt;140576897149976</title>\n",
       "<path d=\"M910.198,-830.4901C955.0447,-819.7631 1008.5528,-806.9643 1054.6045,-795.9491\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1055.7034,-799.285 1064.6148,-793.5547 1054.0749,-792.4771 1055.7034,-799.285\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576023808544 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>140576023808544</title>\n",
       "<polygon fill=\"none\" points=\"646,-664.5 646,-710.5 1204,-710.5 1204,-664.5 646,-664.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"686\" y=\"-683.8\">add_2: Add</text>\n",
       "<polyline fill=\"none\" points=\"726,-664.5 726,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"753.5\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"726,-687.5 781,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"753.5\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"781,-664.5 781,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"992.5\" y=\"-695.3\">[(None, 193, 512), (None, 193, 512), (None, 193, 512), (None, 193, 512)]</text>\n",
       "<polyline fill=\"none\" points=\"781,-687.5 1204,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"992.5\" y=\"-672.3\">(None, 193, 512)</text>\n",
       "</g>\n",
       "<!-- 140576899424664&#45;&gt;140576023808544 -->\n",
       "<g class=\"edge\" id=\"edge17\">\n",
       "<title>140576899424664-&gt;140576023808544</title>\n",
       "<path d=\"M1433.8317,-747.4901C1339.4097,-736.358 1226.0627,-722.9946 1130.3378,-711.7089\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1130.5838,-708.2137 1120.2427,-710.5187 1129.7641,-715.1656 1130.5838,-708.2137\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576898845888&#45;&gt;140576023808544 -->\n",
       "<g class=\"edge\" id=\"edge18\">\n",
       "<title>140576898845888-&gt;140576023808544</title>\n",
       "<path d=\"M419.0594,-747.4901C512.9449,-736.358 625.6478,-722.9946 720.8289,-711.7089\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"721.3483,-715.1719 730.8666,-710.5187 720.524,-708.2206 721.3483,-715.1719\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576897863072&#45;&gt;140576023808544 -->\n",
       "<g class=\"edge\" id=\"edge19\">\n",
       "<title>140576897863072-&gt;140576023808544</title>\n",
       "<path d=\"M757.3168,-747.4901C786.3579,-737.1004 820.8314,-724.7672 850.9461,-713.9934\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"852.3215,-717.2187 860.558,-710.5547 849.9635,-710.6278 852.3215,-717.2187\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576897149976&#45;&gt;140576023808544 -->\n",
       "<g class=\"edge\" id=\"edge20\">\n",
       "<title>140576897149976-&gt;140576023808544</title>\n",
       "<path d=\"M1095.5742,-747.4901C1066.0325,-737.1004 1030.9647,-724.7672 1000.3307,-713.9934\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1001.1478,-710.5707 990.553,-710.5547 998.8254,-717.1742 1001.1478,-710.5707\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576899529976 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>140576899529976</title>\n",
       "<polygon fill=\"none\" points=\"706,-581.5 706,-627.5 1144,-627.5 1144,-581.5 706,-581.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"842.5\" y=\"-600.8\">batch_normalization_206: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"979,-581.5 979,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1006.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"979,-604.5 1034,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1006.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1034,-581.5 1034,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1089\" y=\"-612.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1034,-604.5 1144,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1089\" y=\"-589.3\">(None, 193, 512)</text>\n",
       "</g>\n",
       "<!-- 140576023808544&#45;&gt;140576899529976 -->\n",
       "<g class=\"edge\" id=\"edge21\">\n",
       "<title>140576023808544-&gt;140576899529976</title>\n",
       "<path d=\"M925,-664.3799C925,-656.1745 925,-646.7679 925,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"928.5001,-637.784 925,-627.784 921.5001,-637.784 928.5001,-637.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576899527624 -->\n",
       "<g class=\"node\" id=\"node17\">\n",
       "<title>140576899527624</title>\n",
       "<polygon fill=\"none\" points=\"1465,-498.5 1465,-544.5 1915,-544.5 1915,-498.5 1465,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1557\" y=\"-517.8\">self_attention_9: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1649,-498.5 1649,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1676.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1649,-521.5 1704,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1676.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1704,-498.5 1704,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1809.5\" y=\"-529.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1704,-521.5 1915,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1809.5\" y=\"-506.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140576899529976&#45;&gt;140576899527624 -->\n",
       "<g class=\"edge\" id=\"edge22\">\n",
       "<title>140576899529976-&gt;140576899527624</title>\n",
       "<path d=\"M1137.0792,-581.4901C1239.9939,-570.3242 1363.5983,-556.9135 1467.8162,-545.6062\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1468.2758,-549.077 1477.84,-544.5187 1467.5207,-542.1178 1468.2758,-549.077\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576022683320 -->\n",
       "<g class=\"node\" id=\"node18\">\n",
       "<title>140576022683320</title>\n",
       "<polygon fill=\"none\" points=\"39.5,-498.5 39.5,-544.5 496.5,-544.5 496.5,-498.5 39.5,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135\" y=\"-517.8\">self_attention_10: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"230.5,-498.5 230.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"230.5,-521.5 285.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"285.5,-498.5 285.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391\" y=\"-529.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"285.5,-521.5 496.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391\" y=\"-506.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140576899529976&#45;&gt;140576022683320 -->\n",
       "<g class=\"edge\" id=\"edge23\">\n",
       "<title>140576899529976-&gt;140576022683320</title>\n",
       "<path d=\"M742.8614,-581.4901C654.9213,-570.3805 549.3911,-557.0487 460.1713,-545.7774\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"460.5679,-542.2997 450.208,-544.5187 459.6905,-549.2445 460.5679,-542.2997\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576021140760 -->\n",
       "<g class=\"node\" id=\"node19\">\n",
       "<title>140576021140760</title>\n",
       "<polygon fill=\"none\" points=\"514.5,-498.5 514.5,-544.5 971.5,-544.5 971.5,-498.5 514.5,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"610\" y=\"-517.8\">self_attention_11: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"705.5,-498.5 705.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"733\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"705.5,-521.5 760.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"733\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"760.5,-498.5 760.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"866\" y=\"-529.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"760.5,-521.5 971.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"866\" y=\"-506.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140576899529976&#45;&gt;140576021140760 -->\n",
       "<g class=\"edge\" id=\"edge24\">\n",
       "<title>140576899529976-&gt;140576021140760</title>\n",
       "<path d=\"M874.3029,-581.3799C852.2088,-571.304 826.1427,-559.4167 803.0827,-548.9003\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.2914,-545.6048 793.7406,-544.6399 801.3869,-551.9738 804.2914,-545.6048\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576020299280 -->\n",
       "<g class=\"node\" id=\"node20\">\n",
       "<title>140576020299280</title>\n",
       "<polygon fill=\"none\" points=\"989.5,-498.5 989.5,-544.5 1446.5,-544.5 1446.5,-498.5 989.5,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1085\" y=\"-517.8\">self_attention_12: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1180.5,-498.5 1180.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1208\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1180.5,-521.5 1235.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1208\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1235.5,-498.5 1235.5,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1341\" y=\"-529.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1235.5,-521.5 1446.5,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1341\" y=\"-506.3\">[(None, 193, 512), (193, 193), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140576899529976&#45;&gt;140576020299280 -->\n",
       "<g class=\"edge\" id=\"edge25\">\n",
       "<title>140576899529976-&gt;140576020299280</title>\n",
       "<path d=\"M1006.2277,-581.4901C1043.6984,-570.8755 1088.3302,-558.2324 1126.9368,-547.2961\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1127.9468,-550.6478 1136.6143,-544.5547 1126.0389,-543.9128 1127.9468,-550.6478\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576019602456 -->\n",
       "<g class=\"node\" id=\"node21\">\n",
       "<title>140576019602456</title>\n",
       "<polygon fill=\"none\" points=\"939,-415.5 939,-461.5 1497,-461.5 1497,-415.5 939,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"979\" y=\"-434.8\">add_3: Add</text>\n",
       "<polyline fill=\"none\" points=\"1019,-415.5 1019,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1046.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1019,-438.5 1074,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1046.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1074,-415.5 1074,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1285.5\" y=\"-446.3\">[(None, 193, 512), (None, 193, 512), (None, 193, 512), (None, 193, 512)]</text>\n",
       "<polyline fill=\"none\" points=\"1074,-438.5 1497,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1285.5\" y=\"-423.3\">(None, 193, 512)</text>\n",
       "</g>\n",
       "<!-- 140576899527624&#45;&gt;140576019602456 -->\n",
       "<g class=\"edge\" id=\"edge26\">\n",
       "<title>140576899527624-&gt;140576019602456</title>\n",
       "<path d=\"M1559.1485,-498.4901C1496.9957,-487.5607 1422.6126,-474.4806 1359.1877,-463.3275\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1359.5611,-459.8395 1349.106,-461.5547 1358.3487,-466.7338 1359.5611,-459.8395\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576022683320&#45;&gt;140576019602456 -->\n",
       "<g class=\"edge\" id=\"edge27\">\n",
       "<title>140576022683320-&gt;140576019602456</title>\n",
       "<path d=\"M496.6101,-498.7698C499.423,-498.5105 502.2206,-498.2538 505,-498 644.3971,-485.2734 799.2286,-472.2218 928.8955,-461.5974\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"929.2967,-465.0764 938.9778,-460.772 928.7255,-458.0997 929.2967,-465.0764\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576021140760&#45;&gt;140576019602456 -->\n",
       "<g class=\"edge\" id=\"edge28\">\n",
       "<title>140576021140760-&gt;140576019602456</title>\n",
       "<path d=\"M874.6832,-498.4901C937.231,-487.5607 1012.0868,-474.4806 1075.9149,-463.3275\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1076.8124,-466.7238 1086.0607,-461.5547 1075.6074,-459.8283 1076.8124,-466.7238\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576020299280&#45;&gt;140576019602456 -->\n",
       "<g class=\"edge\" id=\"edge29\">\n",
       "<title>140576020299280-&gt;140576019602456</title>\n",
       "<path d=\"M1218,-498.3799C1218,-490.1745 1218,-480.7679 1218,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1221.5001,-471.784 1218,-461.784 1214.5001,-471.784 1221.5001,-471.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576023074968 -->\n",
       "<g class=\"node\" id=\"node22\">\n",
       "<title>140576023074968</title>\n",
       "<polygon fill=\"none\" points=\"1238,-332.5 1238,-378.5 1676,-378.5 1676,-332.5 1238,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1374.5\" y=\"-351.8\">batch_normalization_207: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1511,-332.5 1511,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1538.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1511,-355.5 1566,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1538.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1566,-332.5 1566,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1621\" y=\"-363.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1566,-355.5 1676,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1621\" y=\"-340.3\">(None, 193, 512)</text>\n",
       "</g>\n",
       "<!-- 140576019602456&#45;&gt;140576023074968 -->\n",
       "<g class=\"edge\" id=\"edge30\">\n",
       "<title>140576019602456-&gt;140576023074968</title>\n",
       "<path d=\"M1284.2574,-415.4901C1314.3042,-405.0554 1349.9959,-392.6604 1381.1144,-381.8536\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1382.3153,-385.1416 1390.6137,-378.5547 1380.0189,-378.529 1382.3153,-385.1416\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576023074688 -->\n",
       "<g class=\"node\" id=\"node23\">\n",
       "<title>140576023074688</title>\n",
       "<polygon fill=\"none\" points=\"1406,-249.5 1406,-295.5 1774,-295.5 1774,-249.5 1406,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1507.5\" y=\"-268.8\">sa_gap: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"1609,-249.5 1609,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1636.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1609,-272.5 1664,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1636.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1664,-249.5 1664,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1719\" y=\"-280.3\">(None, 193, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1664,-272.5 1774,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1719\" y=\"-257.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140576023074968&#45;&gt;140576023074688 -->\n",
       "<g class=\"edge\" id=\"edge31\">\n",
       "<title>140576023074968-&gt;140576023074688</title>\n",
       "<path d=\"M1494.0479,-332.3799C1509.4829,-322.7475 1527.5706,-311.4597 1543.8559,-301.2967\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1546.0589,-304.0476 1552.6895,-295.784 1542.3529,-298.1091 1546.0589,-304.0476\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576023074688&#45;&gt;140576018738424 -->\n",
       "<g class=\"edge\" id=\"edge32\">\n",
       "<title>140576023074688-&gt;140576018738424</title>\n",
       "<path d=\"M1650.9901,-249.4901C1678.4098,-239.1454 1710.9365,-226.874 1739.4054,-216.1334\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1740.7704,-219.3593 1748.8912,-212.5547 1738.2995,-212.8099 1740.7704,-219.3593\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576018738760 -->\n",
       "<g class=\"node\" id=\"node26\">\n",
       "<title>140576018738760</title>\n",
       "<polygon fill=\"none\" points=\"1473,-.5 1473,-46.5 1861,-46.5 1861,-.5 1473,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1557\" y=\"-19.8\">concatenate_1: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"1641,-.5 1641,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1668.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1641,-23.5 1696,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1668.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1696,-.5 1696,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1778.5\" y=\"-31.3\">[(None, 512), (None, 512)]</text>\n",
       "<polyline fill=\"none\" points=\"1696,-23.5 1861,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1778.5\" y=\"-8.3\">(None, 1024)</text>\n",
       "</g>\n",
       "<!-- 140576023074688&#45;&gt;140576018738760 -->\n",
       "<g class=\"edge\" id=\"edge36\">\n",
       "<title>140576023074688-&gt;140576018738760</title>\n",
       "<path d=\"M1592.7584,-249.343C1595.6741,-227.5619 1600.9738,-194.1784 1609,-166 1619.8747,-127.8209 1626.9772,-119.7453 1642,-83 1645.5737,-74.2589 1649.504,-64.8242 1653.1687,-56.1002\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1656.5026,-57.2015 1657.1604,-46.6271 1650.0519,-54.4834 1656.5026,-57.2015\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576018739040 -->\n",
       "<g class=\"node\" id=\"node25\">\n",
       "<title>140576018739040</title>\n",
       "<polygon fill=\"none\" points=\"1650.5,-83.5 1650.5,-129.5 1903.5,-129.5 1903.5,-83.5 1650.5,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1701\" y=\"-102.8\">a_gap: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"1751.5,-83.5 1751.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1779\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1751.5,-106.5 1806.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1779\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1806.5,-83.5 1806.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1855\" y=\"-114.3\">(None, 1, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1806.5,-106.5 1903.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1855\" y=\"-91.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140576018738424&#45;&gt;140576018739040 -->\n",
       "<g class=\"edge\" id=\"edge34\">\n",
       "<title>140576018738424-&gt;140576018739040</title>\n",
       "<path d=\"M1800.8077,-166.3799C1797.4744,-157.9962 1793.6425,-148.3584 1790.0408,-139.2996\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1793.2045,-137.7834 1786.2575,-129.784 1786.6998,-140.3696 1793.2045,-137.7834\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576018739040&#45;&gt;140576018738760 -->\n",
       "<g class=\"edge\" id=\"edge35\">\n",
       "<title>140576018739040-&gt;140576018738760</title>\n",
       "<path d=\"M1746.3589,-83.3799C1733.8295,-73.9259 1719.1866,-62.8772 1705.9141,-52.8625\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1707.949,-50.0133 1697.8583,-46.784 1703.7328,-55.6011 1707.949,-50.0133\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(textNet, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Complete Joint Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q.shape,k.shape,v.shape, (?, 1, 64) (?, 193, 64) (?, 193, 512)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_input = Input(shape=(256,256,3),name='image_input')\n",
    "image_features = imgNet(image_input)\n",
    "image_features = kl.Dropout(0.1)(image_features)\n",
    "image_features = kl.Flatten()(image_features)\n",
    "image_features = kl.Dense(512,activation='relu')(image_features)\n",
    "\n",
    "words_input = kl.Input(shape=(max_wlen,),name='words_input')\n",
    "text_features = textNet(words_input)\n",
    "text_features = kl.Dropout(0.1)(text_features)\n",
    "text_features = kl.Dense(512,activation='relu')(text_features)\n",
    "\n",
    "g = kl.Concatenate()([image_features,text_features])\n",
    "g = kl.Dense(512, activation='relu')(g)\n",
    "target = Dense(vocab_size+1, activation='softmax',name='target_word')(g)\n",
    "model = Model([image_input,words_input],target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model irv2_1dcnn_attention_words. loading word2vec embeddings\n",
      "Existing model irv2_1dcnn_attention_words. trained weights will be loaded\n"
     ]
    }
   ],
   "source": [
    "print('New model {0}. loading word2vec embeddings'.format(model_name))\n",
    "l = textNet.get_layer('w2v_emb')\n",
    "l.set_weights([embedding_matrix])\n",
    "l.trainable = True\n",
    "if not os.path.exists('../checkpoints/{0}.h5'.format(model_name)):\n",
    "    print('New model {0}. loading word2vec embeddings'.format(model_name))\n",
    "    l = textNet.get_layer('w2v_emb')\n",
    "    l.set_weights([embedding_matrix])\n",
    "    l.trainable = True\n",
    "else:\n",
    "    print('Existing model {0}. trained weights will be loaded'.format(model_name))\n",
    "#     model.load_weights('../checkpoints/{0}.h5'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_to_co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_resnet_v2 (Model)     (None, 6, 6, 1536)   54336736    image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, 193)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6, 6, 1536)   0           inception_resnet_v2[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "textModel (Model)               (None, 1024)         8735104     words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 55296)        0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           textModel[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          28312064    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          524800      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1024)         0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          524800      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "target_word (Dense)             (None, 1943)         996759      dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 93,430,263\n",
      "Trainable params: 93,365,623\n",
      "Non-trainable params: 64,640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001,decay=1e-6),metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"636pt\" viewBox=\"0.00 0.00 666.00 636.00\" width=\"666pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 632)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-632 662,-632 662,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140576015753000 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140576015753000</title>\n",
       "<polygon fill=\"none\" points=\"9,-581.5 9,-627.5 341,-627.5 341,-581.5 9,-581.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-600.8\">image_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"161,-581.5 161,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"161,-604.5 216,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"216,-581.5 216,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-612.3\">(None, 256, 256, 3)</text>\n",
       "<polyline fill=\"none\" points=\"216,-604.5 341,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-589.3\">(None, 256, 256, 3)</text>\n",
       "</g>\n",
       "<!-- 140577091252064 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140577091252064</title>\n",
       "<polygon fill=\"none\" points=\"0,-498.5 0,-544.5 350,-544.5 350,-498.5 0,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-517.8\">inception_resnet_v2: Model</text>\n",
       "<polyline fill=\"none\" points=\"170,-498.5 170,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"170,-521.5 225,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"225,-498.5 225,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-529.3\">(None, 256, 256, 3)</text>\n",
       "<polyline fill=\"none\" points=\"225,-521.5 350,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-506.3\">(None, 6, 6, 1536)</text>\n",
       "</g>\n",
       "<!-- 140576015753000&#45;&gt;140577091252064 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140576015753000-&gt;140577091252064</title>\n",
       "<path d=\"M175,-581.3799C175,-573.1745 175,-563.7679 175,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"178.5001,-554.784 175,-544.784 171.5001,-554.784 178.5001,-554.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576015774496 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140576015774496</title>\n",
       "<polygon fill=\"none\" points=\"46,-415.5 46,-461.5 344,-461.5 344,-415.5 46,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108.5\" y=\"-434.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"171,-415.5 171,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"171,-438.5 226,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"226,-415.5 226,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285\" y=\"-446.3\">(None, 6, 6, 1536)</text>\n",
       "<polyline fill=\"none\" points=\"226,-438.5 344,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"285\" y=\"-423.3\">(None, 6, 6, 1536)</text>\n",
       "</g>\n",
       "<!-- 140577091252064&#45;&gt;140576015774496 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140577091252064-&gt;140576015774496</title>\n",
       "<path d=\"M180.5711,-498.3799C182.5698,-490.0854 184.8643,-480.5633 187.0268,-471.5889\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"190.4493,-472.3257 189.3894,-461.784 183.6441,-470.6858 190.4493,-472.3257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576015774104 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140576015774104</title>\n",
       "<polygon fill=\"none\" points=\"368,-498.5 368,-544.5 658,-544.5 658,-498.5 368,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"444\" y=\"-517.8\">words_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"520,-498.5 520,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"547.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"520,-521.5 575,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"547.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"575,-498.5 575,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"616.5\" y=\"-529.3\">(None, 193)</text>\n",
       "<polyline fill=\"none\" points=\"575,-521.5 658,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"616.5\" y=\"-506.3\">(None, 193)</text>\n",
       "</g>\n",
       "<!-- 140576018184456 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140576018184456</title>\n",
       "<polygon fill=\"none\" points=\"372,-415.5 372,-461.5 632,-461.5 632,-415.5 372,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"430\" y=\"-434.8\">textModel: Model</text>\n",
       "<polyline fill=\"none\" points=\"488,-415.5 488,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"515.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"488,-438.5 543,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"515.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"543,-415.5 543,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587.5\" y=\"-446.3\">(None, 193)</text>\n",
       "<polyline fill=\"none\" points=\"543,-438.5 632,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587.5\" y=\"-423.3\">(None, 1024)</text>\n",
       "</g>\n",
       "<!-- 140576015774104&#45;&gt;140576018184456 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140576015774104-&gt;140576018184456</title>\n",
       "<path d=\"M509.9359,-498.3799C508.8484,-490.1745 507.6018,-480.7679 506.4237,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"509.8694,-471.2375 505.0858,-461.784 502.9301,-472.1572 509.8694,-471.2375\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576015752944 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140576015752944</title>\n",
       "<polygon fill=\"none\" points=\"54.5,-332.5 54.5,-378.5 337.5,-378.5 337.5,-332.5 54.5,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"109.5\" y=\"-351.8\">flatten_1: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"164.5,-332.5 164.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"164.5,-355.5 219.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"219.5,-332.5 219.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-363.3\">(None, 6, 6, 1536)</text>\n",
       "<polyline fill=\"none\" points=\"219.5,-355.5 337.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-340.3\">(None, 55296)</text>\n",
       "</g>\n",
       "<!-- 140576015774496&#45;&gt;140576015752944 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140576015774496-&gt;140576015752944</title>\n",
       "<path d=\"M195.2786,-415.3799C195.3774,-407.1745 195.4907,-397.7679 195.5978,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"199.0986,-388.8255 195.7195,-378.784 192.0992,-388.7411 199.0986,-388.8255\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576948994624 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140576948994624</title>\n",
       "<polygon fill=\"none\" points=\"361.5,-332.5 361.5,-378.5 630.5,-378.5 630.5,-332.5 361.5,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"424\" y=\"-351.8\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"486.5,-332.5 486.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"514\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"486.5,-355.5 541.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"514\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"541.5,-332.5 541.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"586\" y=\"-363.3\">(None, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"541.5,-355.5 630.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"586\" y=\"-340.3\">(None, 1024)</text>\n",
       "</g>\n",
       "<!-- 140576018184456&#45;&gt;140576948994624 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140576018184456-&gt;140576948994624</title>\n",
       "<path d=\"M500.3287,-415.3799C499.7355,-407.1745 499.0555,-397.7679 498.4129,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"501.8952,-388.5056 497.6832,-378.784 494.9134,-389.0104 501.8952,-388.5056\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576015773880 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140576015773880</title>\n",
       "<polygon fill=\"none\" points=\"82.5,-249.5 82.5,-295.5 335.5,-295.5 335.5,-249.5 82.5,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133.5\" y=\"-268.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-249.5 184.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-272.5 239.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"239.5,-249.5 239.5,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-280.3\">(None, 55296)</text>\n",
       "<polyline fill=\"none\" points=\"239.5,-272.5 335.5,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-257.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140576015752944&#45;&gt;140576015773880 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140576015752944-&gt;140576015773880</title>\n",
       "<path d=\"M199.6212,-332.3799C200.9064,-324.1745 202.3797,-314.7679 203.772,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"207.2635,-306.2052 205.3531,-295.784 200.3478,-305.1219 207.2635,-306.2052\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576948995072 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>140576948995072</title>\n",
       "<polygon fill=\"none\" points=\"363,-249.5 363,-295.5 609,-295.5 609,-249.5 363,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"414\" y=\"-268.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"465,-249.5 465,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"465,-272.5 520,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"520,-249.5 520,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"564.5\" y=\"-280.3\">(None, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"520,-272.5 609,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"564.5\" y=\"-257.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140576948994624&#45;&gt;140576948995072 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140576948994624-&gt;140576948995072</title>\n",
       "<path d=\"M493.2144,-332.3799C492.2258,-324.1745 491.0925,-314.7679 490.0215,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"493.4764,-305.2935 488.8053,-295.784 486.5267,-306.1309 493.4764,-305.2935\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576948995016 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>140576948995016</title>\n",
       "<polygon fill=\"none\" points=\"149,-166.5 149,-212.5 537,-212.5 537,-166.5 149,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233\" y=\"-185.8\">concatenate_2: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"317,-166.5 317,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"317,-189.5 372,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"372,-166.5 372,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"454.5\" y=\"-197.3\">[(None, 512), (None, 512)]</text>\n",
       "<polyline fill=\"none\" points=\"372,-189.5 537,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"454.5\" y=\"-174.3\">(None, 1024)</text>\n",
       "</g>\n",
       "<!-- 140576015773880&#45;&gt;140576948995016 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>140576015773880-&gt;140576948995016</title>\n",
       "<path d=\"M246.3265,-249.3799C261.8775,-239.7475 280.1012,-228.4597 296.5089,-218.2967\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"298.7507,-221.0252 305.409,-212.784 295.0646,-215.0743 298.7507,-221.0252\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576948995072&#45;&gt;140576948995016 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>140576948995072-&gt;140576948995016</title>\n",
       "<path d=\"M446.1665,-249.3799C429.4174,-239.6583 409.7629,-228.2505 392.1277,-218.0147\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"393.5215,-214.7769 383.1158,-212.784 390.0076,-220.831 393.5215,-214.7769\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576950678136 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>140576950678136</title>\n",
       "<polygon fill=\"none\" points=\"220,-83.5 220,-129.5 466,-129.5 466,-83.5 220,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-102.8\">dense_3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"322,-83.5 322,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"322,-106.5 377,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"377,-83.5 377,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-114.3\">(None, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"377,-106.5 466,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-91.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140576948995016&#45;&gt;140576950678136 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>140576948995016-&gt;140576950678136</title>\n",
       "<path d=\"M343,-166.3799C343,-158.1745 343,-148.7679 343,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"346.5001,-139.784 343,-129.784 339.5001,-139.784 346.5001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140576950678752 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>140576950678752</title>\n",
       "<polygon fill=\"none\" points=\"209.5,-.5 209.5,-46.5 476.5,-46.5 476.5,-.5 209.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271\" y=\"-19.8\">target_word: Dense</text>\n",
       "<polyline fill=\"none\" points=\"332.5,-.5 332.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"332.5,-23.5 387.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"360\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"387.5,-.5 387.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"432\" y=\"-31.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"387.5,-23.5 476.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"432\" y=\"-8.3\">(None, 1943)</text>\n",
       "</g>\n",
       "<!-- 140576950678136&#45;&gt;140576950678752 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>140576950678136-&gt;140576950678752</title>\n",
       "<path d=\"M343,-83.3799C343,-75.1745 343,-65.7679 343,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"346.5001,-56.784 343,-46.784 339.5001,-56.784 346.5001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"../model_json/{0}.json\".format(model_name), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "words_input (InputLayer)     (None, 193)               0         \n",
      "_________________________________________________________________\n",
      "w2v_emb (Embedding)          (None, 193, 300)          582900    \n",
      "=================================================================\n",
      "Total params: 582,900\n",
      "Trainable params: 582,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "emb = Model(textNet.inputs,textNet.get_layer('w2v_emb').output)\n",
    "emb.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fda5eaca8d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('../dataset/images/images_normalized/3591_IM-1770-1001-0001.dcm.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen(img_lst,batch_size=4):\n",
    "    counter=0\n",
    "    x1,x2,y,sents = [],[],[],[]\n",
    "    idx = 0\n",
    "    while True:\n",
    "        im = img_lst[idx]\n",
    "        photo = cv2.imread('../dataset/images/images_normalized/resized_1024/{0}'.format(im))/255.0\n",
    "        sent = merged_ds[merged_ds.filename==im]['findings'].values[0].lower().replace('/',' ')\n",
    "        \n",
    "        ts = nlp('startseq ' + sent + ' endseq')\n",
    "#         print(ts)\n",
    "        ts = [str(x) for x in list(ts)]\n",
    "#         print(tss)\n",
    "        sent_words = []\n",
    "        for t in ts:\n",
    "#             print(t)\n",
    "#             t = 'sdadasasdasads'\n",
    "            if (t not in w_to_co.keys()) : #or ('xx' in t):\n",
    "#                 print('not present:',t)\n",
    "                pass\n",
    "            else:\n",
    "                sent_words.append(t)\n",
    "#         print(sent_words)\n",
    "        seq = [w_to_co[x] for x in sent_words]\n",
    "        # split one sequence into multiple X, y pairs\n",
    "        for i in range(1, len(seq)):\n",
    "            # split into input and output pair\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "#             print(out_seq)\n",
    "            in_seq = sequence.pad_sequences([in_seq], maxlen=max_wlen,padding='pre',value=0)[0]\n",
    "            out_seq = np_utils.to_categorical([out_seq], num_classes=vocab_size+1)[0]\n",
    "            x1.append(photo)\n",
    "            x2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "            sents.append(sent)\n",
    "        counter+=1\n",
    "        idx+=1\n",
    "#         print(idx)\n",
    "        if idx==len(img_lst):\n",
    "            idx=0\n",
    "        if counter==batch_size:\n",
    "            counter=0\n",
    "            inputs = {'image_input': np.array(x1),\n",
    "                      'words_input': np.array(x2)\n",
    "                     }\n",
    "            outputs = {'target_word':np.array(y),\n",
    "                      'actual_sentence':np.array(sents)}\n",
    "            yield inputs, outputs\n",
    "            x1,x2,y,sents = [],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 5511 + val: 646 + test: 300  =  6457\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('../dataset/train_images.p', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    train_images_list = pickle.load(filehandle)\n",
    "with open('../dataset/val_images.p', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    val_images_list = pickle.load(filehandle)\n",
    "with open('../dataset/test_images.p', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    test_images_list = pickle.load(filehandle)\n",
    "\n",
    "print('train:',len(train_images_list),\n",
    "      '+ val:',len(val_images_list),\n",
    "      '+ test:',len(test_images_list),\n",
    "      ' = ',(len(train_images_list)+len(val_images_list)+len(test_images_list)))\n",
    "train_batch_size = 64\n",
    "val_batch_size = 64\n",
    "test_batch_size = 1\n",
    "train_gen = datagen(train_images_list,batch_size=train_batch_size)\n",
    "val_gen = datagen(val_images_list,batch_size=val_batch_size)\n",
    "test_gen = datagen(test_images_list,batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.intersect1d(ar1=val_images_list,ar2=test_images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = merged_ds.filename.values\n",
    "# np.random.shuffle(imgs)\n",
    "\n",
    "# train_images_list = imgs[:int(0.7*len(imgs))]\n",
    "# val_images_list = imgs[int(0.7*len(imgs)):int(0.8*len(imgs))]\n",
    "# test_images_list = imgs[int(0.8*len(imgs)):]\n",
    "# with open('../dataset/train_images.p', 'wb') as file:\n",
    "#     # store the data as binary data stream\n",
    "#     pickle.dump(train_images_list, file)\n",
    "# with open('../dataset/val_images.p', 'wb') as file:\n",
    "#     # store the data as binary data stream\n",
    "#     pickle.dump(val_images_list, file)\n",
    "# with open('../dataset/test_images.p', 'wb') as file:\n",
    "#     # store the data as binary data stream\n",
    "#     pickle.dump(test_images_list_r, file)\n",
    "# with open('../dataset/chestxray_cnn_attention_decoder_ref_sents.p', 'wb') as file:\n",
    "#     # store the data as binary data stream\n",
    "#     pickle.dump(ref_sents, file)\n",
    "# with open('../dataset/chestxray_cnn_attention_decoder_pred_sents.p', 'wb') as file:\n",
    "#     # store the data as binary data stream\n",
    "#     pickle.dump(pred_sents, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tx,ty = next(train_gen)\n",
    "# display(tx['image_input'].shape\n",
    "#         ,tx['words_input'][30]\n",
    "#         ,' '.join([co_to_w[x] if x !=0 else '' for x in tx['words_input'][30]])\n",
    "#         ,ty['actual_sentence'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def _ctc_lambda_func(args):\n",
    "# #     labels, y_pred, input_length, label_length = args\n",
    "# #     return K.tf.keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "# vggnet.summary()\n",
    "# w_to_co['xxxx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(co_to_w[1358])\n",
    "# print(embedding_matrix[1380])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# emb_out = emb.predict(tx['words_input'])\n",
    "# emb_out[1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parallel_model=multi_gpu_model(model, gpus=4)\n",
    "\n",
    "# parallel_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001,decay=1e-06),metrics=['accuracy']) #For multi GPU\n",
    "# parallel_model.summary()\n",
    "# # model_resnet.summary()\n",
    "# # parallel_model.load_weights('./../checkpoints/sa_vgg16_3d_32x24_m32_direct.h5', by_name=True, skip_mismatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training irv2_1dcnn_attention_words for 10 epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mc=ModelCheckpoint(filepath='../checkpoints/vgg16_lstm_words.h5',monitor='val_loss',period=1,save_best_only=True,save_weights_only=True,mode='auto',verbose=3)\n",
    "# es=EarlyStopping(patience=300,monitor='val_loss',min_delta=0.0001,mode='auto')\n",
    "print('training {0} for {1} epochs'.format(model_name,EPOCHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:  5/10, tr_loss:0.6760, tr_acc:0.8232, v_loss:3.5285, v_acc:0.4932 [4527.19 s/e] (min_v_loss:2.0567)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4893d98dc0464e88d0f942df60d548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train_Iter', max=87.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-caa33fe4e70a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# counter = 0\n",
    "model.load_weights('../checkpoints/{0}.h5'.format(model_name))\n",
    "# history = model.fit_generator(train_gen\n",
    "#                               ,epochs=EPOCHS\n",
    "#                               ,steps_per_epoch=4\n",
    "#                               ,validation_data=val_gen\n",
    "#                               ,validation_steps=2\n",
    "#                               ,callbacks=[mc])\n",
    "\n",
    "hist_tl,hist_ta,hist_vl,hist_va,tt = [],[],[],[],[]\n",
    "window = 32\n",
    "val_window = 128\n",
    "train_iterations = int(np.ceil(len(train_images_list)/train_batch_size))\n",
    "val_iterations = int(np.ceil(len(val_images_list)/val_batch_size))\n",
    "\n",
    "\n",
    "min_v_l = 10\n",
    "t_l, t_a, v_l, v_a = 0, 0, 2.4, 0\n",
    "for e in tqdm_notebook(np.arange(start=0,stop=EPOCHS),desc='Epoch'):\n",
    "    start_time = time()\n",
    "    tl,ta,vl,va = [],[],[],[]\n",
    "    for im in tqdm_notebook(range(train_iterations),desc='Train_Iter',leave=False):\n",
    "        tx,ty = next(train_gen)\n",
    "        inputs1 = tx['image_input']\n",
    "        inputs2 = tx['words_input']\n",
    "        labels = ty['target_word']        \n",
    "        for i in np.arange(len(inputs1),step=window):\n",
    "            loss,accuracy = model.train_on_batch([inputs1[i:i+window],inputs2[i:i+window]],labels[i:i+window])\n",
    "            tl.append(loss)\n",
    "            ta.append(accuracy)\n",
    "    for im in tqdm_notebook(range(val_iterations),desc='Val_Iter',leave=False):\n",
    "        vx,vy = next(val_gen)\n",
    "        inputs1 = vx['image_input']\n",
    "        inputs2 = vx['words_input']\n",
    "        labels = vy['target_word']\n",
    "        for i in np.arange(len(inputs1),step=val_window):\n",
    "            loss,accuracy = model.evaluate(verbose=0,x=[inputs1[i:i+val_window],inputs2[i:i+val_window]],y=labels[i:i+val_window])\n",
    "            vl.append(loss)\n",
    "            va.append(accuracy)\n",
    "    v_l = np.round(np.mean(vl),4)\n",
    "    v_a = np.round(np.mean(va),4)\n",
    "    t_l = np.round(np.mean(tl),4)\n",
    "    t_a = np.round(np.mean(ta),4)\n",
    "    \n",
    "    hist_tl.append(t_l)\n",
    "    hist_ta.append(t_a)\n",
    "    hist_vl.append(v_l)\n",
    "    hist_va.append(v_a)\n",
    "    if v_l < min_v_l:\n",
    "        min_v_l = v_l\n",
    "        model.save_weights(filepath='../checkpoints/{0}.h5'.format(model_name),overwrite=True)\n",
    "        imgNet.save_weights(filepath='../checkpoints/{0}_{1}_img_module.h5'.format(img_arch,text_arch),overwrite=True)\n",
    "        textNet.save_weights(filepath='../checkpoints/{0}_{1}_text_module.h5'.format(img_arch,text_arch),overwrite=True)\n",
    "    clear_output(wait=True)\n",
    "    end_time = time()\n",
    "    time_taken = end_time-start_time\n",
    "    tt.append(time_taken)\n",
    "    print('E:{0:3d}/{7}, tr_loss:{1:.4f}, tr_acc:{2:.4f}, v_loss:{3:.4f}, v_acc:{4:.4f} [{5:.2f} s/e] (min_v_loss:{6:.4f})'.format(e+1, t_l, t_a, v_l, v_a, np.mean(tt),min_v_l,EPOCHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fda22f57c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fda22e86a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3XmcFPWd//HXZ2Z6GGBQEBCQUwyKCgkaJBpXQtR4i7eiiKJRf9GsUTeHmsMk/pLdbNyf+8uuicZciqJBAQ1BNDHRhLgbjQM7yGUIEo8BlAHkZq7uz/5RPTDT9Mz0MN1d3cX7+Xj0o2uqv1316YJ+f+vqKnN3REQkWkrCLkBERLJP4S4iEkEKdxGRCFK4i4hEkMJdRCSCFO4iIhGkcBcRiSCFu4hIBCncRUQiqCysGffr189HjBgR1uxFRIrSokWLNrp7/47ahRbuI0aMoKqqKqzZi4gUJTN7J5N22i0jIhJBCncRkQhSuIuIRFBo+9zTaWxspKamhrq6urBLKWgVFRUMGTKEWCwWdikiUqAKKtxramro1asXI0aMwMzCLqcguTubNm2ipqaGww8/POxyRKRAFdRumbq6Ovr27atgb4eZ0bdvX23diEi7CircAQV7BrSMRKQjHYa7mVWY2V/MbImZLTezb6dpM93Mas2sOvm4ITfliogUMXf44/fh/aU5n1Um+9zrgVPdfYeZxYBXzOx5d381pd0sd//H7JcoIhIB7vDbr8OfH4DGXTBwbE5n1+Gauwd2JP+MJR+RvKv2li1b+NGPftSp91RWVuaoGhGJDHf4zVeDYJ9wE5z2zZzPMqN97mZWambVwAbgRXd/LU2zS8zsDTObbWZD25jOTWZWZWZVtbW1XSg7N9oK93g8HkI1IhIJ7vD8nfDqj+ATN8PZ34c8HDfL6FRId48D48ysN/CMmY1x92UtmvwaeNLd683sc8CjwKlppvMw8DDA+PHj2137//avl7Ni3bYMP0ZmjjnsIL55/rFtvn7XXXfx1ltvMW7cOGKxGJWVlQwaNIjq6mpWrFjR7rTdna985Ss8//zzmBlf//rXueKKK1i/fj1XXHEF27Zto6mpiQcffJBPfvKTfPazn6Wqqgoz4/rrr+eOO+7I6mcVkQKQSMDzX4bXfwon/SOc8Z28BDt08jx3d99iZn8AzgKWtRi/qUWznwD/mpXq8ux73/sey5Yto7q6mj/84Q+ce+65LFu2LKPzyefOnUt1dTVLlixh48aNnHDCCUycOJEnnniCM888k6997WvE43F27dpFdXU1a9euZdmyYBFu2bIl1x9NRPItkYDn/gkW/QJOvg1O/3begh0yCHcz6w80JoO9O3A6KeFtZoPcfX3yz8nAyq4W1t4adr5MmDAh4x8KvfLKK1x55ZWUlpYyYMAAPvWpT/H6669zwgkncP3119PY2MiFF17IuHHjGDlyJGvWrOHWW2/l3HPP5YwzzsjxJxGRvEokYP5tsHgG/MM/wWn35DXYIbN97oOAl83sDeB1gn3u883sXjObnGzzheRpkkuALwDTc1NufvXs2TPjtu7p9zJNnDiRhQsXMnjwYKZNm8aMGTPo06cPS5YsYdKkSfzwhz/khht05qhIZCTiMO/WINgnfjmUYIcM1tzd/Q3guDTj72kxfDdwd3ZLy79evXqxffv2/XrvxIkT+fGPf8y1117L5s2bWbhwIffddx/vvPMOgwcP5sYbb2Tnzp0sXryYc845h/Lyci655BKOOOIIpk+fnt0PIiLhSMThV5+HJU/CpLth0l2hlVJQ15YJW9++fTn55JMZM2YM3bt3Z8CAARm/96KLLuLPf/4zH/vYxzAzvv/97zNw4EAeffRR7rvvvj0HaGfMmMHatWu57rrrSCQSAPzLv/xLrj6SiORLvAmevRmWPgWf/hp86iuhlmNt7U7ItfHjx3vqnZhWrlzJ0UcfHUo9xUbLSqSAxJvgmZtg2Rw49Rsw8Us5m5WZLXL38R2105q7iEhXxBth7o2w/Bk4/VvwD4VxWrPCPQObNm3itNNO22f873//e/r27RtCRSJSEOKNMPt6WDkvOIf9k7eGXdEeCvcM9O3bl+rq6rDLEJFC0tQAs6+DN+fDmf8MJ30+7IpaUbiLiHRWUz08PR3+ugDO+lc48XNhV7QPhbuISGc01cOsafC338A5/wYTbgy7orQU7iIimWqsg1lXw+oX4bx/h/HXh11RmxTuIiKZaNwNv5wKb/0ezv8BfHx62BW1q+Bus1dM2ruW+9tvv82YMWPyWI2I5EzDLnhyCrz1Ekx+oOCDHbTmLiLSvoadQbD//U9w4Y9g3FVhV5SRwg335+/K/n0GB46Fs7/X5st33nknw4cP55ZbbgHgW9/6FmbGwoUL+fDDD2lsbOQ73/kOF1xwQadmW1dXx80330xVVRVlZWXcf//9fPrTn2b58uVcd911NDQ0kEgkmDNnDocddhiXX345NTU1xONxvvGNb3DFFVd06WOLyH6q3xEE+zv/BRf9GD5WPN/Fwg33EEyZMoXbb799T7g/9dRTvPDCC9xxxx0cdNBBbNy4kRNPPJHJkydjnbjK2w9/+EMAli5dyptvvskZZ5zBqlWreOihh7jtttuYOnUqDQ0NxONxFixYwGGHHcZzzz0HwNatW7P/QUWkY/XbYebl8N6rcNHD8NHLwq6oUwo33NtZw86V4447jg0bNrBu3Tpqa2vp06cPgwYN4o477mDhwoWUlJSwdu1aPvjgAwYOHJjxdF955RVuvTX45dro0aMZPnw4q1at4qSTTuK73/0uNTU1XHzxxYwaNYqxY8fypS99iTvvvJPzzjuPU045JVcfV0TaUrcNZl4GNa/DJT+FMZeEXVGn6YBqiksvvZTZs2cza9YspkyZwsyZM6mtrWXRokVUV1czYMAA6urqOjXNti7OdtVVVzFv3jy6d+/OmWeeyUsvvcSRRx7JokWLGDt2LHfffTf33ntvNj6WiGSqbis8fgmsrYJLf16UwQ6FvOYekilTpnDjjTeyceNG/vjHP/LUU09x6KGHEovFePnll3nnnXc6Pc2JEycyc+ZMTj31VFatWsW7777LUUcdxZo1axg5ciRf+MIXWLNmDW+88QajR4/mkEMO4eqrr6ayspJHHnkk+x9SRNLbvSUI9vXVcNkjcPT5YVe03xTuKY499li2b9/O4MGDGTRoEFOnTuX8889n/PjxjBs3jtGjR3d6mrfccguf+9znGDt2LGVlZTzyyCN069aNWbNm8fjjjxOLxRg4cCD33HMPr7/+Ol/+8pcpKSkhFovx4IMP5uBTisg+dn8Ij10E7y+Dy2fA6HPDrqhLdD33IqVlJZJFuzbDYxfChpVw+WNw1FlhV9QmXc9dRCQTuzbDjMlQuwqumAlHRuOG9Qr3Llq6dCnTpk1rNa5bt2689tprIVUkIhnbuRFmXAAb/wZXPgEfOT3sirKm4MLd3Tt1DnnYxo4dm/drvYe1K00kUnbUBmvsm9fAVb+EI04Nu6KsKqhTISsqKti0aZPCqx3uzqZNm6ioqAi7FJHitWMDPHoebP47XDUrcsEOBbbmPmTIEGpqaqitrQ27lIJWUVHBkCFDwi5DpDhtfx8ePR+21sDUp+HwaP5QsKDCPRaLcfjhh4ddhohE1bb1wRr7tvUwdTaMODnsinKmoMJdRCRntq2DR86DHR/A1XNg+ElhV5RTHe5zN7MKM/uLmS0xs+Vm9u00bbqZ2SwzW21mr5nZiFwUKyKyX7bWwC/OCfa1Xz038sEOmR1QrQdOdfePAeOAs8zsxJQ2nwU+dPePAP8O/Gt2yxQR2U9b3g2CfdcmmPYMDPtE2BXlRYfh7oEdyT9jyUfq6SwXAI8mh2cDp1kxnc8oItH04TvwyLnBNWOmPQtDTwi7orzJ6FRIMys1s2pgA/Ciu6f+Qmcw8B6AuzcBW4G+2SxURKRTNv89CPa6rXDNszDk42FXlFcZhbu7x919HDAEmGBmqTcHTbeWvs/J6mZ2k5lVmVmVTncUkZzZvCY4eNqwA66ZB4OPD7uivOvUj5jcfQvwByD1qjo1wFAAMysDDgY2p3n/w+4+3t3H9+/ff78KFhFp16a34BfnQuMuuPbXcNi4sCsKRSZny/Q3s97J4e7A6cCbKc3mAdcmhy8FXnL9zFRE8m3j34KDp/H6INgHjg27otBkcp77IOBRMysl6Ayecvf5ZnYvUOXu84CfAY+Z2WqCNfYpOatYRCSd2r8Gvzz1BFw7HwYcE3ZFoeow3N39DeC4NOPvaTFcBxTX3WNFJDo2rIRHJwfD186HQzt/U52oKagLh4mIdNoHy4ODp1YC059TsCfp8gMiUrzeXxpcj720PFhj7/eRsCsqGFpzF5HitP6NYB97WUWwxq5gb0XhLiLFZ111EOyxnjB9PvQ9IuyKCo7CXUSKy9pFwR2Uuh0E1z0Hh4wMu6KCpH3uIlI8aqrgsYuh+8HBPvY+w8OuqGBpzV1EisN7f4HHLoIefWD6AgV7BxTuIlL43n01WGPv2S8I9t5Dw66o4CncRaSwvfPfQbD3GhCcFXPw4LArKgra5y4ihevtV2Dm5XDQYcFZMb0Ghl1R0dCau4gUpr8vhJmXwcFDgjV2BXunKNxFpPC89XKwxt57eDLYB4RdUdFRuItIYVn9e3hySnD++vT5UKl7P+wPhbuIFI6//Q6evBL6jgqux96zX9gVFS2Fu4gUhlW/gV9eCf2PgmvnQU/dhrkrFO4iEr43F8Avp8KhxwTB3uOQsCsqegp3EQnXyvnw1DXBLfGu+RV07xN2RZGgcBeR8Kz4FTx9bXAT62uehe69w64oMhTuIhKO5c/A09fB4I/D1XOh4uCwK4oUhbuI5N/S2TD7szB0Alw9ByoOCruiyFG4i0h+vfEUzL0Rhp0IU2dDt15hVxRJCncRyZ8lv4Rn/g8MPxmmPg3dKsOuKLIU7iKSH/8zE575HIw4Ba56Csp7hl1RpCncRST3Fs+AX30eRk6Cq2ZBeY+wK4o8hbuI5FbVL2DerXDEqXDlkxDrHnZFBwSFu4jkzus/hfm3w6gzYMoTCvY86jDczWyomb1sZivNbLmZ3ZamzSQz22pm1cnHPbkpV0SKxmsPw3NfhCPPhiseh1hF2BUdUDK5E1MT8EV3X2xmvYBFZvaiu69Iafcndz8v+yWKSNF59UF44S446ly47BEoKw+7ogNOh2vu7r7e3Rcnh7cDKwHdxFBE0vvvB4JgH32egj1EndrnbmYjgOOA19K8fJKZLTGz583s2CzUJiLF5r9+AL/9GhxzgYI9ZBnfINvMKoE5wO3uvi3l5cXAcHffYWbnAM8Co9JM4ybgJoBhw4btd9EiUoD+9P/g9/fCsRfDxT+B0ozjRXIgozV3M4sRBPtMd5+b+rq7b3P3HcnhBUDMzPa5hYq7P+zu4919fP/+unWWSGT88b4g2MdepmAvEB3+C5iZAT8DVrr7/W20GQh84O5uZhMIOo1NWa1URApP/Q545f5grf2jU+DCH0FJadhVCZntljkZmAYsNbPq5LivAsMA3P0h4FLgZjNrAnYDU9zdc1CviIStqR5W/w6WPg1/fQGadsO4qTD5PxXsBaTDcHf3VwDroM0DwAPZKkpECkwiDm//KQj0lb+Guq3Qoy+MuwrGXgrDTgJrNyYkz7RjTETSc4eaKlg2O7ixxo4PoLwyOMVx7GUw8lNQGgu7SmmDwl1EWvtgRRDoy+bAh29DaTcY9Zkg0I88U5cQKBIKdxEJQnxpMtA3rAArCa7gOPErcPR5ugVeEVK4ixyotn8Q7G5ZNhtqXg/GDf0EnH0fHHshVB4abn3SJQp3kQPJ7i3BAdFls+HvC8ETMGAMnPZNGHMJ9BkedoWSJQp3kahr2AWrXgh2ufzttxBvgD4j4JQvwphL4dDRYVcoOaBwF4mieCO89XKwhv7mc9CwAyoHwgk3BIE++HiduhhxCneRqEgk4N0/B+eir/gV7N4cHAgdc3EQ6CP+QT8yOoAo3EWKmTusXxIE+vJnYNtaiPWAo84OAv0jp0FZt7CrlBAo3EWK0ca/JU9dnA2bVkNJLAjyz9wLR54F3SrDrlBCpnAXKRZba2DZ3CDQ1y8BLNjV8slb4ejJ0OOQsCuUAqJwFylkOzfBimeDtfR3/zsYd9jxcOY/w7EXwUGHhVufFCyFu0ihqd8enOGydDaseRkSTdDvKPj014Jz0fseEXaFUgQU7iKFoLEOVr8YBPqqF6CpDg4eCid9Primy4AxOnVROkXhLhKWeBO8vRCWzgl+NVq/FXr0g+OmBZfRHTIBSjp1m2ORPRTuIvnkHlzHZelsWD4XdtZCeS84+nwYewkcPkm3qJOs0P8ikXz4YPneUxe3vBtcRvfIM4M19FFn6DK6knUKd5Fc2fz3IMyXzoHalWClwWV0J30VRp8LFQeFXaFEWPGFu7sOLEnh2v5+8EvRpbNhbVUwbuiJcM6/wTEXQmX/cOuTA0bxhfub82HODdC9T/JxCHTvHQz3OKTFuD4p4/po01dyY/eHwQHRpbOD+4x6AgaOhdO/HVzXpfewsCuUA1DxhXufETDhpuAL1fzYvAZ2bQ4ulBRvaPu9Zd1TQr93O51By06hIm8fT4pEwy5Y9Xywy2X1i8H/u0NGwilfCvaj9z8q7ArlAFd84T5wbPBIxx0adwchv/vDZOA3dwIthnclnzeuDsbv2gyJxrbnGevRYkuhT/qtgubOoOU4XbApWpoagh8VLX0a3lwAjTuh16BgZWPMJXDYcdplKAWj+MK9PWZQ3iN4HDwk8/e5Q+Ou9J3BnnFb9o7buGrv+HY7hZ4tOoI++3YEbW0plJV3fVlIdiQS8M5/BQdGV/wq+Dev6A0fvSy46uLwT+oyulKQohXu+8sMynsGj95DM3+fOzTsTNkq2Nyic9jSetyGN/e2TTS1Pd3yymTQ9277+EHqlkJFb3UK2eIO6/4nuHPRsrmwfV3QUY8+Jwj0I07VspaCp3DvCrPg0qrdKjt30Mw9uDNO2i2FD/cdt2HF3rYeb3u65b32dgotO4KK3kGt7oC3eE4kh0nzWmqbdK81PxO0a7eNt9Em3bwzmWcHr7U7z2TNbbWp3xEEekkMRn0Gxvzf4Pro5T0z/zcWCZnCPQxm0K1X8OjMDYndg4tKpd1S2LLvrqSta4NxdVtbnEJqwbOV7B1O+0wGbZqfS1q/r622uZpn80/092ueacaVxmDEKXDM5KBzFClCHYa7mQ0FZgADgQTwsLv/IKWNAT8AzgF2AdPdfXH2yz3AmQU/fKk4KDhrSESkDZmsuTcBX3T3xWbWC1hkZi+6+4oWbc4GRiUfnwAeTD6LiEgIOrzknLuvb14Ld/ftwEpgcEqzC4AZHngV6G1mg7JerYiIZKRT1xM1sxHAccBrKS8NBt5r8XcN+3YAmNlNZlZlZlW1tbWdq1RERDKWcbibWSUwB7jd3belvpzmLb7PCPeH3X28u4/v31/X2BARyZWMwt3MYgTBPtPd56ZpUgO0PEF8CLCu6+WJiMj+6DDck2fC/AxY6e73t9FsHnCNBU4Etrr7+izWKSIinZDJ2TInA9OApWZWnRz3VWAYgLs/BCwgOA1yNcGpkNdlv1QREclUh+Hu7q+Qfp96yzYOfD5bRYmISNfo7rsiIhGkcBcRiSCFu4hIBCncRUQiSOEuIhJBCncRkQhSuIuIRJDCXUQkghTuIiIRpHAXEYkghbuISAQp3EVEIkjhLiISQQp3EZEIUriLiESQwl1EJIIU7iIiEaRwFxGJIIW7iEgEKdxFRCJI4S4iEkEKdxGRCFK4i4hEkMJdRCSCFO4iIhHUYbib2c/NbIOZLWvj9UlmttXMqpOPe7JfpoiIdEZZBm0eAR4AZrTT5k/ufl5WKhIRkS7rcM3d3RcCm/NQi4iIZEm29rmfZGZLzOx5Mzs2S9MUEZH9lMlumY4sBoa7+w4zOwd4FhiVrqGZ3QTcBDBs2LAszFpERNLp8pq7u29z9x3J4QVAzMz6tdH2YXcf7+7j+/fv39VZi4hIG7oc7mY20MwsOTwhOc1NXZ2uiIjsvw53y5jZk8AkoJ+Z1QDfBGIA7v4QcClws5k1AbuBKe7uOatYREQ61GG4u/uVHbz+AMGpkiIiUiD0C1URkQhSuIuIRJDCXUQkghTuIiIRpHAXEYkghbuISAQp3EVEIkjhLiISQQp3EZEIUriLiESQwl1EJIIU7iIiEaRwFxGJIIW7iEgEKdxFRCJI4S4iEkEKdxGRCFK4i4hEkMJdRCSCFO4iIhGkcBcRiSCFu4hIBCncRUQiSOEuIhJBCncRkQhSuIuIRFCH4W5mPzezDWa2rI3Xzcz+w8xWm9kbZnZ89ssUEZHOyGTN/RHgrHZePxsYlXzcBDzY9bJERKQrOgx3d18IbG6nyQXADA+8CvQ2s0HZKlBERDovG/vcBwPvtfi7JjluH2Z2k5lVmVlVbW1tFmYtIiLpZCPcLc04T9fQ3R929/HuPr5///5ZmLWIiKSTjXCvAYa2+HsIsC4L0xURkf2UjXCfB1yTPGvmRGCru6/PwnRFRGQ/lXXUwMyeBCYB/cysBvgmEANw94eABcA5wGpgF3BdrooVEZHMdBju7n5lB6878PmsVSQiIl2mX6iKiESQwl1EJIKKLtzrGuNs2dVAYzwRdikiIgWrw33uhealNzdwy8zFAHQrK6FXRRk9u5VR2S147pV8rqwIxqUfX0pltxg9u5XSK/lcVlp0/ZyISJuKLtxHD+zFN847hp31TexIPnbWN7GjLhh+f1tdq9fqGjNbw6+IlbTqDJqHKytSOoeU8S3/riwvU0chIgWh6MJ9ZP9KRvavzLh9YzzBrvo42+sb2VkfZ0d9Izvq4+yoCzqF7c2dQ/Ojxfj3t9Wxozb5d10T9U2d6ShiwRZCRRk9y8tabWG06kRStzBS2pWWpPsBsIhI+4ou3DsrVlrCwT1KOLhHrMvTaown9tli2F7XtG+n0dA8fm/bdVvq2Nmwdwsj046ie6w0pQMobd1xtLNV0XJXVM9ydRQiB5LIh3s2xUpL6N2jnN49yrs8reaOYnuyM2gO/TY7jRa7n9Zt2b23XX0TDZ3oKPZuHZTSs3zfXUw9y/cel+iZeryixRZGeZl2PYkUMoV7SLLZUTQ0pdmiSDkWsadzqI+3avv+tjp21nb+GEV5aUmwFZHcKmi1m6m8uTMobaPjaN1ZVMRKMNNWhUg2KdwjoLyshPKycvr07HpH0RRPBFsMDS12K7XYxbS3Y4jv06Fs2dXAex/uYmd9sNWxs6EJT3t90NZKjFZbCKlbCc1bEXs6hvLU4xN7z37qWV5GiXY/iSjcpbWyLB6jSCScXY3x9J3Enl1R+3YSzc8bttcld00F4+KJDHoKoEd5aavOoeVxin07jtanyPZMdh7lZSWUlRhlpc3PRqykRB2HFA2Fu+RMSYntCdIBXZyWu1PflEg5JpHsJFqc/ZSuk9hR38TaLbuTWxSdO06RygxiJSWUlRqlJUasOfybO4LS5HBJCbFkm7LS5uESYsmOoqykZO9zc+dRWpJsH3QkwfRbdDCtOpsW028xr1iLzqjVPJqnWWrJGlpMP1mDOq5oUbhLUTAzKmKlVMRK6VfZrcvTSz2g3Xw8ovlsp8Z4gqa405RwmuKJ5LPTlEjQGHfiyeemRIJ4woPhlHbNw43xBPWNCRoTceKJxJ5xe96XbhoJz3hLJVtKjFYdSWxPB9B2p9M83D2WcoylvPWWUbD1pAPz+aRwlwNSNg9o50oi4cQ92UEkEsSTz01xT3YG6Tqdlh3E3nHNnVU8sXcanem4Wk6jedrN76lrTLB5594to86c6tt8YL51R5DcRZZyAL7V+Bbjmo+99IiVauujBYW7SIEqKTFKMGKl0J3SsMvplH1/PNjUKvyDXWrxtMditu5uZF1yN1pz20w3YnqWp3YU6bcYWh6ob3U2155Tg0vpVlZcyzyVwl1Esi6bPx50d+oaE3s6itTjKTvbOSi/sz6+5weEzeMzPd03Vmp7DrA3/4CwzQPyqR1FAZzFpXAXkYJmZnQvL6V7eSn06vr00p3uu3erov2OYntdE+9vbX39qky3Knq02KqY+olh3HDKyK5/mHYo3EXkgJLN032btyr26QgaWnQUdfuOz8ZJAR1RuIuI7KeWWxX9e+U+sDtD5yGJiESQwl1EJIIU7iIiEaRwFxGJIIW7iEgEKdxFRCJI4S4iEkEKdxGRCDLP5FY5uZixWS3wzn6+vR+wMYvlZEuh1gWFW5vq6hzV1TlRrGu4u/fvqFFo4d4VZlbl7uPDriNVodYFhVub6uoc1dU5B3Jd2i0jIhJBCncRkQgq1nB/OOwC2lCodUHh1qa6Okd1dc4BW1dR7nMXEZH2Feuau4iItKOgw93MzjKzv5rZajO7K83r3cxsVvL118xsRIHUNd3Mas2sOvm4IU91/dzMNpjZsjZeNzP7j2Tdb5jZ8QVS1yQz29pied2Th5qGmtnLZrbSzJab2W1p2uR9eWVYV96XV3K+FWb2FzNbkqzt22na5P07mWFdYX0nS83sf8xsfprXcrus3L0gH0Ap8BYwEigHlgDHpLS5BXgoOTwFmFUgdU0HHghhmU0EjgeWtfH6OcDzgAEnAq8VSF2TgPl5XlaDgOOTw72AVWn+HfO+vDKsK+/LKzlfAyqTwzHgNeDElDZhfCczqSus7+Q/AU+k+/fK9bIq5DX3CcBqd1/j7g3AL4ELUtpcADyaHJ4NnGZmub4LbSZ1hcLdFwKb22lyATDDA68Cvc1sUAHUlXfuvt7dFyeHtwMrgcEpzfK+vDKsKxTJ5bAj+Wcs+Ug9aJf372SGdeWdmQ0BzgV+2kaTnC6rQg73wcB7Lf6uYd//5HvauHsTsBXoWwB1AVyS3JSfbWZDc1xTpjKtPQwnJTernzezY/M54+Tm8HEEa3wthbq82qkLQlpeyd0M1cAG4EV3b3OZ5fE7mUldkP/v5P8HvgIk2ng9p8uqkMM9XQ+W2htn0ibbMpnnr4ER7v5R4Hfs7Z3DFsbyysRigp9Ufwz4T+DZfM3YzCqBOcDt7r4t9eU0b8nL8uqgrtCWl7vH3X0cMASYYGZjUpqEsswyqCuv30m1ZicbAAAB0UlEQVQzOw/Y4O6L2muWZlzWllUhh3sN0LJ3HQKsa6uNmZUBB5P7zf8O63L3Te5en/zzJ8DHc1xTpjJZpnnn7tuaN6vdfQEQM7N+uZ6vmcUIAnSmu89N0ySU5dVRXWEtr5QatgB/AM5KeSmM72SHdYXwnTwZmGxmbxPsuj3VzB5PaZPTZVXI4f46MMrMDjezcoIDDvNS2swDrk0OXwq85MmjE2HWlbJfdjLBftNCMA+4JnkWyInAVndfH3ZRZjaweV+jmU0g+H+5KcfzNOBnwEp3v7+NZnlfXpnUFcbySs6rv5n1Tg53B04H3kxplvfvZCZ15fs76e53u/sQdx9BkBEvufvVKc1yuqzKsjWhbHP3JjP7R+A3BGeo/Nzdl5vZvUCVu88j+BI8ZmarCXq8KQVS1xfMbDLQlKxreq7rAjCzJwnOpOhnZjXANwkOLuHuDwELCM4AWQ3sAq4rkLouBW42syZgNzAlD530ycA0YGlyXy3AV4FhLeoKY3llUlcYywuCM3keNbNSgg7lKXefH/Z3MsO6QvlOpsrnstIvVEVEIqiQd8uIiMh+UriLiESQwl1EJIIU7iIiEaRwFxGJIIW7iEgEKdxFRCJI4S4iEkH/C8qBp+zTbzURAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = pd.DataFrame()\n",
    "history['tr_acc'] = hist_ta\n",
    "history['val_acc'] = hist_va\n",
    "history['tr_loss'] = hist_tl\n",
    "history['val_loss'] = hist_vl\n",
    "display(history[['tr_acc','val_acc']].plot())\n",
    "display(history[['tr_loss','val_loss']].plot())\n",
    "history.to_csv('../tf_runs/{0}_1.csv'.format(model_name),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../checkpoints/{0}.h5'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict_captions(image):\n",
    "    start_word = [\"startseq\"]\n",
    "    while True:\n",
    "        par_caps = [w_to_co[i] for i in start_word]\n",
    "        par_caps = sequence.pad_sequences([par_caps], maxlen=max_wlen, padding='pre',value=-1)\n",
    "        preds = model.predict([image, np.array(par_caps)])\n",
    "#         print(preds.shape)\n",
    "        idx = preds.argmax(-1)\n",
    "        word_pred = co_to_w[idx[0]]\n",
    "#         print(par_caps)\n",
    "        start_word.append(word_pred)\n",
    "        \n",
    "        if word_pred == \"endseq\" or len(start_word) > max_wlen:\n",
    "            break\n",
    "            \n",
    "    return ' '.join(start_word[1:-1])\n",
    "\n",
    "# print('Predicted:',' '.join(out_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_predictions(image, beam_index = 3):\n",
    "    start = [w_to_co[\"startseq\"]]\n",
    "    \n",
    "    # start_word[0][0] = index of the starting word\n",
    "    # start_word[0][1] = probability of the word predicted\n",
    "    start_word = [[start, 0.0]]\n",
    "    \n",
    "    while len(start_word[0][0]) < max_wlen:\n",
    "        temp = []\n",
    "        for s in start_word:\n",
    "            par_caps = sequence.pad_sequences([s[0]], maxlen=max_wlen, padding='pre', value=-1)\n",
    "            preds = model.predict([image, np.array(par_caps)])\n",
    "            \n",
    "            # Getting the top <beam_index>(n) predictions\n",
    "            word_preds = np.argsort(preds[0])[-beam_index:]\n",
    "            \n",
    "            # creating a new list so as to put them via the model again\n",
    "            for w in word_preds:\n",
    "                next_cap, prob = s[0][:], s[1]\n",
    "                next_cap.append(w)\n",
    "                prob += preds[0][w]\n",
    "                temp.append([next_cap, prob])\n",
    "                    \n",
    "        start_word = temp\n",
    "        # Sorting according to the probabilities\n",
    "        start_word = sorted(start_word, reverse=False, key=lambda l: l[1])\n",
    "        # Getting the top words\n",
    "        start_word = start_word[-beam_index:]\n",
    "    \n",
    "    start_word = start_word[-1][0]\n",
    "    intermediate_caption = [co_to_w[i] for i in start_word]\n",
    "\n",
    "    final_caption = []\n",
    "    \n",
    "    for i in intermediate_caption:\n",
    "        if i != 'endseq':\n",
    "            final_caption.append(i)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    final_caption = ' '.join(final_caption[1:])\n",
    "    return final_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshaikh2/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292e2fa6117446d8bf96f64474da14d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ref_sents = []\n",
    "pred_sents = []\n",
    "for counter in tqdm_notebook(range(len(test_images_list))):\n",
    "    testx,testy = next(test_gen)\n",
    "    photo = testx['image_input'][0]\n",
    "#     plt.imshow(photo)\n",
    "#     plt.show()\n",
    "    photo = np.expand_dims(photo,0)\n",
    "    \n",
    "#     print('Actual:',testy['actual_sentence'][0])\n",
    "#     print()\n",
    "    # st = time()\n",
    "    # pred_greedy = predict_captions(photo)\n",
    "    # et = time()\n",
    "    # print('Greedy Predicted:{0},[{1:.2f} s]'.format(pred_greedy,et-st))\n",
    "#     st = time()\n",
    "    pred_bm5 = beam_search_predictions(photo,beam_index=5)\n",
    "#     et = time()\n",
    "#     print('Beam-5 Predicted:{0},[{1:.2f} s]'.format(pred_bm5,et-st))\n",
    "    ref_sents.append(testy['actual_sentence'][0])\n",
    "    pred_sents.append(pred_bm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ref_sents),len(pred_sents)\n",
    "# st = time()\n",
    "# pred_greedy = predict_captions(photo)\n",
    "# et = time()\n",
    "# print('Greedy Predicted:{0},[{1:.2f} s]'.format(pred_greedy,et-st))\n",
    "\n",
    "# st = time()\n",
    "# pred_bm3 = beam_search_predictions(photo,beam_index=3)\n",
    "# et = time()\n",
    "# print('Beam-3 Predicted:{0},[{1:.2f} s]'.format(pred_bm3,et-st))\n",
    "\n",
    "# st = time()\n",
    "# pred_bm5 = beam_search_predictions(photo,beam_index=5)\n",
    "# et = time()\n",
    "# print('Beam-5 Predicted:{0},[{1:.2f} s]'.format(pred_bm5,et-st))\n",
    "\n",
    "# st = time()\n",
    "# pred_bm7 = beam_search_predictions(photo,beam_index=7)\n",
    "# et = time()\n",
    "# print('Beam-7 Predicted:{0},[{1:.2f} s]'.format(pred_bm7,et-st))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshaikh2/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/mshaikh2/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/mshaikh2/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>BLEU-2</th>\n",
       "      <th>BLEU-3</th>\n",
       "      <th>BLEU-4</th>\n",
       "      <th>ROUGE-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.368</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.310</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.277</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.161</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.487</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.444</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.553</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.166</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.284</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.217</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.294</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.393</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.474</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.251</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.158</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.434</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.289</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.447</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.158</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.432</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.444</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.307</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.389</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.444</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.194</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.450</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.474</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.763</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.493</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.236</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.270</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.184</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.463</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.383</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.329</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BLEU-1  BLEU-2  BLEU-3  BLEU-4  ROUGE-L\n",
       "0     0.368   0.173   0.000   0.000    0.226\n",
       "1     0.310   0.222   0.161   0.120    0.290\n",
       "2     0.361   0.144   0.000   0.000    0.372\n",
       "3     0.500   0.414   0.360   0.301    0.468\n",
       "4     0.469   0.301   0.212   0.158    0.314\n",
       "5     0.277   0.126   0.000   0.000    0.333\n",
       "6     0.500   0.308   0.202   0.146    0.385\n",
       "7     0.161   0.000   0.000   0.000    0.059\n",
       "8     0.500   0.349   0.242   0.000    0.500\n",
       "9     0.487   0.277   0.187   0.115    0.436\n",
       "10    0.444   0.195   0.000   0.000    0.327\n",
       "11    0.553   0.405   0.287   0.190    0.500\n",
       "12    0.500   0.359   0.251   0.174    0.431\n",
       "13    0.224   0.076   0.000   0.000    0.102\n",
       "14    0.166   0.093   0.050   0.000    0.219\n",
       "15    0.284   0.144   0.094   0.062    0.300\n",
       "16    0.217   0.102   0.057   0.000    0.242\n",
       "17    0.294   0.164   0.096   0.000    0.275\n",
       "18    0.393   0.213   0.098   0.000    0.317\n",
       "19    0.474   0.253   0.000   0.000    0.269\n",
       "20    0.275   0.072   0.000   0.000    0.258\n",
       "21    0.263   0.000   0.000   0.000    0.238\n",
       "22    0.265   0.090   0.000   0.000    0.250\n",
       "23    0.417   0.189   0.104   0.000    0.360\n",
       "24    0.225   0.000   0.000   0.000    0.098\n",
       "25    0.417   0.218   0.114   0.000    0.333\n",
       "26    0.251   0.191   0.169   0.151    0.368\n",
       "27    0.158   0.113   0.091   0.067    0.211\n",
       "28    0.434   0.233   0.000   0.000    0.440\n",
       "29    0.289   0.153   0.089   0.000    0.311\n",
       "..      ...     ...     ...     ...      ...\n",
       "270   0.500   0.329   0.211   0.000    0.491\n",
       "271   0.435   0.267   0.176   0.000    0.400\n",
       "272   0.447   0.246   0.153   0.000    0.392\n",
       "273   0.158   0.092   0.064   0.000    0.154\n",
       "274   0.417   0.244   0.155   0.000    0.333\n",
       "275   0.545   0.261   0.000   0.000    0.449\n",
       "276   0.167   0.098   0.067   0.000    0.154\n",
       "277   0.432   0.190   0.103   0.000    0.353\n",
       "278   0.444   0.276   0.192   0.119    0.200\n",
       "279   0.250   0.119   0.061   0.000    0.308\n",
       "280   0.307   0.257   0.236   0.221    0.328\n",
       "281   0.389   0.236   0.120   0.000    0.348\n",
       "282   0.756   0.710   0.674   0.642    0.691\n",
       "283   0.444   0.276   0.168   0.108    0.245\n",
       "284   0.194   0.129   0.081   0.000    0.216\n",
       "285   0.417   0.218   0.114   0.000    0.327\n",
       "286   0.450   0.240   0.148   0.095    0.421\n",
       "287   0.474   0.339   0.255   0.174    0.436\n",
       "288   0.763   0.704   0.664   0.629    0.679\n",
       "289   0.756   0.710   0.674   0.642    0.691\n",
       "290   0.493   0.255   0.000   0.000    0.286\n",
       "291   0.333   0.195   0.134   0.000    0.356\n",
       "292   0.526   0.337   0.215   0.153    0.436\n",
       "293   0.236   0.162   0.124   0.096    0.222\n",
       "294   0.270   0.087   0.000   0.000    0.182\n",
       "295   0.184   0.071   0.000   0.000    0.178\n",
       "296   0.417   0.218   0.144   0.000    0.415\n",
       "297   0.463   0.373   0.333   0.303    0.481\n",
       "298   0.383   0.224   0.113   0.000    0.316\n",
       "299   0.329   0.203   0.158   0.121    0.381\n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge\n",
    "rouge = Rouge()\n",
    "# reference = nlp(str(vy['actual_sentence'][0]))\n",
    "# reference = [[str(x) for x in list(reference)]]\n",
    "\n",
    "\n",
    "# candidate = nlp(pred_greedy)\n",
    "# candidate = [str(x) for x in list(candidate)]\n",
    "# df_result['greedy'] = [sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "#                       ,sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0))\n",
    "#                       ,sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0))\n",
    "#                       ,sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))]\n",
    "\n",
    "# candidate = nlp(pred_bm3)\n",
    "# candidate = [str(x) for x in list(candidate)]\n",
    "# df_result['bm3'] = [sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "#                       ,sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0))\n",
    "#                       ,sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0))\n",
    "#                       ,sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))]\n",
    "row = []\n",
    "for i in range(len(ref_sents)):\n",
    "    r = ref_sents[i]\n",
    "    c = pred_sents[i]\n",
    "    reference = nlp(str(r))\n",
    "    reference = [[str(x) for x in list(reference)]]\n",
    "    candidate = nlp(str(c))\n",
    "    candidate = [str(x) for x in list(candidate)]\n",
    "    row.append([sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "                          ,sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0))\n",
    "                          ,sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0))\n",
    "                          ,sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "                          ,rouge.get_scores(hyps=c,refs=r)[0]['rouge-l']['f']])\n",
    "\n",
    "\n",
    "# candidate = nlp(pred_bm7)\n",
    "# candidate = [str(x) for x in list(candidate)]\n",
    "# df_result['bm7'] = [sentence_bleu(reference, candidate, weights=(1, 0, 0, 0))\n",
    "#                       ,sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0))\n",
    "#                       ,sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0))\n",
    "#                       ,sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))]\n",
    "df_result = pd.DataFrame(row)\n",
    "df_result.columns = ['BLEU-1','BLEU-2','BLEU-3','BLEU-4','ROUGE-L']\n",
    "df_result.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLEU-1     0.354683\n",
       "BLEU-2     0.205537\n",
       "BLEU-3     0.122557\n",
       "BLEU-4     0.062123\n",
       "ROUGE-L    0.310510\n",
       "dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = df_result.round(3)\n",
    "p.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'f': 0.3544303756192918, 'p': 0.6086956521739131, 'r': 0.25},\n",
       "  'rouge-2': {'f': 0.18181817773654926,\n",
       "   'p': 0.3181818181818182,\n",
       "   'r': 0.12727272727272726},\n",
       "  'rouge-l': {'f': 0.42622950403654936,\n",
       "   'p': 0.7222222222222222,\n",
       "   'r': 0.3023255813953488}}]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# reference = str(vy['actual_sentence'][0])\n",
    "# # reference = [[str(x) for x in list(reference)]]\n",
    "# candidate = pred_greedy\n",
    "# # candidate = [str(x) for x in list(candidate)]\n",
    "# ro = rouge.get_scores(hyps=candidate,refs=reference)\n",
    "ro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rouge-1</th>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-2</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.127273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge-l</th>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.302326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                f         p         r\n",
       "rouge-1  0.354430  0.608696  0.250000\n",
       "rouge-2  0.181818  0.318182  0.127273\n",
       "rouge-l  0.426230  0.722222  0.302326"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ro[0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.meteor.meteor import Meteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_scores(ref, hypo):\n",
    "    \"\"\"\n",
    "    ref, dictionary of reference sentences (id, sentence)\n",
    "    hypo, dictionary of hypothesis sentences (id, sentence)\n",
    "    score, dictionary of scores\n",
    "    \"\"\"\n",
    "    scorers = [\n",
    "        (Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]),\n",
    "#         (Meteor(),\"METEOR\"),\n",
    "        (Rouge(), \"ROUGE_L\"),\n",
    "        (Cider(), \"CIDEr\")\n",
    "    ]\n",
    "    final_scores = {}\n",
    "    for scorer, method in scorers:\n",
    "        score, scores = scorer.compute_score(ref, hypo)\n",
    "        if type(score) == list:\n",
    "            for m, s in zip(method, score):\n",
    "                final_scores[m] = s\n",
    "        else:\n",
    "            final_scores[method] = score\n",
    "    return final_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': [14, 3, 0, 0], 'reflen': 33, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1515151514802573\n",
      "{'correct': [20, 10, 5, 3], 'reflen': 57, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.6315789473573408\n",
      "{'correct': [13, 2, 0, 0], 'reflen': 21, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.7142857142040817\n",
      "{'correct': [18, 12, 9, 6], 'reflen': 25, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.4399999999424\n",
      "{'correct': [15, 6, 3, 2], 'reflen': 32, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.9999999999687501\n",
      "{'correct': [20, 4, 0, 0], 'reflen': 63, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 0.6190476190377929\n",
      "{'correct': [19, 7, 3, 2], 'reflen': 33, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1515151514802573\n",
      "{'correct': [5, 0, 0, 0], 'reflen': 19, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 1.6315789472825484\n",
      "{'correct': [19, 9, 4, 0], 'reflen': 37, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0270270269992696\n",
      "{'correct': [19, 6, 3, 1], 'reflen': 33, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 1.1818181817823692\n",
      "{'correct': [16, 3, 0, 0], 'reflen': 33, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.0909090908760333\n",
      "{'correct': [21, 11, 5, 2], 'reflen': 30, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.2666666666244444\n",
      "{'correct': [18, 9, 4, 2], 'reflen': 29, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.2413793103020214\n",
      "{'correct': [9, 1, 0, 0], 'reflen': 40, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.8999999999775001\n",
      "{'correct': [13, 4, 1, 0], 'reflen': 64, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.5624999999912109\n",
      "{'correct': [16, 4, 2, 1], 'reflen': 53, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.7169811320619438\n",
      "{'correct': [14, 3, 1, 0], 'reflen': 57, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.6315789473573408\n",
      "{'correct': [10, 3, 1, 0], 'reflen': 29, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 1.1724137930630203\n",
      "{'correct': [21, 6, 1, 0], 'reflen': 51, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.7450980392010765\n",
      "{'correct': [18, 5, 0, 0], 'reflen': 31, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.225806451573361\n",
      "{'correct': [15, 1, 0, 0], 'reflen': 51, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7058823529273357\n",
      "{'correct': [10, 0, 0, 0], 'reflen': 19, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.9999999998947369\n",
      "{'correct': [9, 1, 0, 0], 'reflen': 27, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 1.25925925921262\n",
      "{'correct': [15, 3, 1, 0], 'reflen': 29, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.2413793103020214\n",
      "{'correct': [9, 0, 0, 0], 'reflen': 40, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 0.974999999975625\n",
      "{'correct': [15, 4, 1, 0], 'reflen': 36, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9999999999722223\n",
      "{'correct': [11, 6, 5, 4], 'reflen': 34, 'testlen': 18, 'guess': [18, 17, 16, 15]}\n",
      "ratio: 0.5294117646903115\n",
      "{'correct': [6, 3, 2, 1], 'reflen': 12, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 3.1666666664027776\n",
      "{'correct': [18, 5, 0, 0], 'reflen': 40, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 0.7749999999806251\n",
      "{'correct': [11, 3, 1, 0], 'reflen': 23, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.6521739129716446\n",
      "{'correct': [9, 2, 1, 0], 'reflen': 24, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.5833333332673611\n",
      "{'correct': [18, 8, 5, 3], 'reflen': 39, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.9743589743339909\n",
      "{'correct': [17, 3, 1, 0], 'reflen': 43, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.8837209302120066\n",
      "{'correct': [15, 7, 4, 2], 'reflen': 36, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 0.8611111110871914\n",
      "{'correct': [10, 2, 0, 0], 'reflen': 31, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.161290322543184\n",
      "{'correct': [32, 27, 24, 22], 'reflen': 42, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.9047619047403629\n",
      "{'correct': [14, 5, 2, 0], 'reflen': 39, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.9743589743339909\n",
      "{'correct': [14, 2, 0, 0], 'reflen': 61, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.5573770491711906\n",
      "{'correct': [19, 6, 2, 1], 'reflen': 55, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.690909090896529\n",
      "{'correct': [7, 2, 1, 0], 'reflen': 17, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 2.2352941175155707\n",
      "{'correct': [23, 17, 14, 12], 'reflen': 37, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 0.8378378378151936\n",
      "{'correct': [16, 6, 3, 1], 'reflen': 61, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.5901639344165547\n",
      "{'correct': [19, 6, 2, 1], 'reflen': 55, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.6181818181705786\n",
      "{'correct': [9, 3, 1, 0], 'reflen': 24, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.4999999999375\n",
      "{'correct': [13, 3, 0, 0], 'reflen': 38, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 1.026315789446676\n",
      "{'correct': [7, 2, 1, 0], 'reflen': 17, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 2.2352941175155707\n",
      "{'correct': [17, 6, 2, 0], 'reflen': 36, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0555555555262346\n",
      "{'correct': [28, 24, 21, 19], 'reflen': 37, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9729729729466765\n",
      "{'correct': [9, 3, 1, 0], 'reflen': 24, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.4999999999375\n",
      "{'correct': [18, 5, 1, 0], 'reflen': 35, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.0285714285420409\n",
      "{'correct': [15, 6, 3, 1], 'reflen': 37, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 0.8378378378151936\n",
      "{'correct': [14, 4, 2, 1], 'reflen': 47, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7659574467922138\n",
      "{'correct': [13, 7, 4, 2], 'reflen': 27, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.3333333332839505\n",
      "{'correct': [6, 2, 1, 0], 'reflen': 19, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.8947368420055402\n",
      "{'correct': [16, 7, 3, 1], 'reflen': 37, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0270270269992696\n",
      "{'correct': [16, 4, 1, 0], 'reflen': 38, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9473684210277009\n",
      "{'correct': [14, 3, 1, 0], 'reflen': 26, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.38461538456213\n",
      "{'correct': [16, 6, 2, 1], 'reflen': 25, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.5199999999392\n",
      "{'correct': [13, 2, 0, 0], 'reflen': 20, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.899999999905\n",
      "{'correct': [20, 5, 2, 1], 'reflen': 90, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.35555555555160495\n",
      "{'correct': [20, 9, 2, 0], 'reflen': 35, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0857142856832653\n",
      "{'correct': [17, 5, 2, 0], 'reflen': 50, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.7599999999848001\n",
      "{'correct': [17, 8, 5, 3], 'reflen': 23, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.6521739129716446\n",
      "{'correct': [21, 8, 4, 1], 'reflen': 51, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 0.764705882337947\n",
      "{'correct': [8, 0, 0, 0], 'reflen': 24, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.5833333332673611\n",
      "{'correct': [13, 3, 0, 0], 'reflen': 27, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.4074074073552811\n",
      "{'correct': [20, 7, 3, 1], 'reflen': 40, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 0.9999999999750001\n",
      "{'correct': [12, 5, 1, 0], 'reflen': 36, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9999999999722223\n",
      "{'correct': [10, 1, 0, 0], 'reflen': 17, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 2.2352941175155707\n",
      "{'correct': [12, 1, 0, 0], 'reflen': 46, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7826086956351608\n",
      "{'correct': [11, 1, 0, 0], 'reflen': 31, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.225806451573361\n",
      "{'correct': [22, 7, 2, 0], 'reflen': 49, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.775510204065806\n",
      "{'correct': [10, 1, 0, 0], 'reflen': 18, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.9999999998888889\n",
      "{'correct': [8, 4, 2, 0], 'reflen': 17, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 2.2352941175155707\n",
      "{'correct': [10, 1, 0, 0], 'reflen': 43, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 0.9302325581179016\n",
      "{'correct': [23, 13, 6, 3], 'reflen': 36, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0555555555262346\n",
      "{'correct': [26, 11, 4, 2], 'reflen': 37, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 0.8378378378151936\n",
      "{'correct': [19, 8, 2, 0], 'reflen': 40, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.9499999999762501\n",
      "{'correct': [12, 3, 0, 0], 'reflen': 32, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 1.2187499999619142\n",
      "{'correct': [14, 3, 2, 1], 'reflen': 32, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1874999999628908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': [11, 2, 1, 0], 'reflen': 37, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9729729729466765\n",
      "{'correct': [22, 10, 6, 4], 'reflen': 49, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.775510204065806\n",
      "{'correct': [13, 5, 2, 1], 'reflen': 44, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.7272727272561984\n",
      "{'correct': [12, 2, 0, 0], 'reflen': 31, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.161290322543184\n",
      "{'correct': [18, 6, 3, 2], 'reflen': 54, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.5925925925816187\n",
      "{'correct': [21, 8, 3, 1], 'reflen': 75, 'testlen': 37, 'guess': [37, 36, 35, 34]}\n",
      "ratio: 0.49333333332675555\n",
      "{'correct': [14, 2, 1, 0], 'reflen': 40, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.8999999999775001\n",
      "{'correct': [10, 3, 1, 0], 'reflen': 19, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.8947368420055402\n",
      "{'correct': [10, 2, 1, 0], 'reflen': 20, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.899999999905\n",
      "{'correct': [16, 6, 2, 1], 'reflen': 37, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0270270269992696\n",
      "{'correct': [15, 4, 2, 1], 'reflen': 40, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 0.974999999975625\n",
      "{'correct': [18, 3, 1, 0], 'reflen': 63, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 0.6349206349105568\n",
      "{'correct': [14, 5, 2, 0], 'reflen': 24, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.4999999999375\n",
      "{'correct': [12, 3, 0, 0], 'reflen': 44, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.8181818181632232\n",
      "{'correct': [16, 5, 2, 1], 'reflen': 40, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.8499999999787501\n",
      "{'correct': [18, 5, 2, 1], 'reflen': 46, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 0.8695652173724008\n",
      "{'correct': [18, 3, 0, 0], 'reflen': 35, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0857142856832653\n",
      "{'correct': [18, 4, 2, 0], 'reflen': 74, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.5135135135065741\n",
      "{'correct': [16, 2, 0, 0], 'reflen': 64, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.49999999999218747\n",
      "{'correct': [19, 7, 3, 2], 'reflen': 33, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1515151514802573\n",
      "{'correct': [18, 11, 7, 5], 'reflen': 29, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.2413793103020214\n",
      "{'correct': [10, 1, 0, 0], 'reflen': 67, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.50746268655959\n",
      "{'correct': [18, 3, 0, 0], 'reflen': 60, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.6333333333227779\n",
      "{'correct': [9, 4, 2, 1], 'reflen': 19, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 1.6315789472825484\n",
      "{'correct': [8, 1, 0, 0], 'reflen': 28, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.2857142856683674\n",
      "{'correct': [17, 5, 3, 1], 'reflen': 24, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.5833333332673611\n",
      "{'correct': [12, 5, 1, 0], 'reflen': 44, 'testlen': 37, 'guess': [37, 36, 35, 34]}\n",
      "ratio: 0.8409090908899794\n",
      "{'correct': [14, 5, 1, 0], 'reflen': 34, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.058823529380623\n",
      "{'correct': [10, 2, 0, 0], 'reflen': 27, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 1.4444444443909465\n",
      "{'correct': [20, 7, 3, 1], 'reflen': 44, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.8636363636167356\n",
      "{'correct': [13, 5, 2, 0], 'reflen': 27, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.3333333332839505\n",
      "{'correct': [6, 1, 0, 0], 'reflen': 26, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.38461538456213\n",
      "{'correct': [17, 3, 1, 0], 'reflen': 41, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.9268292682700774\n",
      "{'correct': [11, 4, 2, 1], 'reflen': 18, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.9999999998888889\n",
      "{'correct': [7, 3, 2, 1], 'reflen': 23, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.565217391236295\n",
      "{'correct': [12, 3, 0, 0], 'reflen': 27, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 1.1481481481056242\n",
      "{'correct': [6, 3, 2, 1], 'reflen': 12, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 2.99999999975\n",
      "{'correct': [21, 11, 4, 1], 'reflen': 48, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.7916666666501737\n",
      "{'correct': [19, 3, 1, 0], 'reflen': 42, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 0.9523809523582767\n",
      "{'correct': [11, 4, 2, 0], 'reflen': 57, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 0.7017543859526009\n",
      "{'correct': [6, 0, 0, 0], 'reflen': 28, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 1.392857142807398\n",
      "{'correct': [15, 3, 1, 0], 'reflen': 36, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9999999999722223\n",
      "{'correct': [18, 3, 0, 0], 'reflen': 45, 'testlen': 37, 'guess': [37, 36, 35, 34]}\n",
      "ratio: 0.8222222222039507\n",
      "{'correct': [14, 4, 2, 0], 'reflen': 27, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.4074074073552811\n",
      "{'correct': [15, 4, 1, 0], 'reflen': 34, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1176470587906575\n",
      "{'correct': [10, 3, 2, 1], 'reflen': 17, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 2.2352941175155707\n",
      "{'correct': [15, 2, 1, 0], 'reflen': 69, 'testlen': 41, 'guess': [41, 40, 39, 38]}\n",
      "ratio: 0.594202898542113\n",
      "{'correct': [8, 4, 2, 0], 'reflen': 17, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 2.117647058698962\n",
      "{'correct': [18, 9, 7, 6], 'reflen': 36, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0555555555262346\n",
      "{'correct': [25, 21, 18, 16], 'reflen': 40, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.8999999999775001\n",
      "{'correct': [8, 4, 2, 0], 'reflen': 17, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 2.117647058698962\n",
      "{'correct': [16, 8, 4, 1], 'reflen': 29, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 1.0689655172045185\n",
      "{'correct': [20, 4, 1, 0], 'reflen': 48, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.7916666666501737\n",
      "{'correct': [15, 3, 1, 0], 'reflen': 27, 'testlen': 28, 'guess': [28, 27, 26, 25]}\n",
      "ratio: 1.0370370369986281\n",
      "{'correct': [18, 12, 10, 8], 'reflen': 71, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.5352112675980956\n",
      "{'correct': [12, 4, 0, 0], 'reflen': 38, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9473684210277009\n",
      "{'correct': [19, 13, 10, 7], 'reflen': 31, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 1.2903225806035379\n",
      "{'correct': [15, 5, 3, 2], 'reflen': 36, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 0.8611111110871914\n",
      "{'correct': [17, 4, 2, 1], 'reflen': 78, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 0.5128205128139381\n",
      "{'correct': [17, 7, 3, 1], 'reflen': 47, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.7234042553037574\n",
      "{'correct': [17, 5, 1, 0], 'reflen': 30, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.2666666666244444\n",
      "{'correct': [12, 4, 0, 0], 'reflen': 42, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.8571428571224491\n",
      "{'correct': [17, 3, 0, 0], 'reflen': 21, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.8095238094376418\n",
      "{'correct': [21, 9, 4, 2], 'reflen': 41, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.9268292682700774\n",
      "{'correct': [11, 5, 3, 2], 'reflen': 24, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.4999999999375\n",
      "{'correct': [16, 6, 4, 3], 'reflen': 28, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.2857142856683674\n",
      "{'correct': [11, 2, 0, 0], 'reflen': 27, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.3333333332839505\n",
      "{'correct': [15, 4, 1, 0], 'reflen': 46, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.7391304347665407\n",
      "{'correct': [18, 3, 0, 0], 'reflen': 45, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7999999999822223\n",
      "{'correct': [21, 7, 2, 0], 'reflen': 37, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0270270269992696\n",
      "{'correct': [14, 3, 0, 0], 'reflen': 44, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.8636363636167356\n",
      "{'correct': [8, 4, 2, 0], 'reflen': 17, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 2.2352941175155707\n",
      "{'correct': [14, 5, 3, 1], 'reflen': 15, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 2.6666666664888887\n",
      "{'correct': [15, 5, 3, 1], 'reflen': 25, 'testlen': 28, 'guess': [28, 27, 26, 25]}\n",
      "ratio: 1.1199999999552\n",
      "{'correct': [11, 2, 0, 0], 'reflen': 14, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 2.7142857140918366\n",
      "{'correct': [17, 5, 2, 0], 'reflen': 30, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.2666666666244444\n",
      "{'correct': [19, 8, 5, 3], 'reflen': 41, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.9268292682700774\n",
      "{'correct': [9, 2, 0, 0], 'reflen': 22, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 1.7727272726466943\n",
      "{'correct': [19, 6, 3, 1], 'reflen': 60, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.5333333333244444\n",
      "{'correct': [18, 12, 9, 6], 'reflen': 25, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.4399999999424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': [14, 2, 0, 0], 'reflen': 33, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 1.1818181817823692\n",
      "{'correct': [18, 7, 3, 1], 'reflen': 35, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0857142856832653\n",
      "{'correct': [14, 3, 1, 0], 'reflen': 45, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 0.8666666666474074\n",
      "{'correct': [22, 11, 7, 4], 'reflen': 40, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 0.9999999999750001\n",
      "{'correct': [14, 4, 2, 0], 'reflen': 27, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.4074074073552811\n",
      "{'correct': [16, 4, 0, 0], 'reflen': 48, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.749999999984375\n",
      "{'correct': [20, 8, 2, 1], 'reflen': 53, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.6037735848942685\n",
      "{'correct': [15, 3, 1, 0], 'reflen': 42, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.8095238095045352\n",
      "{'correct': [19, 7, 3, 1], 'reflen': 68, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.5294117646980968\n",
      "{'correct': [15, 5, 2, 0], 'reflen': 28, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.3571428570943878\n",
      "{'correct': [10, 4, 2, 0], 'reflen': 28, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.2857142856683674\n",
      "{'correct': [9, 0, 0, 0], 'reflen': 54, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 0.5740740740634431\n",
      "{'correct': [12, 1, 0, 0], 'reflen': 120, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.2999999999975\n",
      "{'correct': [12, 3, 0, 0], 'reflen': 36, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0555555555262346\n",
      "{'correct': [16, 4, 2, 0], 'reflen': 30, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.2666666666244444\n",
      "{'correct': [17, 3, 0, 0], 'reflen': 33, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1515151514802573\n",
      "{'correct': [16, 4, 1, 0], 'reflen': 72, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.47222222221566357\n",
      "{'correct': [14, 3, 1, 0], 'reflen': 28, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.3571428570943878\n",
      "{'correct': [22, 8, 2, 0], 'reflen': 59, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.6101694915150819\n",
      "{'correct': [16, 4, 1, 0], 'reflen': 120, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 0.33333333333055554\n",
      "{'correct': [20, 11, 6, 4], 'reflen': 50, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7199999999856\n",
      "{'correct': [14, 2, 0, 0], 'reflen': 32, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1874999999628908\n",
      "{'correct': [13, 5, 2, 0], 'reflen': 32, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.124999999964844\n",
      "{'correct': [8, 4, 2, 0], 'reflen': 17, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 2.117647058698962\n",
      "{'correct': [13, 3, 2, 1], 'reflen': 27, 'testlen': 28, 'guess': [28, 27, 26, 25]}\n",
      "ratio: 1.0370370369986281\n",
      "{'correct': [10, 3, 1, 0], 'reflen': 26, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.38461538456213\n",
      "{'correct': [6, 0, 0, 0], 'reflen': 23, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.6521739129716446\n",
      "{'correct': [9, 3, 2, 1], 'reflen': 37, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9729729729466765\n",
      "{'correct': [23, 7, 2, 0], 'reflen': 49, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.775510204065806\n",
      "{'correct': [11, 6, 4, 2], 'reflen': 31, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 1.0967741935130073\n",
      "{'correct': [12, 4, 3, 2], 'reflen': 27, 'testlen': 29, 'guess': [29, 28, 27, 26]}\n",
      "ratio: 1.0740740740342936\n",
      "{'correct': [19, 12, 9, 6], 'reflen': 28, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.2857142856683674\n",
      "{'correct': [9, 3, 1, 0], 'reflen': 33, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.969696969667585\n",
      "{'correct': [10, 2, 0, 0], 'reflen': 31, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.161290322543184\n",
      "{'correct': [16, 4, 1, 0], 'reflen': 38, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.8421052631357342\n",
      "{'correct': [11, 3, 0, 0], 'reflen': 43, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.7441860464943213\n",
      "{'correct': [12, 5, 1, 0], 'reflen': 36, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9999999999722223\n",
      "{'correct': [11, 2, 0, 0], 'reflen': 31, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.161290322543184\n",
      "{'correct': [9, 4, 2, 1], 'reflen': 35, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.9142857142595919\n",
      "{'correct': [21, 8, 4, 1], 'reflen': 57, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.6666666666549708\n",
      "{'correct': [29, 24, 21, 19], 'reflen': 37, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0270270269992696\n",
      "{'correct': [15, 6, 3, 1], 'reflen': 29, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.2413793103020214\n",
      "{'correct': [12, 2, 1, 0], 'reflen': 53, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.7169811320619438\n",
      "{'correct': [16, 3, 1, 0], 'reflen': 35, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 1.1428571428244898\n",
      "{'correct': [18, 8, 4, 2], 'reflen': 35, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.0285714285420409\n",
      "{'correct': [14, 3, 1, 0], 'reflen': 36, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9999999999722223\n",
      "{'correct': [19, 8, 6, 5], 'reflen': 58, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.5517241379215221\n",
      "{'correct': [21, 10, 5, 2], 'reflen': 33, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1515151514802573\n",
      "{'correct': [7, 3, 2, 1], 'reflen': 23, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 1.6956521738393195\n",
      "{'correct': [13, 4, 1, 0], 'reflen': 73, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.46575342465115405\n",
      "{'correct': [18, 7, 4, 2], 'reflen': 33, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.0909090908760333\n",
      "{'correct': [12, 2, 0, 0], 'reflen': 45, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.8444444444256791\n",
      "{'correct': [17, 6, 3, 1], 'reflen': 54, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.6296296296179699\n",
      "{'correct': [18, 6, 2, 1], 'reflen': 45, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.7111111110953087\n",
      "{'correct': [13, 3, 1, 0], 'reflen': 34, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.058823529380623\n",
      "{'correct': [19, 5, 2, 1], 'reflen': 43, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.8837209302120066\n",
      "{'correct': [15, 5, 1, 0], 'reflen': 62, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.5483870967653486\n",
      "{'correct': [17, 3, 0, 0], 'reflen': 33, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1515151514802573\n",
      "{'correct': [19, 6, 2, 1], 'reflen': 41, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.9268292682700774\n",
      "{'correct': [18, 7, 3, 1], 'reflen': 62, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.5483870967653486\n",
      "{'correct': [13, 2, 1, 0], 'reflen': 30, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.2666666666244444\n",
      "{'correct': [13, 5, 2, 0], 'reflen': 27, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.3333333332839505\n",
      "{'correct': [23, 12, 7, 4], 'reflen': 43, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.8372093023061115\n",
      "{'correct': [16, 4, 2, 1], 'reflen': 35, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 1.1428571428244898\n",
      "{'correct': [16, 8, 4, 1], 'reflen': 32, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 0.9687499999697267\n",
      "{'correct': [17, 7, 3, 2], 'reflen': 33, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.0909090908760333\n",
      "{'correct': [10, 1, 0, 0], 'reflen': 38, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 1.0526315789196676\n",
      "{'correct': [12, 2, 0, 0], 'reflen': 24, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.5833333332673611\n",
      "{'correct': [18, 7, 3, 0], 'reflen': 29, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.3103448275410225\n",
      "{'correct': [9, 2, 1, 0], 'reflen': 26, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.38461538456213\n",
      "{'correct': [8, 2, 1, 0], 'reflen': 27, 'testlen': 28, 'guess': [28, 27, 26, 25]}\n",
      "ratio: 1.0370370369986281\n",
      "{'correct': [17, 4, 2, 1], 'reflen': 43, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.8372093023061115\n",
      "{'correct': [15, 4, 1, 0], 'reflen': 53, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.679245283006052\n",
      "{'correct': [17, 5, 0, 0], 'reflen': 45, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 0.6888888888735804\n",
      "{'correct': [14, 2, 0, 0], 'reflen': 47, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7659574467922138\n",
      "{'correct': [19, 5, 2, 1], 'reflen': 41, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 0.7560975609571684\n",
      "{'correct': [10, 2, 1, 0], 'reflen': 36, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9999999999722223\n",
      "{'correct': [10, 3, 2, 1], 'reflen': 18, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 1.8888888887839506\n",
      "{'correct': [16, 4, 0, 0], 'reflen': 41, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 0.9512195121719216\n",
      "{'correct': [13, 3, 1, 0], 'reflen': 46, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.7391304347665407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': [19, 7, 4, 2], 'reflen': 45, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7999999999822223\n",
      "{'correct': [9, 3, 1, 0], 'reflen': 19, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.8947368420055402\n",
      "{'correct': [10, 3, 1, 0], 'reflen': 19, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.8947368420055402\n",
      "{'correct': [20, 6, 3, 1], 'reflen': 45, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 0.8444444444256791\n",
      "{'correct': [18, 6, 2, 0], 'reflen': 39, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9230769230532545\n",
      "{'correct': [16, 8, 6, 4], 'reflen': 33, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.0909090908760333\n",
      "{'correct': [14, 4, 1, 0], 'reflen': 27, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.3333333332839505\n",
      "{'correct': [14, 1, 0, 0], 'reflen': 46, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7826086956351608\n",
      "{'correct': [16, 7, 3, 1], 'reflen': 33, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1515151514802573\n",
      "{'correct': [16, 1, 0, 0], 'reflen': 68, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.49999999999264705\n",
      "{'correct': [14, 4, 2, 0], 'reflen': 27, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.4074074073552811\n",
      "{'correct': [16, 4, 1, 0], 'reflen': 40, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.8999999999775001\n",
      "{'correct': [16, 4, 0, 0], 'reflen': 49, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7346938775360267\n",
      "{'correct': [17, 3, 1, 0], 'reflen': 48, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.749999999984375\n",
      "{'correct': [13, 4, 1, 0], 'reflen': 45, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7999999999822223\n",
      "{'correct': [10, 3, 0, 0], 'reflen': 19, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.9999999998947369\n",
      "{'correct': [10, 2, 1, 0], 'reflen': 31, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 1.0967741935130073\n",
      "{'correct': [10, 2, 1, 0], 'reflen': 18, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 2.111111110993827\n",
      "{'correct': [19, 12, 7, 4], 'reflen': 35, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.0285714285420409\n",
      "{'correct': [15, 3, 1, 0], 'reflen': 37, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.8648648648414902\n",
      "{'correct': [10, 3, 1, 0], 'reflen': 29, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 1.103448275824019\n",
      "{'correct': [23, 9, 3, 0], 'reflen': 45, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7999999999822223\n",
      "{'correct': [14, 2, 1, 0], 'reflen': 51, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.6666666666535949\n",
      "{'correct': [18, 9, 4, 1], 'reflen': 51, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.7058823529273357\n",
      "{'correct': [18, 6, 3, 0], 'reflen': 56, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 0.7142857142729593\n",
      "{'correct': [8, 4, 2, 0], 'reflen': 17, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 2.2352941175155707\n",
      "{'correct': [14, 4, 1, 0], 'reflen': 30, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 1.066666666631111\n",
      "{'correct': [17, 5, 2, 1], 'reflen': 36, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9999999999722223\n",
      "{'correct': [13, 4, 0, 0], 'reflen': 27, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.3333333332839505\n",
      "{'correct': [14, 3, 1, 0], 'reflen': 37, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9729729729466765\n",
      "{'correct': [19, 8, 3, 0], 'reflen': 33, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1515151514802573\n",
      "{'correct': [19, 7, 3, 0], 'reflen': 43, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.8372093023061115\n",
      "{'correct': [17, 5, 2, 0], 'reflen': 30, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.2666666666244444\n",
      "{'correct': [6, 2, 1, 0], 'reflen': 13, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 2.9230769228520708\n",
      "{'correct': [15, 5, 2, 0], 'reflen': 36, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9999999999722223\n",
      "{'correct': [18, 4, 0, 0], 'reflen': 33, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.969696969667585\n",
      "{'correct': [6, 2, 1, 0], 'reflen': 16, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 2.249999999859375\n",
      "{'correct': [16, 3, 1, 0], 'reflen': 37, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9729729729466765\n",
      "{'correct': [16, 6, 3, 1], 'reflen': 35, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.0285714285420409\n",
      "{'correct': [18, 4, 1, 0], 'reflen': 61, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.5901639344165547\n",
      "{'correct': [22, 15, 13, 12], 'reflen': 57, 'testlen': 31, 'guess': [31, 30, 29, 28]}\n",
      "ratio: 0.5438596491132657\n",
      "{'correct': [14, 5, 1, 0], 'reflen': 23, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.565217391236295\n",
      "{'correct': [28, 24, 21, 19], 'reflen': 37, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9729729729466765\n",
      "{'correct': [16, 6, 2, 1], 'reflen': 28, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.2857142856683674\n",
      "{'correct': [7, 3, 1, 0], 'reflen': 13, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 2.7692307690177516\n",
      "{'correct': [15, 4, 1, 0], 'reflen': 32, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.124999999964844\n",
      "{'correct': [18, 5, 2, 1], 'reflen': 38, 'testlen': 40, 'guess': [40, 39, 38, 37]}\n",
      "ratio: 1.0526315789196676\n",
      "{'correct': [18, 9, 5, 2], 'reflen': 37, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0270270269992696\n",
      "{'correct': [29, 24, 21, 19], 'reflen': 37, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.0270270269992696\n",
      "{'correct': [28, 24, 21, 19], 'reflen': 37, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9729729729466765\n",
      "{'correct': [23, 6, 0, 0], 'reflen': 46, 'testlen': 39, 'guess': [39, 38, 37, 36]}\n",
      "ratio: 0.8478260869380908\n",
      "{'correct': [12, 4, 2, 0], 'reflen': 27, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.3333333332839505\n",
      "{'correct': [20, 8, 3, 2], 'reflen': 34, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1176470587906575\n",
      "{'correct': [11, 5, 3, 2], 'reflen': 44, 'testlen': 32, 'guess': [32, 31, 30, 29]}\n",
      "ratio: 0.7272727272561984\n",
      "{'correct': [10, 1, 0, 0], 'reflen': 37, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9729729729466765\n",
      "{'correct': [7, 1, 0, 0], 'reflen': 20, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.899999999905\n",
      "{'correct': [15, 4, 2, 0], 'reflen': 35, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 1.0285714285420409\n",
      "{'correct': [19, 12, 10, 9], 'reflen': 32, 'testlen': 41, 'guess': [41, 40, 39, 38]}\n",
      "ratio: 1.2812499999599611\n",
      "{'correct': [15, 5, 1, 0], 'reflen': 39, 'testlen': 36, 'guess': [36, 35, 34, 33]}\n",
      "ratio: 0.9230769230532545\n",
      "{'correct': [19, 7, 5, 3], 'reflen': 52, 'testlen': 34, 'guess': [34, 33, 32, 31]}\n",
      "ratio: 0.6538461538335799\n"
     ]
    }
   ],
   "source": [
    "r={}\n",
    "h={}\n",
    "df = pd.DataFrame(columns=['Bleu_1','Bleu_2','Bleu_3','Bleu_4','CIDEr','ROUGE_L'])\n",
    "for i in range(len(ref_sents)):\n",
    "#     t = nlp(str(ref_sents[i]))\n",
    "#     t_arr = [[str(x) for x in t]]\n",
    "\n",
    "    ref_t = nlp(str(ref_sents[i]))\n",
    "    ref_t = [str(x) for x in ref_t]\n",
    "    ref_t = ' '.join(ref_t)\n",
    "\n",
    "    pred_t = nlp(str(pred_sents[i]))\n",
    "    pred_t = [str(x) for x in pred_t]\n",
    "    pred_t = ' '.join(pred_t)\n",
    "    \n",
    "\n",
    "    r['0']=[ref_t]\n",
    "    h['0']=[pred_t]\n",
    "    \n",
    "    \n",
    "    d = calc_scores(r,h)\n",
    "    l = pd.DataFrame.from_dict(data=d,orient='index')\n",
    "    l = l.sort_index()\n",
    "    l = l.T\n",
    "    df=df.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bleu_1     0.354704\n",
       "Bleu_2     0.205565\n",
       "Bleu_3     0.120703\n",
       "Bleu_4     0.062119\n",
       "CIDEr      0.000000\n",
       "ROUGE_L    0.297629\n",
       "dtype: float64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_bleu(references=[ref_sents[0]], hypothesis=pred_sents[0], weights=(1, 0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['heart size within normal limits, stable mediastinal and hilar contours. no focal alveolar consolidation, no definite pleural effusion seen. no typical findings of pulmonary edema. no pneumothorax.'],\n",
       " 'both lungs are clear bilaterally . specifically , no evidence of focal consolidation , pneumothorax , or pleural effusion . cardiomediastinal silhouette is unremarkable . visualized osseous structures appear intact . there are no acute bony abnormality .')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ref_sents[0]],pred_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Bleu(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': [14, 3, 0, 0], 'reflen': 33, 'testlen': 38, 'guess': [38, 37, 36, 35]}\n",
      "ratio: 1.1515151514802573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.36842105262188374,\n",
       "  0.17283511575720037,\n",
       "  9.396955198772326e-07,\n",
       "  2.206598690629072e-09],\n",
       " [[0.36842105262188374],\n",
       "  [0.17283511575720037],\n",
       "  [9.396955198772326e-07],\n",
       "  [2.206598690629072e-09]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.compute_score({'0':[ref_t]},{'0':[pred_t]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshaikh2/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/mshaikh2/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2121212121212121"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_bleu(references=[ref_sents[0].replace('.',' ').split()], hypothesis=pred_sents[0].replace('.',' ').split(), weights=(1, 0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "ref_t = nlp(str(ref_sents[i]))\n",
    "ref_t = [str(x) for x in ref_t]\n",
    "ref_t = ' '.join(ref_t)\n",
    "\n",
    "pred_t = nlp(str(pred_sents[i]))\n",
    "pred_t = [str(x) for x in pred_t]\n",
    "pred_t = ' '.join(pred_t)\n",
    "\n",
    "\n",
    "r['0']=[ref_t]\n",
    "h['0']=[ref_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-335-b34c6372cae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/pycocoevalcap/cider/cider.py\u001b[0m in \u001b[0;36mcompute_score\u001b[0;34m(self, gts, res)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mcider_scorer\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhypo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcider_scorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/pycocoevalcap/cider/cider_scorer.py\u001b[0m in \u001b[0;36mcompute_score\u001b[0;34m(self, option, verbose)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_frequency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# compute cider score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_cider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# print score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/pycocoevalcap/cider/cider_scorer.py\u001b[0m in \u001b[0;36mcompute_cider\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;31m# compute vector for test captions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;31m# compute vector for ref captions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/pycocoevalcap/cider/cider_scorer.py\u001b[0m in \u001b[0;36mcounts2vec\u001b[0;34m(cnts)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# tf (term_freq) * idf (precomputed idf) for n-grams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0;31m# compute norm for the vector.  the norm will be used for computing similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mnorm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "scorer = Cider(n=2)\n",
    "scorer.compute_score(gts=r,res=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'0': ['heart size within normal limits , stable mediastinal and hilar contours . no focal alveolar consolidation , no definite pleural effusion seen . no typical findings of pulmonary edema . no pneumothorax .']},\n",
       " {'0': ['heart size within normal limits , stable mediastinal and hilar contours . no focal alveolar consolidation , no definite pleural effusion seen . no typical findings of pulmonary edema . no pneumothorax .']})"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
